{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mffx6_-pv2_h"
      },
      "source": [
        "# Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6FkrB3Zv2eC",
        "outputId": "e187c5ff-6b83-44af-cbde-4d7f8f3308f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: monai==1.3.2 in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai==1.3.2) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai==1.3.2) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.3.2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.3.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.3.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.3.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.3.2) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.3.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->monai==1.3.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai==1.3.2) (3.0.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.7)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.26.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.26.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (11.0.0)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.16.0)\n",
            "Requirement already satisfied: timm==0.9.7 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.9.7)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.5.1+cu121)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.0.2)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.10.3)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations) (3.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install monai==1.3.2\n",
        "!pip install timm\n",
        "!pip install segmentation-models-pytorch\n",
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBbGkvlMv9GR"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tapwnk8Fv8rI",
        "outputId": "e51435c5-a9b9-4610-ec23-4994fd7b1ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.5.1+cu121\n",
            "CUDA Available: True\n",
            "MONAI Version: 1.3.2\n",
            "timm Version: 0.9.7\n",
            "Segmentation Models PyTorch Version: 0.3.4\n"
          ]
        }
      ],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import PyTorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Import torchvision for image handling\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Import MONAI for medical image processing\n",
        "import monai\n",
        "from monai.transforms import (\n",
        "    Compose, LoadImaged, EnsureChannelFirstd,Spacingd, Orientationd, ScaleIntensityRanged,\n",
        "    CropForegroundd, RandCropByPosNegLabeld, RandFlipd, RandRotate90d, EnsureTyped,NormalizeIntensityd,Lambdad, ResizeWithPadOrCropd\n",
        ")\n",
        "\n",
        "# Import timm for Transformer models\n",
        "import timm\n",
        "\n",
        "# Import segmentation_models_pytorch for additional utilities\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Import Albumentations for advanced augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Verify imports\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"MONAI Version: {monai.__version__}\")\n",
        "print(f\"timm Version: {timm.__version__}\")\n",
        "print(f\"Segmentation Models PyTorch Version: {smp.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4w0mbiEOaUh"
      },
      "source": [
        "# Downloading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNy5KtUuNxOC",
        "outputId": "ca9c7951-9e51-4d8c-9f60-33924c5cc80c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "y7U1Cig1Odx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6f36cc-7699-45a9-94e1-331a218be8e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'1455606068279-GRS with C.M.4-2015.gdoc'\n",
            "'1455606068279-GRS with C.M.4-2015.pdf'\n",
            "'Colab Notebooks'\n",
            "'Detailed Report on Kavach: Train Collision Avoidance System.gdoc'\n",
            "'Images (1).zip'\n",
            " Images.zip\n",
            " night_video_output.mp4\n",
            " output.mp4\n",
            " output_video_ocr.mp4\n",
            "'Signs and Signals In Indian Railways.docx'\n",
            "'Signs and Signals In Indian Railways.gdoc'\n",
            "'State of the Art Techniques for Object Tracking.gdoc'\n",
            " Task01_BrainTumour.tar\n",
            " test_output_custom_model.mp4\n",
            " test_output_yolov8x.mp4\n",
            " test_v3.mp4\n",
            "'TrackSide Poles Vison Monitoring.gdoc'\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwe2Cf-UOpTD",
        "outputId": "ad2a0fd8-3e2e-494f-a722-73062e4e4b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "# Define the path to the .tar fileconten in Google Drive\n",
        "drive_tar_path = '/content/drive/MyDrive/Task01_BrainTumour.tar'  # Update if different\n",
        "\n",
        "# Define the extraction directory\n",
        "extract_dir = '/content'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract the .tar file\n",
        "with tarfile.open(drive_tar_path, 'r') as tar:\n",
        "    tar.extractall(path=extract_dir)\n",
        "\n",
        "print(\"Extraction completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j1HbjJ8E-HLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4112dfcb-3d67-43cc-d000-c0d3a509cac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset.json  imagesTr\timagesTs  labelsTr\n"
          ]
        }
      ],
      "source": [
        "! ls /content/Task01_BrainTumour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pIvnr9G8QsU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff67aae-a9a0-45a8-9246-5bb313f497fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images Directory Contents:\n",
            "['BRATS_457.nii.gz', 'BRATS_465.nii.gz', 'BRATS_333.nii.gz', 'BRATS_362.nii.gz', 'BRATS_084.nii.gz', 'BRATS_246.nii.gz', 'BRATS_466.nii.gz', 'BRATS_071.nii.gz', 'BRATS_422.nii.gz', 'BRATS_248.nii.gz', 'BRATS_256.nii.gz', 'BRATS_013.nii.gz', 'BRATS_272.nii.gz', 'BRATS_085.nii.gz', 'BRATS_072.nii.gz', 'BRATS_153.nii.gz', 'BRATS_441.nii.gz', 'BRATS_183.nii.gz', 'BRATS_235.nii.gz', 'BRATS_370.nii.gz', 'BRATS_005.nii.gz', 'BRATS_051.nii.gz', 'BRATS_329.nii.gz', 'BRATS_463.nii.gz', 'BRATS_025.nii.gz', 'BRATS_114.nii.gz', 'BRATS_197.nii.gz', 'BRATS_184.nii.gz', 'BRATS_193.nii.gz', 'BRATS_297.nii.gz', 'BRATS_042.nii.gz', 'BRATS_182.nii.gz', 'BRATS_124.nii.gz', 'BRATS_299.nii.gz', 'BRATS_035.nii.gz', 'BRATS_095.nii.gz', 'BRATS_323.nii.gz', 'BRATS_469.nii.gz', 'BRATS_252.nii.gz', 'BRATS_113.nii.gz', 'BRATS_257.nii.gz', 'BRATS_286.nii.gz', 'BRATS_122.nii.gz', 'BRATS_059.nii.gz', 'BRATS_165.nii.gz', 'BRATS_474.nii.gz', 'BRATS_258.nii.gz', 'BRATS_419.nii.gz', 'BRATS_117.nii.gz', 'BRATS_010.nii.gz', 'BRATS_322.nii.gz', 'BRATS_399.nii.gz', 'BRATS_119.nii.gz', 'BRATS_444.nii.gz', 'BRATS_243.nii.gz', '._BRATS_006.nii.gz', 'BRATS_427.nii.gz', 'BRATS_026.nii.gz', '._BRATS_004.nii.gz', 'BRATS_345.nii.gz', 'BRATS_259.nii.gz', 'BRATS_484.nii.gz', 'BRATS_379.nii.gz', 'BRATS_338.nii.gz', 'BRATS_176.nii.gz', 'BRATS_166.nii.gz', 'BRATS_215.nii.gz', 'BRATS_300.nii.gz', 'BRATS_191.nii.gz', 'BRATS_425.nii.gz', 'BRATS_239.nii.gz', 'BRATS_363.nii.gz', 'BRATS_408.nii.gz', 'BRATS_432.nii.gz', 'BRATS_325.nii.gz', 'BRATS_130.nii.gz', 'BRATS_126.nii.gz', 'BRATS_224.nii.gz', 'BRATS_405.nii.gz', 'BRATS_185.nii.gz', 'BRATS_456.nii.gz', 'BRATS_052.nii.gz', 'BRATS_156.nii.gz', 'BRATS_250.nii.gz', 'BRATS_365.nii.gz', 'BRATS_178.nii.gz', 'BRATS_118.nii.gz', 'BRATS_339.nii.gz', 'BRATS_181.nii.gz', 'BRATS_194.nii.gz', 'BRATS_438.nii.gz', 'BRATS_128.nii.gz', 'BRATS_196.nii.gz', 'BRATS_136.nii.gz', 'BRATS_177.nii.gz', 'BRATS_079.nii.gz', 'BRATS_471.nii.gz', 'BRATS_012.nii.gz', 'BRATS_146.nii.gz', 'BRATS_078.nii.gz', 'BRATS_413.nii.gz', 'BRATS_205.nii.gz', 'BRATS_291.nii.gz', 'BRATS_139.nii.gz', 'BRATS_331.nii.gz', 'BRATS_401.nii.gz', 'BRATS_449.nii.gz', 'BRATS_434.nii.gz', 'BRATS_308.nii.gz', 'BRATS_131.nii.gz', 'BRATS_394.nii.gz', 'BRATS_436.nii.gz', 'BRATS_306.nii.gz', 'BRATS_030.nii.gz', 'BRATS_433.nii.gz', 'BRATS_092.nii.gz', 'BRATS_442.nii.gz', 'BRATS_163.nii.gz', 'BRATS_314.nii.gz', 'BRATS_106.nii.gz', 'BRATS_352.nii.gz', 'BRATS_275.nii.gz', 'BRATS_170.nii.gz', 'BRATS_112.nii.gz', 'BRATS_290.nii.gz', 'BRATS_319.nii.gz', 'BRATS_066.nii.gz', 'BRATS_280.nii.gz', 'BRATS_409.nii.gz', 'BRATS_414.nii.gz', 'BRATS_437.nii.gz', 'BRATS_377.nii.gz', 'BRATS_265.nii.gz', 'BRATS_234.nii.gz', 'BRATS_097.nii.gz', 'BRATS_198.nii.gz', 'BRATS_075.nii.gz', 'BRATS_389.nii.gz', 'BRATS_022.nii.gz', 'BRATS_284.nii.gz', 'BRATS_179.nii.gz', 'BRATS_019.nii.gz', 'BRATS_411.nii.gz', 'BRATS_203.nii.gz', 'BRATS_395.nii.gz', 'BRATS_387.nii.gz', 'BRATS_278.nii.gz', 'BRATS_328.nii.gz', 'BRATS_359.nii.gz', 'BRATS_232.nii.gz', '._BRATS_028.nii.gz', 'BRATS_237.nii.gz', 'BRATS_001.nii.gz', '._BRATS_169.nii.gz', 'BRATS_429.nii.gz', 'BRATS_053.nii.gz', 'BRATS_341.nii.gz', 'BRATS_206.nii.gz', 'BRATS_225.nii.gz', 'BRATS_420.nii.gz', 'BRATS_326.nii.gz', 'BRATS_381.nii.gz', 'BRATS_302.nii.gz', 'BRATS_080.nii.gz', 'BRATS_404.nii.gz', 'BRATS_312.nii.gz', 'BRATS_134.nii.gz', 'BRATS_446.nii.gz', '._BRATS_274.nii.gz', 'BRATS_186.nii.gz', 'BRATS_448.nii.gz', 'BRATS_060.nii.gz', 'BRATS_337.nii.gz', 'BRATS_303.nii.gz', 'BRATS_089.nii.gz', 'BRATS_074.nii.gz', 'BRATS_159.nii.gz', 'BRATS_249.nii.gz', 'BRATS_242.nii.gz', 'BRATS_211.nii.gz', 'BRATS_479.nii.gz', 'BRATS_453.nii.gz', 'BRATS_330.nii.gz', 'BRATS_364.nii.gz', 'BRATS_201.nii.gz', 'BRATS_115.nii.gz', 'BRATS_120.nii.gz', 'BRATS_298.nii.gz', 'BRATS_151.nii.gz', 'BRATS_041.nii.gz', 'BRATS_482.nii.gz', 'BRATS_350.nii.gz', 'BRATS_285.nii.gz', 'BRATS_274.nii.gz', 'BRATS_357.nii.gz', 'BRATS_132.nii.gz', 'BRATS_483.nii.gz', 'BRATS_260.nii.gz', 'BRATS_152.nii.gz', 'BRATS_093.nii.gz', 'BRATS_233.nii.gz', 'BRATS_016.nii.gz', 'BRATS_020.nii.gz', 'BRATS_162.nii.gz', 'BRATS_349.nii.gz', 'BRATS_410.nii.gz', 'BRATS_472.nii.gz', '._BRATS_002.nii.gz', 'BRATS_109.nii.gz', 'BRATS_011.nii.gz', 'BRATS_360.nii.gz', 'BRATS_174.nii.gz', 'BRATS_228.nii.gz', 'BRATS_481.nii.gz', 'BRATS_158.nii.gz', 'BRATS_049.nii.gz', 'BRATS_154.nii.gz', 'BRATS_137.nii.gz', 'BRATS_305.nii.gz', 'BRATS_415.nii.gz', 'BRATS_372.nii.gz', 'BRATS_288.nii.gz', 'BRATS_226.nii.gz', 'BRATS_313.nii.gz', 'BRATS_082.nii.gz', 'BRATS_056.nii.gz', 'BRATS_104.nii.gz', 'BRATS_320.nii.gz', 'BRATS_462.nii.gz', 'BRATS_318.nii.gz', 'BRATS_400.nii.gz', 'BRATS_307.nii.gz', 'BRATS_167.nii.gz', 'BRATS_382.nii.gz', 'BRATS_046.nii.gz', 'BRATS_428.nii.gz', 'BRATS_430.nii.gz', 'BRATS_155.nii.gz', 'BRATS_091.nii.gz', 'BRATS_192.nii.gz', 'BRATS_083.nii.gz', 'BRATS_090.nii.gz', 'BRATS_251.nii.gz', 'BRATS_334.nii.gz', 'BRATS_336.nii.gz', 'BRATS_375.nii.gz', 'BRATS_135.nii.gz', 'BRATS_268.nii.gz', 'BRATS_048.nii.gz', 'BRATS_220.nii.gz', 'BRATS_142.nii.gz', 'BRATS_295.nii.gz', 'BRATS_315.nii.gz', 'BRATS_327.nii.gz', 'BRATS_173.nii.gz', 'BRATS_351.nii.gz', 'BRATS_386.nii.gz', 'BRATS_426.nii.gz', 'BRATS_219.nii.gz', 'BRATS_223.nii.gz', 'BRATS_107.nii.gz', 'BRATS_103.nii.gz', 'BRATS_039.nii.gz', 'BRATS_101.nii.gz', 'BRATS_148.nii.gz', 'BRATS_412.nii.gz', 'BRATS_385.nii.gz', 'BRATS_121.nii.gz', 'BRATS_150.nii.gz', 'BRATS_417.nii.gz', 'BRATS_366.nii.gz', 'BRATS_216.nii.gz', 'BRATS_207.nii.gz', '._BRATS_027.nii.gz', 'BRATS_477.nii.gz', 'BRATS_204.nii.gz', 'BRATS_468.nii.gz', 'BRATS_214.nii.gz', 'BRATS_100.nii.gz', 'BRATS_301.nii.gz', 'BRATS_029.nii.gz', '._BRATS_166.nii.gz', 'BRATS_416.nii.gz', 'BRATS_064.nii.gz', 'BRATS_459.nii.gz', 'BRATS_398.nii.gz', 'BRATS_188.nii.gz', 'BRATS_036.nii.gz', 'BRATS_281.nii.gz', 'BRATS_087.nii.gz', 'BRATS_380.nii.gz', 'BRATS_445.nii.gz', 'BRATS_467.nii.gz', 'BRATS_439.nii.gz', 'BRATS_213.nii.gz', 'BRATS_034.nii.gz', 'BRATS_068.nii.gz', '._BRATS_001.nii.gz', 'BRATS_003.nii.gz', 'BRATS_396.nii.gz', 'BRATS_390.nii.gz', 'BRATS_470.nii.gz', 'BRATS_157.nii.gz', 'BRATS_009.nii.gz', 'BRATS_431.nii.gz', 'BRATS_391.nii.gz', 'BRATS_102.nii.gz', 'BRATS_199.nii.gz', 'BRATS_077.nii.gz', 'BRATS_443.nii.gz', 'BRATS_195.nii.gz', 'BRATS_393.nii.gz', 'BRATS_054.nii.gz', 'BRATS_283.nii.gz', 'BRATS_264.nii.gz', 'BRATS_110.nii.gz', 'BRATS_043.nii.gz', 'BRATS_149.nii.gz', 'BRATS_311.nii.gz', 'BRATS_367.nii.gz', 'BRATS_355.nii.gz', 'BRATS_476.nii.gz', 'BRATS_018.nii.gz', 'BRATS_040.nii.gz', 'BRATS_065.nii.gz', 'BRATS_169.nii.gz', 'BRATS_240.nii.gz', 'BRATS_273.nii.gz', 'BRATS_270.nii.gz', 'BRATS_070.nii.gz', 'BRATS_202.nii.gz', 'BRATS_050.nii.gz', 'BRATS_231.nii.gz', 'BRATS_361.nii.gz', 'BRATS_373.nii.gz', 'BRATS_304.nii.gz', 'BRATS_244.nii.gz', 'BRATS_032.nii.gz', 'BRATS_347.nii.gz', 'BRATS_028.nii.gz', 'BRATS_023.nii.gz', 'BRATS_116.nii.gz', 'BRATS_292.nii.gz', 'BRATS_144.nii.gz', 'BRATS_464.nii.gz', 'BRATS_047.nii.gz', 'BRATS_241.nii.gz', 'BRATS_371.nii.gz', 'BRATS_081.nii.gz', 'BRATS_129.nii.gz', 'BRATS_123.nii.gz', 'BRATS_451.nii.gz', 'BRATS_421.nii.gz', 'BRATS_127.nii.gz', 'BRATS_324.nii.gz', 'BRATS_418.nii.gz', 'BRATS_348.nii.gz', 'BRATS_478.nii.gz', 'BRATS_147.nii.gz', 'BRATS_368.nii.gz', 'BRATS_238.nii.gz', 'BRATS_008.nii.gz', 'BRATS_210.nii.gz', 'BRATS_269.nii.gz', 'BRATS_058.nii.gz', 'BRATS_094.nii.gz', 'BRATS_407.nii.gz', 'BRATS_271.nii.gz', '._BRATS_275.nii.gz', 'BRATS_452.nii.gz', 'BRATS_424.nii.gz', 'BRATS_160.nii.gz', 'BRATS_098.nii.gz', 'BRATS_447.nii.gz', 'BRATS_473.nii.gz', 'BRATS_045.nii.gz', 'BRATS_021.nii.gz', 'BRATS_321.nii.gz', 'BRATS_187.nii.gz', 'BRATS_277.nii.gz', 'BRATS_316.nii.gz', 'BRATS_376.nii.gz', 'BRATS_276.nii.gz', 'BRATS_296.nii.gz', 'BRATS_073.nii.gz', 'BRATS_189.nii.gz', 'BRATS_057.nii.gz', 'BRATS_383.nii.gz', 'BRATS_384.nii.gz', 'BRATS_309.nii.gz', 'BRATS_221.nii.gz', 'BRATS_031.nii.gz', 'BRATS_403.nii.gz', 'BRATS_282.nii.gz', 'BRATS_346.nii.gz', 'BRATS_397.nii.gz', 'BRATS_212.nii.gz', 'BRATS_171.nii.gz', 'BRATS_294.nii.gz', 'BRATS_140.nii.gz', 'BRATS_440.nii.gz', 'BRATS_111.nii.gz', 'BRATS_460.nii.gz', 'BRATS_247.nii.gz', 'BRATS_133.nii.gz', 'BRATS_289.nii.gz', 'BRATS_218.nii.gz', 'BRATS_406.nii.gz', 'BRATS_293.nii.gz', 'BRATS_125.nii.gz', 'BRATS_069.nii.gz', 'BRATS_388.nii.gz', 'BRATS_454.nii.gz', 'BRATS_335.nii.gz', 'BRATS_015.nii.gz', 'BRATS_055.nii.gz', 'BRATS_088.nii.gz', 'BRATS_354.nii.gz', 'BRATS_161.nii.gz', 'BRATS_063.nii.gz', 'BRATS_168.nii.gz', 'BRATS_061.nii.gz', 'BRATS_027.nii.gz', 'BRATS_108.nii.gz', 'BRATS_222.nii.gz', 'BRATS_475.nii.gz', 'BRATS_263.nii.gz', 'BRATS_145.nii.gz', 'BRATS_402.nii.gz', 'BRATS_164.nii.gz', 'BRATS_208.nii.gz', 'BRATS_014.nii.gz', 'BRATS_267.nii.gz', 'BRATS_236.nii.gz', 'BRATS_002.nii.gz', 'BRATS_480.nii.gz', 'BRATS_369.nii.gz', 'BRATS_450.nii.gz', 'BRATS_343.nii.gz', 'BRATS_006.nii.gz', 'BRATS_105.nii.gz', 'BRATS_358.nii.gz', 'BRATS_172.nii.gz', 'BRATS_037.nii.gz', 'BRATS_190.nii.gz', 'BRATS_340.nii.gz', 'BRATS_266.nii.gz', '._BRATS_115.nii.gz', 'BRATS_017.nii.gz', 'BRATS_254.nii.gz', 'BRATS_024.nii.gz', 'BRATS_378.nii.gz', 'BRATS_209.nii.gz', 'BRATS_423.nii.gz', 'BRATS_007.nii.gz', 'BRATS_332.nii.gz', 'BRATS_356.nii.gz', 'BRATS_317.nii.gz', 'BRATS_255.nii.gz', 'BRATS_217.nii.gz', 'BRATS_067.nii.gz', 'BRATS_175.nii.gz', 'BRATS_200.nii.gz', 'BRATS_455.nii.gz', 'BRATS_033.nii.gz', 'BRATS_287.nii.gz', 'BRATS_141.nii.gz', 'BRATS_261.nii.gz', 'BRATS_230.nii.gz', 'BRATS_096.nii.gz', 'BRATS_180.nii.gz', 'BRATS_044.nii.gz', 'BRATS_344.nii.gz', 'BRATS_062.nii.gz', 'BRATS_076.nii.gz', 'BRATS_353.nii.gz', 'BRATS_245.nii.gz', 'BRATS_227.nii.gz', 'BRATS_143.nii.gz', 'BRATS_461.nii.gz', 'BRATS_262.nii.gz', 'BRATS_435.nii.gz', 'BRATS_392.nii.gz', 'BRATS_458.nii.gz', 'BRATS_374.nii.gz', 'BRATS_253.nii.gz', 'BRATS_310.nii.gz', 'BRATS_229.nii.gz', 'BRATS_342.nii.gz', 'BRATS_086.nii.gz', 'BRATS_279.nii.gz', 'BRATS_138.nii.gz', 'BRATS_004.nii.gz', 'BRATS_099.nii.gz', 'BRATS_038.nii.gz']\n",
            "495\n",
            "\n",
            "Labels Directory Contents:\n",
            "['BRATS_457.nii.gz', 'BRATS_465.nii.gz', 'BRATS_333.nii.gz', 'BRATS_362.nii.gz', 'BRATS_084.nii.gz', 'BRATS_246.nii.gz', 'BRATS_466.nii.gz', 'BRATS_071.nii.gz', 'BRATS_422.nii.gz', 'BRATS_248.nii.gz', 'BRATS_256.nii.gz', 'BRATS_013.nii.gz', 'BRATS_272.nii.gz', 'BRATS_085.nii.gz', 'BRATS_072.nii.gz', 'BRATS_153.nii.gz', 'BRATS_441.nii.gz', 'BRATS_183.nii.gz', 'BRATS_235.nii.gz', 'BRATS_370.nii.gz', 'BRATS_005.nii.gz', 'BRATS_051.nii.gz', 'BRATS_329.nii.gz', 'BRATS_463.nii.gz', 'BRATS_025.nii.gz', 'BRATS_114.nii.gz', 'BRATS_197.nii.gz', 'BRATS_184.nii.gz', 'BRATS_193.nii.gz', 'BRATS_297.nii.gz', 'BRATS_042.nii.gz', 'BRATS_182.nii.gz', 'BRATS_124.nii.gz', 'BRATS_299.nii.gz', 'BRATS_035.nii.gz', 'BRATS_095.nii.gz', 'BRATS_323.nii.gz', 'BRATS_469.nii.gz', 'BRATS_252.nii.gz', 'BRATS_113.nii.gz', 'BRATS_257.nii.gz', 'BRATS_286.nii.gz', 'BRATS_122.nii.gz', 'BRATS_059.nii.gz', 'BRATS_165.nii.gz', 'BRATS_474.nii.gz', 'BRATS_258.nii.gz', 'BRATS_419.nii.gz', 'BRATS_117.nii.gz', 'BRATS_010.nii.gz', 'BRATS_322.nii.gz', 'BRATS_399.nii.gz', 'BRATS_119.nii.gz', 'BRATS_444.nii.gz', 'BRATS_243.nii.gz', 'BRATS_427.nii.gz', 'BRATS_026.nii.gz', 'BRATS_345.nii.gz', 'BRATS_259.nii.gz', 'BRATS_484.nii.gz', 'BRATS_379.nii.gz', 'BRATS_338.nii.gz', 'BRATS_176.nii.gz', 'BRATS_166.nii.gz', 'BRATS_215.nii.gz', 'BRATS_300.nii.gz', 'BRATS_191.nii.gz', 'BRATS_425.nii.gz', 'BRATS_239.nii.gz', 'BRATS_363.nii.gz', 'BRATS_408.nii.gz', 'BRATS_432.nii.gz', 'BRATS_325.nii.gz', 'BRATS_130.nii.gz', 'BRATS_126.nii.gz', 'BRATS_224.nii.gz', 'BRATS_405.nii.gz', 'BRATS_185.nii.gz', 'BRATS_456.nii.gz', 'BRATS_052.nii.gz', 'BRATS_156.nii.gz', 'BRATS_250.nii.gz', 'BRATS_365.nii.gz', 'BRATS_178.nii.gz', 'BRATS_118.nii.gz', 'BRATS_339.nii.gz', 'BRATS_181.nii.gz', 'BRATS_194.nii.gz', 'BRATS_438.nii.gz', 'BRATS_128.nii.gz', 'BRATS_196.nii.gz', 'BRATS_136.nii.gz', 'BRATS_177.nii.gz', 'BRATS_079.nii.gz', 'BRATS_471.nii.gz', 'BRATS_012.nii.gz', 'BRATS_146.nii.gz', 'BRATS_078.nii.gz', 'BRATS_413.nii.gz', 'BRATS_205.nii.gz', 'BRATS_291.nii.gz', 'BRATS_139.nii.gz', 'BRATS_331.nii.gz', 'BRATS_401.nii.gz', 'BRATS_449.nii.gz', 'BRATS_434.nii.gz', 'BRATS_308.nii.gz', 'BRATS_131.nii.gz', 'BRATS_394.nii.gz', 'BRATS_436.nii.gz', 'BRATS_306.nii.gz', 'BRATS_030.nii.gz', 'BRATS_433.nii.gz', 'BRATS_092.nii.gz', 'BRATS_442.nii.gz', 'BRATS_163.nii.gz', 'BRATS_314.nii.gz', 'BRATS_106.nii.gz', 'BRATS_352.nii.gz', 'BRATS_275.nii.gz', 'BRATS_170.nii.gz', 'BRATS_112.nii.gz', 'BRATS_290.nii.gz', 'BRATS_319.nii.gz', 'BRATS_066.nii.gz', 'BRATS_280.nii.gz', 'BRATS_409.nii.gz', 'BRATS_414.nii.gz', 'BRATS_437.nii.gz', 'BRATS_377.nii.gz', 'BRATS_265.nii.gz', 'BRATS_234.nii.gz', 'BRATS_097.nii.gz', 'BRATS_198.nii.gz', 'BRATS_075.nii.gz', 'BRATS_389.nii.gz', 'BRATS_022.nii.gz', 'BRATS_284.nii.gz', 'BRATS_179.nii.gz', 'BRATS_019.nii.gz', 'BRATS_411.nii.gz', 'BRATS_203.nii.gz', 'BRATS_395.nii.gz', 'BRATS_387.nii.gz', 'BRATS_278.nii.gz', 'BRATS_328.nii.gz', 'BRATS_359.nii.gz', 'BRATS_232.nii.gz', 'BRATS_237.nii.gz', 'BRATS_001.nii.gz', 'BRATS_429.nii.gz', 'BRATS_053.nii.gz', 'BRATS_341.nii.gz', 'BRATS_206.nii.gz', 'BRATS_225.nii.gz', 'BRATS_420.nii.gz', 'BRATS_326.nii.gz', 'BRATS_381.nii.gz', 'BRATS_302.nii.gz', 'BRATS_080.nii.gz', 'BRATS_404.nii.gz', 'BRATS_312.nii.gz', 'BRATS_134.nii.gz', 'BRATS_446.nii.gz', 'BRATS_186.nii.gz', 'BRATS_448.nii.gz', 'BRATS_060.nii.gz', 'BRATS_337.nii.gz', 'BRATS_303.nii.gz', 'BRATS_089.nii.gz', 'BRATS_074.nii.gz', 'BRATS_159.nii.gz', 'BRATS_249.nii.gz', 'BRATS_242.nii.gz', 'BRATS_211.nii.gz', 'BRATS_479.nii.gz', 'BRATS_453.nii.gz', 'BRATS_330.nii.gz', 'BRATS_364.nii.gz', 'BRATS_201.nii.gz', 'BRATS_115.nii.gz', 'BRATS_120.nii.gz', 'BRATS_298.nii.gz', 'BRATS_151.nii.gz', 'BRATS_041.nii.gz', 'BRATS_482.nii.gz', 'BRATS_350.nii.gz', 'BRATS_285.nii.gz', 'BRATS_274.nii.gz', 'BRATS_357.nii.gz', 'BRATS_132.nii.gz', 'BRATS_483.nii.gz', 'BRATS_260.nii.gz', 'BRATS_152.nii.gz', 'BRATS_093.nii.gz', 'BRATS_233.nii.gz', 'BRATS_016.nii.gz', 'BRATS_020.nii.gz', 'BRATS_162.nii.gz', 'BRATS_349.nii.gz', 'BRATS_410.nii.gz', 'BRATS_472.nii.gz', 'BRATS_109.nii.gz', 'BRATS_011.nii.gz', 'BRATS_360.nii.gz', 'BRATS_174.nii.gz', 'BRATS_228.nii.gz', 'BRATS_481.nii.gz', 'BRATS_158.nii.gz', 'BRATS_049.nii.gz', 'BRATS_154.nii.gz', 'BRATS_137.nii.gz', 'BRATS_305.nii.gz', 'BRATS_415.nii.gz', 'BRATS_372.nii.gz', 'BRATS_288.nii.gz', 'BRATS_226.nii.gz', 'BRATS_313.nii.gz', 'BRATS_082.nii.gz', 'BRATS_056.nii.gz', 'BRATS_104.nii.gz', 'BRATS_320.nii.gz', 'BRATS_462.nii.gz', 'BRATS_318.nii.gz', 'BRATS_400.nii.gz', 'BRATS_307.nii.gz', 'BRATS_167.nii.gz', 'BRATS_382.nii.gz', 'BRATS_046.nii.gz', 'BRATS_428.nii.gz', 'BRATS_430.nii.gz', 'BRATS_155.nii.gz', 'BRATS_091.nii.gz', 'BRATS_192.nii.gz', 'BRATS_083.nii.gz', 'BRATS_090.nii.gz', 'BRATS_251.nii.gz', 'BRATS_334.nii.gz', 'BRATS_336.nii.gz', 'BRATS_375.nii.gz', 'BRATS_135.nii.gz', 'BRATS_268.nii.gz', 'BRATS_048.nii.gz', 'BRATS_220.nii.gz', 'BRATS_142.nii.gz', 'BRATS_295.nii.gz', 'BRATS_315.nii.gz', 'BRATS_327.nii.gz', 'BRATS_173.nii.gz', 'BRATS_351.nii.gz', 'BRATS_386.nii.gz', 'BRATS_426.nii.gz', 'BRATS_219.nii.gz', 'BRATS_223.nii.gz', 'BRATS_107.nii.gz', 'BRATS_103.nii.gz', 'BRATS_039.nii.gz', 'BRATS_101.nii.gz', 'BRATS_148.nii.gz', 'BRATS_412.nii.gz', 'BRATS_385.nii.gz', 'BRATS_121.nii.gz', 'BRATS_150.nii.gz', 'BRATS_417.nii.gz', 'BRATS_366.nii.gz', 'BRATS_216.nii.gz', 'BRATS_207.nii.gz', 'BRATS_477.nii.gz', 'BRATS_204.nii.gz', 'BRATS_468.nii.gz', 'BRATS_214.nii.gz', 'BRATS_100.nii.gz', 'BRATS_301.nii.gz', 'BRATS_029.nii.gz', '._BRATS_166.nii.gz', 'BRATS_416.nii.gz', 'BRATS_064.nii.gz', 'BRATS_459.nii.gz', 'BRATS_398.nii.gz', 'BRATS_188.nii.gz', 'BRATS_036.nii.gz', 'BRATS_281.nii.gz', 'BRATS_087.nii.gz', 'BRATS_380.nii.gz', 'BRATS_445.nii.gz', 'BRATS_467.nii.gz', 'BRATS_439.nii.gz', 'BRATS_213.nii.gz', 'BRATS_034.nii.gz', 'BRATS_068.nii.gz', 'BRATS_003.nii.gz', 'BRATS_396.nii.gz', 'BRATS_390.nii.gz', 'BRATS_470.nii.gz', 'BRATS_157.nii.gz', 'BRATS_009.nii.gz', 'BRATS_431.nii.gz', 'BRATS_391.nii.gz', 'BRATS_102.nii.gz', 'BRATS_199.nii.gz', 'BRATS_077.nii.gz', 'BRATS_443.nii.gz', 'BRATS_195.nii.gz', 'BRATS_393.nii.gz', 'BRATS_054.nii.gz', 'BRATS_283.nii.gz', 'BRATS_264.nii.gz', 'BRATS_110.nii.gz', 'BRATS_043.nii.gz', 'BRATS_149.nii.gz', 'BRATS_311.nii.gz', 'BRATS_367.nii.gz', 'BRATS_355.nii.gz', 'BRATS_476.nii.gz', 'BRATS_018.nii.gz', 'BRATS_040.nii.gz', 'BRATS_065.nii.gz', 'BRATS_169.nii.gz', 'BRATS_240.nii.gz', 'BRATS_273.nii.gz', 'BRATS_270.nii.gz', 'BRATS_070.nii.gz', 'BRATS_202.nii.gz', 'BRATS_050.nii.gz', 'BRATS_231.nii.gz', 'BRATS_361.nii.gz', 'BRATS_373.nii.gz', 'BRATS_304.nii.gz', 'BRATS_244.nii.gz', 'BRATS_032.nii.gz', 'BRATS_347.nii.gz', 'BRATS_028.nii.gz', 'BRATS_023.nii.gz', 'BRATS_116.nii.gz', 'BRATS_292.nii.gz', 'BRATS_144.nii.gz', 'BRATS_464.nii.gz', 'BRATS_047.nii.gz', 'BRATS_241.nii.gz', 'BRATS_371.nii.gz', 'BRATS_081.nii.gz', 'BRATS_129.nii.gz', 'BRATS_123.nii.gz', 'BRATS_451.nii.gz', 'BRATS_421.nii.gz', 'BRATS_127.nii.gz', 'BRATS_324.nii.gz', 'BRATS_418.nii.gz', 'BRATS_348.nii.gz', 'BRATS_478.nii.gz', 'BRATS_147.nii.gz', 'BRATS_368.nii.gz', 'BRATS_238.nii.gz', 'BRATS_008.nii.gz', 'BRATS_210.nii.gz', 'BRATS_269.nii.gz', 'BRATS_058.nii.gz', 'BRATS_094.nii.gz', 'BRATS_407.nii.gz', 'BRATS_271.nii.gz', 'BRATS_452.nii.gz', 'BRATS_424.nii.gz', 'BRATS_160.nii.gz', 'BRATS_098.nii.gz', 'BRATS_447.nii.gz', 'BRATS_473.nii.gz', 'BRATS_045.nii.gz', 'BRATS_021.nii.gz', 'BRATS_321.nii.gz', 'BRATS_187.nii.gz', 'BRATS_277.nii.gz', 'BRATS_316.nii.gz', 'BRATS_376.nii.gz', 'BRATS_276.nii.gz', 'BRATS_296.nii.gz', 'BRATS_073.nii.gz', 'BRATS_189.nii.gz', 'BRATS_057.nii.gz', 'BRATS_383.nii.gz', 'BRATS_384.nii.gz', 'BRATS_309.nii.gz', 'BRATS_221.nii.gz', 'BRATS_031.nii.gz', 'BRATS_403.nii.gz', 'BRATS_282.nii.gz', 'BRATS_346.nii.gz', 'BRATS_397.nii.gz', 'BRATS_212.nii.gz', 'BRATS_171.nii.gz', 'BRATS_294.nii.gz', 'BRATS_140.nii.gz', 'BRATS_440.nii.gz', 'BRATS_111.nii.gz', 'BRATS_460.nii.gz', 'BRATS_247.nii.gz', 'BRATS_133.nii.gz', 'BRATS_289.nii.gz', 'BRATS_218.nii.gz', 'BRATS_406.nii.gz', 'BRATS_293.nii.gz', 'BRATS_125.nii.gz', 'BRATS_069.nii.gz', 'BRATS_388.nii.gz', 'BRATS_454.nii.gz', 'BRATS_335.nii.gz', 'BRATS_015.nii.gz', 'BRATS_055.nii.gz', 'BRATS_088.nii.gz', 'BRATS_354.nii.gz', 'BRATS_161.nii.gz', 'BRATS_063.nii.gz', 'BRATS_168.nii.gz', 'BRATS_061.nii.gz', 'BRATS_027.nii.gz', 'BRATS_108.nii.gz', 'BRATS_222.nii.gz', 'BRATS_475.nii.gz', 'BRATS_263.nii.gz', 'BRATS_145.nii.gz', 'BRATS_402.nii.gz', 'BRATS_164.nii.gz', 'BRATS_208.nii.gz', 'BRATS_014.nii.gz', 'BRATS_267.nii.gz', 'BRATS_236.nii.gz', 'BRATS_002.nii.gz', 'BRATS_480.nii.gz', 'BRATS_369.nii.gz', 'BRATS_450.nii.gz', 'BRATS_343.nii.gz', 'BRATS_006.nii.gz', 'BRATS_105.nii.gz', 'BRATS_358.nii.gz', 'BRATS_172.nii.gz', 'BRATS_037.nii.gz', 'BRATS_190.nii.gz', 'BRATS_340.nii.gz', 'BRATS_266.nii.gz', 'BRATS_017.nii.gz', 'BRATS_254.nii.gz', 'BRATS_024.nii.gz', 'BRATS_378.nii.gz', 'BRATS_209.nii.gz', 'BRATS_423.nii.gz', 'BRATS_007.nii.gz', 'BRATS_332.nii.gz', 'BRATS_356.nii.gz', 'BRATS_317.nii.gz', 'BRATS_255.nii.gz', 'BRATS_217.nii.gz', 'BRATS_067.nii.gz', 'BRATS_175.nii.gz', 'BRATS_200.nii.gz', 'BRATS_455.nii.gz', 'BRATS_033.nii.gz', 'BRATS_287.nii.gz', 'BRATS_141.nii.gz', 'BRATS_261.nii.gz', 'BRATS_230.nii.gz', 'BRATS_096.nii.gz', 'BRATS_180.nii.gz', 'BRATS_044.nii.gz', 'BRATS_344.nii.gz', 'BRATS_062.nii.gz', 'BRATS_076.nii.gz', 'BRATS_353.nii.gz', 'BRATS_245.nii.gz', 'BRATS_227.nii.gz', 'BRATS_143.nii.gz', 'BRATS_461.nii.gz', 'BRATS_262.nii.gz', 'BRATS_435.nii.gz', 'BRATS_392.nii.gz', 'BRATS_458.nii.gz', 'BRATS_374.nii.gz', 'BRATS_253.nii.gz', 'BRATS_310.nii.gz', 'BRATS_229.nii.gz', 'BRATS_342.nii.gz', 'BRATS_086.nii.gz', 'BRATS_279.nii.gz', 'BRATS_138.nii.gz', 'BRATS_004.nii.gz', 'BRATS_099.nii.gz', 'BRATS_038.nii.gz']\n",
            "485\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define paths to images and labels\n",
        "images_dir = '/content/Task01_BrainTumour/imagesTr'\n",
        "labels_dir = '/content/Task01_BrainTumour/labelsTr'\n",
        "\n",
        "# List the contents of images and labels directories\n",
        "print(\"Images Directory Contents:\")\n",
        "print(os.listdir(images_dir)[:])  # Display first 5 files\n",
        "print(len(os.listdir(images_dir)))\n",
        "\n",
        "print(\"\\nLabels Directory Contents:\")\n",
        "print(os.listdir(labels_dir)[:])  # Display first 5 files\n",
        "print(len(os.listdir(labels_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzx1fKOG_Jqk"
      },
      "source": [
        "# Exploring the json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_UVYcmerRbZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4691b8c0-d93d-4bd8-d3b7-a301fc37a934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in dataset.json: dict_keys(['name', 'description', 'reference', 'licence', 'release', 'tensorImageSize', 'modality', 'labels', 'numTraining', 'numTest', 'training', 'test'])\n",
            "\n",
            "Key: name\n",
            "BRATS\n",
            "\n",
            "Key: description\n",
            "Gliomas segmentation tumour and oedema in on brain images\n",
            "\n",
            "Key: reference\n",
            "https://www.med.upenn.edu/sbia/brats2017.html\n",
            "\n",
            "Key: licence\n",
            "CC-BY-SA 4.0\n",
            "\n",
            "Key: release\n",
            "2.0 04/05/2018\n",
            "\n",
            "Key: tensorImageSize\n",
            "4D\n",
            "\n",
            "Key: modality\n",
            "{'0': 'FLAIR', '1': 'T1w', '2': 't1gd', '3': 'T2w'}\n",
            "\n",
            "Key: labels\n",
            "{'0': 'background', '1': 'edema', '2': 'non-enhancing tumor', '3': 'enhancing tumour'}\n",
            "\n",
            "Key: numTraining\n",
            "484\n",
            "\n",
            "Key: numTest\n",
            "266\n",
            "\n",
            "Key: training\n",
            "[{'image': './imagesTr/BRATS_457.nii.gz', 'label': './labelsTr/BRATS_457.nii.gz'}, {'image': './imagesTr/BRATS_306.nii.gz', 'label': './labelsTr/BRATS_306.nii.gz'}, {'image': './imagesTr/BRATS_206.nii.gz', 'label': './labelsTr/BRATS_206.nii.gz'}, {'image': './imagesTr/BRATS_449.nii.gz', 'label': './labelsTr/BRATS_449.nii.gz'}, {'image': './imagesTr/BRATS_318.nii.gz', 'label': './labelsTr/BRATS_318.nii.gz'}, {'image': './imagesTr/BRATS_218.nii.gz', 'label': './labelsTr/BRATS_218.nii.gz'}, {'image': './imagesTr/BRATS_434.nii.gz', 'label': './labelsTr/BRATS_434.nii.gz'}, {'image': './imagesTr/BRATS_365.nii.gz', 'label': './labelsTr/BRATS_365.nii.gz'}, {'image': './imagesTr/BRATS_265.nii.gz', 'label': './labelsTr/BRATS_265.nii.gz'}, {'image': './imagesTr/BRATS_214.nii.gz', 'label': './labelsTr/BRATS_214.nii.gz'}, {'image': './imagesTr/BRATS_314.nii.gz', 'label': './labelsTr/BRATS_314.nii.gz'}, {'image': './imagesTr/BRATS_445.nii.gz', 'label': './labelsTr/BRATS_445.nii.gz'}, {'image': './imagesTr/BRATS_269.nii.gz', 'label': './labelsTr/BRATS_269.nii.gz'}, {'image': './imagesTr/BRATS_369.nii.gz', 'label': './labelsTr/BRATS_369.nii.gz'}, {'image': './imagesTr/BRATS_438.nii.gz', 'label': './labelsTr/BRATS_438.nii.gz'}, {'image': './imagesTr/BRATS_277.nii.gz', 'label': './labelsTr/BRATS_277.nii.gz'}, {'image': './imagesTr/BRATS_377.nii.gz', 'label': './labelsTr/BRATS_377.nii.gz'}, {'image': './imagesTr/BRATS_426.nii.gz', 'label': './labelsTr/BRATS_426.nii.gz'}, {'image': './imagesTr/BRATS_095.nii.gz', 'label': './labelsTr/BRATS_095.nii.gz'}, {'image': './imagesTr/BRATS_222.nii.gz', 'label': './labelsTr/BRATS_222.nii.gz'}, {'image': './imagesTr/BRATS_195.nii.gz', 'label': './labelsTr/BRATS_195.nii.gz'}, {'image': './imagesTr/BRATS_473.nii.gz', 'label': './labelsTr/BRATS_473.nii.gz'}, {'image': './imagesTr/BRATS_322.nii.gz', 'label': './labelsTr/BRATS_322.nii.gz'}, {'image': './imagesTr/BRATS_241.nii.gz', 'label': './labelsTr/BRATS_241.nii.gz'}, {'image': './imagesTr/BRATS_410.nii.gz', 'label': './labelsTr/BRATS_410.nii.gz'}, {'image': './imagesTr/BRATS_341.nii.gz', 'label': './labelsTr/BRATS_341.nii.gz'}, {'image': './imagesTr/BRATS_330.nii.gz', 'label': './labelsTr/BRATS_330.nii.gz'}, {'image': './imagesTr/BRATS_461.nii.gz', 'label': './labelsTr/BRATS_461.nii.gz'}, {'image': './imagesTr/BRATS_187.nii.gz', 'label': './labelsTr/BRATS_187.nii.gz'}, {'image': './imagesTr/BRATS_230.nii.gz', 'label': './labelsTr/BRATS_230.nii.gz'}, {'image': './imagesTr/BRATS_087.nii.gz', 'label': './labelsTr/BRATS_087.nii.gz'}, {'image': './imagesTr/BRATS_199.nii.gz', 'label': './labelsTr/BRATS_199.nii.gz'}, {'image': './imagesTr/BRATS_099.nii.gz', 'label': './labelsTr/BRATS_099.nii.gz'}, {'image': './imagesTr/BRATS_353.nii.gz', 'label': './labelsTr/BRATS_353.nii.gz'}, {'image': './imagesTr/BRATS_402.nii.gz', 'label': './labelsTr/BRATS_402.nii.gz'}, {'image': './imagesTr/BRATS_253.nii.gz', 'label': './labelsTr/BRATS_253.nii.gz'}, {'image': './imagesTr/BRATS_384.nii.gz', 'label': './labelsTr/BRATS_384.nii.gz'}, {'image': './imagesTr/BRATS_133.nii.gz', 'label': './labelsTr/BRATS_133.nii.gz'}, {'image': './imagesTr/BRATS_284.nii.gz', 'label': './labelsTr/BRATS_284.nii.gz'}, {'image': './imagesTr/BRATS_033.nii.gz', 'label': './labelsTr/BRATS_033.nii.gz'}, {'image': './imagesTr/BRATS_150.nii.gz', 'label': './labelsTr/BRATS_150.nii.gz'}, {'image': './imagesTr/BRATS_050.nii.gz', 'label': './labelsTr/BRATS_050.nii.gz'}, {'image': './imagesTr/BRATS_021.nii.gz', 'label': './labelsTr/BRATS_021.nii.gz'}, {'image': './imagesTr/BRATS_296.nii.gz', 'label': './labelsTr/BRATS_296.nii.gz'}, {'image': './imagesTr/BRATS_121.nii.gz', 'label': './labelsTr/BRATS_121.nii.gz'}, {'image': './imagesTr/BRATS_396.nii.gz', 'label': './labelsTr/BRATS_396.nii.gz'}, {'image': './imagesTr/BRATS_288.nii.gz', 'label': './labelsTr/BRATS_288.nii.gz'}, {'image': './imagesTr/BRATS_388.nii.gz', 'label': './labelsTr/BRATS_388.nii.gz'}, {'image': './imagesTr/BRATS_042.nii.gz', 'label': './labelsTr/BRATS_042.nii.gz'}, {'image': './imagesTr/BRATS_142.nii.gz', 'label': './labelsTr/BRATS_142.nii.gz'}, {'image': './imagesTr/BRATS_017.nii.gz', 'label': './labelsTr/BRATS_017.nii.gz'}, {'image': './imagesTr/BRATS_117.nii.gz', 'label': './labelsTr/BRATS_117.nii.gz'}, {'image': './imagesTr/BRATS_009.nii.gz', 'label': './labelsTr/BRATS_009.nii.gz'}, {'image': './imagesTr/BRATS_109.nii.gz', 'label': './labelsTr/BRATS_109.nii.gz'}, {'image': './imagesTr/BRATS_074.nii.gz', 'label': './labelsTr/BRATS_074.nii.gz'}, {'image': './imagesTr/BRATS_174.nii.gz', 'label': './labelsTr/BRATS_174.nii.gz'}, {'image': './imagesTr/BRATS_105.nii.gz', 'label': './labelsTr/BRATS_105.nii.gz'}, {'image': './imagesTr/BRATS_005.nii.gz', 'label': './labelsTr/BRATS_005.nii.gz'}, {'image': './imagesTr/BRATS_178.nii.gz', 'label': './labelsTr/BRATS_178.nii.gz'}, {'image': './imagesTr/BRATS_078.nii.gz', 'label': './labelsTr/BRATS_078.nii.gz'}, {'image': './imagesTr/BRATS_480.nii.gz', 'label': './labelsTr/BRATS_480.nii.gz'}, {'image': './imagesTr/BRATS_166.nii.gz', 'label': './labelsTr/BRATS_166.nii.gz'}, {'image': './imagesTr/BRATS_066.nii.gz', 'label': './labelsTr/BRATS_066.nii.gz'}, {'image': './imagesTr/BRATS_040.nii.gz', 'label': './labelsTr/BRATS_040.nii.gz'}, {'image': './imagesTr/BRATS_140.nii.gz', 'label': './labelsTr/BRATS_140.nii.gz'}, {'image': './imagesTr/BRATS_023.nii.gz', 'label': './labelsTr/BRATS_023.nii.gz'}, {'image': './imagesTr/BRATS_294.nii.gz', 'label': './labelsTr/BRATS_294.nii.gz'}, {'image': './imagesTr/BRATS_123.nii.gz', 'label': './labelsTr/BRATS_123.nii.gz'}, {'image': './imagesTr/BRATS_394.nii.gz', 'label': './labelsTr/BRATS_394.nii.gz'}, {'image': './imagesTr/BRATS_398.nii.gz', 'label': './labelsTr/BRATS_398.nii.gz'}, {'image': './imagesTr/BRATS_298.nii.gz', 'label': './labelsTr/BRATS_298.nii.gz'}, {'image': './imagesTr/BRATS_152.nii.gz', 'label': './labelsTr/BRATS_152.nii.gz'}, {'image': './imagesTr/BRATS_052.nii.gz', 'label': './labelsTr/BRATS_052.nii.gz'}, {'image': './imagesTr/BRATS_386.nii.gz', 'label': './labelsTr/BRATS_386.nii.gz'}, {'image': './imagesTr/BRATS_131.nii.gz', 'label': './labelsTr/BRATS_131.nii.gz'}, {'image': './imagesTr/BRATS_286.nii.gz', 'label': './labelsTr/BRATS_286.nii.gz'}, {'image': './imagesTr/BRATS_031.nii.gz', 'label': './labelsTr/BRATS_031.nii.gz'}, {'image': './imagesTr/BRATS_119.nii.gz', 'label': './labelsTr/BRATS_119.nii.gz'}, {'image': './imagesTr/BRATS_019.nii.gz', 'label': './labelsTr/BRATS_019.nii.gz'}, {'image': './imagesTr/BRATS_482.nii.gz', 'label': './labelsTr/BRATS_482.nii.gz'}, {'image': './imagesTr/BRATS_164.nii.gz', 'label': './labelsTr/BRATS_164.nii.gz'}, {'image': './imagesTr/BRATS_064.nii.gz', 'label': './labelsTr/BRATS_064.nii.gz'}, {'image': './imagesTr/BRATS_107.nii.gz', 'label': './labelsTr/BRATS_107.nii.gz'}, {'image': './imagesTr/BRATS_007.nii.gz', 'label': './labelsTr/BRATS_007.nii.gz'}, {'image': './imagesTr/BRATS_076.nii.gz', 'label': './labelsTr/BRATS_076.nii.gz'}, {'image': './imagesTr/BRATS_176.nii.gz', 'label': './labelsTr/BRATS_176.nii.gz'}, {'image': './imagesTr/BRATS_015.nii.gz', 'label': './labelsTr/BRATS_015.nii.gz'}, {'image': './imagesTr/BRATS_115.nii.gz', 'label': './labelsTr/BRATS_115.nii.gz'}, {'image': './imagesTr/BRATS_068.nii.gz', 'label': './labelsTr/BRATS_068.nii.gz'}, {'image': './imagesTr/BRATS_168.nii.gz', 'label': './labelsTr/BRATS_168.nii.gz'}, {'image': './imagesTr/BRATS_208.nii.gz', 'label': './labelsTr/BRATS_208.nii.gz'}, {'image': './imagesTr/BRATS_308.nii.gz', 'label': './labelsTr/BRATS_308.nii.gz'}, {'image': './imagesTr/BRATS_459.nii.gz', 'label': './labelsTr/BRATS_459.nii.gz'}, {'image': './imagesTr/BRATS_275.nii.gz', 'label': './labelsTr/BRATS_275.nii.gz'}, {'image': './imagesTr/BRATS_375.nii.gz', 'label': './labelsTr/BRATS_375.nii.gz'}, {'image': './imagesTr/BRATS_424.nii.gz', 'label': './labelsTr/BRATS_424.nii.gz'}, {'image': './imagesTr/BRATS_216.nii.gz', 'label': './labelsTr/BRATS_216.nii.gz'}, {'image': './imagesTr/BRATS_316.nii.gz', 'label': './labelsTr/BRATS_316.nii.gz'}, {'image': './imagesTr/BRATS_447.nii.gz', 'label': './labelsTr/BRATS_447.nii.gz'}, {'image': './imagesTr/BRATS_436.nii.gz', 'label': './labelsTr/BRATS_436.nii.gz'}, {'image': './imagesTr/BRATS_367.nii.gz', 'label': './labelsTr/BRATS_367.nii.gz'}, {'image': './imagesTr/BRATS_267.nii.gz', 'label': './labelsTr/BRATS_267.nii.gz'}, {'image': './imagesTr/BRATS_455.nii.gz', 'label': './labelsTr/BRATS_455.nii.gz'}, {'image': './imagesTr/BRATS_304.nii.gz', 'label': './labelsTr/BRATS_304.nii.gz'}, {'image': './imagesTr/BRATS_204.nii.gz', 'label': './labelsTr/BRATS_204.nii.gz'}, {'image': './imagesTr/BRATS_428.nii.gz', 'label': './labelsTr/BRATS_428.nii.gz'}, {'image': './imagesTr/BRATS_379.nii.gz', 'label': './labelsTr/BRATS_379.nii.gz'}, {'image': './imagesTr/BRATS_279.nii.gz', 'label': './labelsTr/BRATS_279.nii.gz'}, {'image': './imagesTr/BRATS_351.nii.gz', 'label': './labelsTr/BRATS_351.nii.gz'}, {'image': './imagesTr/BRATS_400.nii.gz', 'label': './labelsTr/BRATS_400.nii.gz'}, {'image': './imagesTr/BRATS_251.nii.gz', 'label': './labelsTr/BRATS_251.nii.gz'}, {'image': './imagesTr/BRATS_332.nii.gz', 'label': './labelsTr/BRATS_332.nii.gz'}, {'image': './imagesTr/BRATS_463.nii.gz', 'label': './labelsTr/BRATS_463.nii.gz'}, {'image': './imagesTr/BRATS_185.nii.gz', 'label': './labelsTr/BRATS_185.nii.gz'}, {'image': './imagesTr/BRATS_232.nii.gz', 'label': './labelsTr/BRATS_232.nii.gz'}, {'image': './imagesTr/BRATS_085.nii.gz', 'label': './labelsTr/BRATS_085.nii.gz'}, {'image': './imagesTr/BRATS_089.nii.gz', 'label': './labelsTr/BRATS_089.nii.gz'}, {'image': './imagesTr/BRATS_189.nii.gz', 'label': './labelsTr/BRATS_189.nii.gz'}, {'image': './imagesTr/BRATS_243.nii.gz', 'label': './labelsTr/BRATS_243.nii.gz'}, {'image': './imagesTr/BRATS_412.nii.gz', 'label': './labelsTr/BRATS_412.nii.gz'}, {'image': './imagesTr/BRATS_343.nii.gz', 'label': './labelsTr/BRATS_343.nii.gz'}, {'image': './imagesTr/BRATS_097.nii.gz', 'label': './labelsTr/BRATS_097.nii.gz'}, {'image': './imagesTr/BRATS_220.nii.gz', 'label': './labelsTr/BRATS_220.nii.gz'}, {'image': './imagesTr/BRATS_197.nii.gz', 'label': './labelsTr/BRATS_197.nii.gz'}, {'image': './imagesTr/BRATS_471.nii.gz', 'label': './labelsTr/BRATS_471.nii.gz'}, {'image': './imagesTr/BRATS_320.nii.gz', 'label': './labelsTr/BRATS_320.nii.gz'}, {'image': './imagesTr/BRATS_072.nii.gz', 'label': './labelsTr/BRATS_072.nii.gz'}, {'image': './imagesTr/BRATS_172.nii.gz', 'label': './labelsTr/BRATS_172.nii.gz'}, {'image': './imagesTr/BRATS_011.nii.gz', 'label': './labelsTr/BRATS_011.nii.gz'}, {'image': './imagesTr/BRATS_111.nii.gz', 'label': './labelsTr/BRATS_111.nii.gz'}, {'image': './imagesTr/BRATS_160.nii.gz', 'label': './labelsTr/BRATS_160.nii.gz'}, {'image': './imagesTr/BRATS_060.nii.gz', 'label': './labelsTr/BRATS_060.nii.gz'}, {'image': './imagesTr/BRATS_103.nii.gz', 'label': './labelsTr/BRATS_103.nii.gz'}, {'image': './imagesTr/BRATS_003.nii.gz', 'label': './labelsTr/BRATS_003.nii.gz'}, {'image': './imagesTr/BRATS_156.nii.gz', 'label': './labelsTr/BRATS_156.nii.gz'}, {'image': './imagesTr/BRATS_056.nii.gz', 'label': './labelsTr/BRATS_056.nii.gz'}, {'image': './imagesTr/BRATS_148.nii.gz', 'label': './labelsTr/BRATS_148.nii.gz'}, {'image': './imagesTr/BRATS_048.nii.gz', 'label': './labelsTr/BRATS_048.nii.gz'}, {'image': './imagesTr/BRATS_382.nii.gz', 'label': './labelsTr/BRATS_382.nii.gz'}, {'image': './imagesTr/BRATS_135.nii.gz', 'label': './labelsTr/BRATS_135.nii.gz'}, {'image': './imagesTr/BRATS_282.nii.gz', 'label': './labelsTr/BRATS_282.nii.gz'}, {'image': './imagesTr/BRATS_035.nii.gz', 'label': './labelsTr/BRATS_035.nii.gz'}, {'image': './imagesTr/BRATS_044.nii.gz', 'label': './labelsTr/BRATS_044.nii.gz'}, {'image': './imagesTr/BRATS_144.nii.gz', 'label': './labelsTr/BRATS_144.nii.gz'}, {'image': './imagesTr/BRATS_039.nii.gz', 'label': './labelsTr/BRATS_039.nii.gz'}, {'image': './imagesTr/BRATS_139.nii.gz', 'label': './labelsTr/BRATS_139.nii.gz'}, {'image': './imagesTr/BRATS_027.nii.gz', 'label': './labelsTr/BRATS_027.nii.gz'}, {'image': './imagesTr/BRATS_290.nii.gz', 'label': './labelsTr/BRATS_290.nii.gz'}, {'image': './imagesTr/BRATS_127.nii.gz', 'label': './labelsTr/BRATS_127.nii.gz'}, {'image': './imagesTr/BRATS_390.nii.gz', 'label': './labelsTr/BRATS_390.nii.gz'}, {'image': './imagesTr/BRATS_247.nii.gz', 'label': './labelsTr/BRATS_247.nii.gz'}, {'image': './imagesTr/BRATS_347.nii.gz', 'label': './labelsTr/BRATS_347.nii.gz'}, {'image': './imagesTr/BRATS_416.nii.gz', 'label': './labelsTr/BRATS_416.nii.gz'}, {'image': './imagesTr/BRATS_259.nii.gz', 'label': './labelsTr/BRATS_259.nii.gz'}, {'image': './imagesTr/BRATS_359.nii.gz', 'label': './labelsTr/BRATS_359.nii.gz'}, {'image': './imagesTr/BRATS_408.nii.gz', 'label': './labelsTr/BRATS_408.nii.gz'}, {'image': './imagesTr/BRATS_093.nii.gz', 'label': './labelsTr/BRATS_093.nii.gz'}, {'image': './imagesTr/BRATS_224.nii.gz', 'label': './labelsTr/BRATS_224.nii.gz'}, {'image': './imagesTr/BRATS_193.nii.gz', 'label': './labelsTr/BRATS_193.nii.gz'}, {'image': './imagesTr/BRATS_324.nii.gz', 'label': './labelsTr/BRATS_324.nii.gz'}, {'image': './imagesTr/BRATS_475.nii.gz', 'label': './labelsTr/BRATS_475.nii.gz'}, {'image': './imagesTr/BRATS_404.nii.gz', 'label': './labelsTr/BRATS_404.nii.gz'}, {'image': './imagesTr/BRATS_355.nii.gz', 'label': './labelsTr/BRATS_355.nii.gz'}, {'image': './imagesTr/BRATS_255.nii.gz', 'label': './labelsTr/BRATS_255.nii.gz'}, {'image': './imagesTr/BRATS_479.nii.gz', 'label': './labelsTr/BRATS_479.nii.gz'}, {'image': './imagesTr/BRATS_328.nii.gz', 'label': './labelsTr/BRATS_328.nii.gz'}, {'image': './imagesTr/BRATS_228.nii.gz', 'label': './labelsTr/BRATS_228.nii.gz'}, {'image': './imagesTr/BRATS_467.nii.gz', 'label': './labelsTr/BRATS_467.nii.gz'}, {'image': './imagesTr/BRATS_336.nii.gz', 'label': './labelsTr/BRATS_336.nii.gz'}, {'image': './imagesTr/BRATS_181.nii.gz', 'label': './labelsTr/BRATS_181.nii.gz'}, {'image': './imagesTr/BRATS_236.nii.gz', 'label': './labelsTr/BRATS_236.nii.gz'}, {'image': './imagesTr/BRATS_081.nii.gz', 'label': './labelsTr/BRATS_081.nii.gz'}, {'image': './imagesTr/BRATS_363.nii.gz', 'label': './labelsTr/BRATS_363.nii.gz'}, {'image': './imagesTr/BRATS_432.nii.gz', 'label': './labelsTr/BRATS_432.nii.gz'}, {'image': './imagesTr/BRATS_263.nii.gz', 'label': './labelsTr/BRATS_263.nii.gz'}, {'image': './imagesTr/BRATS_300.nii.gz', 'label': './labelsTr/BRATS_300.nii.gz'}, {'image': './imagesTr/BRATS_451.nii.gz', 'label': './labelsTr/BRATS_451.nii.gz'}, {'image': './imagesTr/BRATS_200.nii.gz', 'label': './labelsTr/BRATS_200.nii.gz'}, {'image': './imagesTr/BRATS_271.nii.gz', 'label': './labelsTr/BRATS_271.nii.gz'}, {'image': './imagesTr/BRATS_420.nii.gz', 'label': './labelsTr/BRATS_420.nii.gz'}, {'image': './imagesTr/BRATS_371.nii.gz', 'label': './labelsTr/BRATS_371.nii.gz'}, {'image': './imagesTr/BRATS_212.nii.gz', 'label': './labelsTr/BRATS_212.nii.gz'}, {'image': './imagesTr/BRATS_443.nii.gz', 'label': './labelsTr/BRATS_443.nii.gz'}, {'image': './imagesTr/BRATS_312.nii.gz', 'label': './labelsTr/BRATS_312.nii.gz'}, {'image': './imagesTr/BRATS_418.nii.gz', 'label': './labelsTr/BRATS_418.nii.gz'}, {'image': './imagesTr/BRATS_349.nii.gz', 'label': './labelsTr/BRATS_349.nii.gz'}, {'image': './imagesTr/BRATS_249.nii.gz', 'label': './labelsTr/BRATS_249.nii.gz'}, {'image': './imagesTr/BRATS_465.nii.gz', 'label': './labelsTr/BRATS_465.nii.gz'}, {'image': './imagesTr/BRATS_334.nii.gz', 'label': './labelsTr/BRATS_334.nii.gz'}, {'image': './imagesTr/BRATS_183.nii.gz', 'label': './labelsTr/BRATS_183.nii.gz'}, {'image': './imagesTr/BRATS_234.nii.gz', 'label': './labelsTr/BRATS_234.nii.gz'}, {'image': './imagesTr/BRATS_083.nii.gz', 'label': './labelsTr/BRATS_083.nii.gz'}, {'image': './imagesTr/BRATS_406.nii.gz', 'label': './labelsTr/BRATS_406.nii.gz'}, {'image': './imagesTr/BRATS_357.nii.gz', 'label': './labelsTr/BRATS_357.nii.gz'}, {'image': './imagesTr/BRATS_257.nii.gz', 'label': './labelsTr/BRATS_257.nii.gz'}, {'image': './imagesTr/BRATS_091.nii.gz', 'label': './labelsTr/BRATS_091.nii.gz'}, {'image': './imagesTr/BRATS_226.nii.gz', 'label': './labelsTr/BRATS_226.nii.gz'}, {'image': './imagesTr/BRATS_191.nii.gz', 'label': './labelsTr/BRATS_191.nii.gz'}, {'image': './imagesTr/BRATS_326.nii.gz', 'label': './labelsTr/BRATS_326.nii.gz'}, {'image': './imagesTr/BRATS_477.nii.gz', 'label': './labelsTr/BRATS_477.nii.gz'}, {'image': './imagesTr/BRATS_245.nii.gz', 'label': './labelsTr/BRATS_245.nii.gz'}, {'image': './imagesTr/BRATS_345.nii.gz', 'label': './labelsTr/BRATS_345.nii.gz'}, {'image': './imagesTr/BRATS_414.nii.gz', 'label': './labelsTr/BRATS_414.nii.gz'}, {'image': './imagesTr/BRATS_238.nii.gz', 'label': './labelsTr/BRATS_238.nii.gz'}, {'image': './imagesTr/BRATS_338.nii.gz', 'label': './labelsTr/BRATS_338.nii.gz'}, {'image': './imagesTr/BRATS_469.nii.gz', 'label': './labelsTr/BRATS_469.nii.gz'}, {'image': './imagesTr/BRATS_210.nii.gz', 'label': './labelsTr/BRATS_210.nii.gz'}, {'image': './imagesTr/BRATS_441.nii.gz', 'label': './labelsTr/BRATS_441.nii.gz'}, {'image': './imagesTr/BRATS_310.nii.gz', 'label': './labelsTr/BRATS_310.nii.gz'}, {'image': './imagesTr/BRATS_273.nii.gz', 'label': './labelsTr/BRATS_273.nii.gz'}, {'image': './imagesTr/BRATS_422.nii.gz', 'label': './labelsTr/BRATS_422.nii.gz'}, {'image': './imagesTr/BRATS_373.nii.gz', 'label': './labelsTr/BRATS_373.nii.gz'}, {'image': './imagesTr/BRATS_302.nii.gz', 'label': './labelsTr/BRATS_302.nii.gz'}, {'image': './imagesTr/BRATS_453.nii.gz', 'label': './labelsTr/BRATS_453.nii.gz'}, {'image': './imagesTr/BRATS_202.nii.gz', 'label': './labelsTr/BRATS_202.nii.gz'}, {'image': './imagesTr/BRATS_361.nii.gz', 'label': './labelsTr/BRATS_361.nii.gz'}, {'image': './imagesTr/BRATS_430.nii.gz', 'label': './labelsTr/BRATS_430.nii.gz'}, {'image': './imagesTr/BRATS_261.nii.gz', 'label': './labelsTr/BRATS_261.nii.gz'}, {'image': './imagesTr/BRATS_101.nii.gz', 'label': './labelsTr/BRATS_101.nii.gz'}, {'image': './imagesTr/BRATS_001.nii.gz', 'label': './labelsTr/BRATS_001.nii.gz'}, {'image': './imagesTr/BRATS_484.nii.gz', 'label': './labelsTr/BRATS_484.nii.gz'}, {'image': './imagesTr/BRATS_162.nii.gz', 'label': './labelsTr/BRATS_162.nii.gz'}, {'image': './imagesTr/BRATS_062.nii.gz', 'label': './labelsTr/BRATS_062.nii.gz'}, {'image': './imagesTr/BRATS_013.nii.gz', 'label': './labelsTr/BRATS_013.nii.gz'}, {'image': './imagesTr/BRATS_113.nii.gz', 'label': './labelsTr/BRATS_113.nii.gz'}, {'image': './imagesTr/BRATS_070.nii.gz', 'label': './labelsTr/BRATS_070.nii.gz'}, {'image': './imagesTr/BRATS_170.nii.gz', 'label': './labelsTr/BRATS_170.nii.gz'}, {'image': './imagesTr/BRATS_058.nii.gz', 'label': './labelsTr/BRATS_058.nii.gz'}, {'image': './imagesTr/BRATS_158.nii.gz', 'label': './labelsTr/BRATS_158.nii.gz'}, {'image': './imagesTr/BRATS_025.nii.gz', 'label': './labelsTr/BRATS_025.nii.gz'}, {'image': './imagesTr/BRATS_292.nii.gz', 'label': './labelsTr/BRATS_292.nii.gz'}, {'image': './imagesTr/BRATS_125.nii.gz', 'label': './labelsTr/BRATS_125.nii.gz'}, {'image': './imagesTr/BRATS_392.nii.gz', 'label': './labelsTr/BRATS_392.nii.gz'}, {'image': './imagesTr/BRATS_046.nii.gz', 'label': './labelsTr/BRATS_046.nii.gz'}, {'image': './imagesTr/BRATS_146.nii.gz', 'label': './labelsTr/BRATS_146.nii.gz'}, {'image': './imagesTr/BRATS_380.nii.gz', 'label': './labelsTr/BRATS_380.nii.gz'}, {'image': './imagesTr/BRATS_137.nii.gz', 'label': './labelsTr/BRATS_137.nii.gz'}, {'image': './imagesTr/BRATS_280.nii.gz', 'label': './labelsTr/BRATS_280.nii.gz'}, {'image': './imagesTr/BRATS_037.nii.gz', 'label': './labelsTr/BRATS_037.nii.gz'}, {'image': './imagesTr/BRATS_154.nii.gz', 'label': './labelsTr/BRATS_154.nii.gz'}, {'image': './imagesTr/BRATS_054.nii.gz', 'label': './labelsTr/BRATS_054.nii.gz'}, {'image': './imagesTr/BRATS_129.nii.gz', 'label': './labelsTr/BRATS_129.nii.gz'}, {'image': './imagesTr/BRATS_029.nii.gz', 'label': './labelsTr/BRATS_029.nii.gz'}, {'image': './imagesTr/BRATS_175.nii.gz', 'label': './labelsTr/BRATS_175.nii.gz'}, {'image': './imagesTr/BRATS_075.nii.gz', 'label': './labelsTr/BRATS_075.nii.gz'}, {'image': './imagesTr/BRATS_108.nii.gz', 'label': './labelsTr/BRATS_108.nii.gz'}, {'image': './imagesTr/BRATS_008.nii.gz', 'label': './labelsTr/BRATS_008.nii.gz'}, {'image': './imagesTr/BRATS_116.nii.gz', 'label': './labelsTr/BRATS_116.nii.gz'}, {'image': './imagesTr/BRATS_016.nii.gz', 'label': './labelsTr/BRATS_016.nii.gz'}, {'image': './imagesTr/BRATS_067.nii.gz', 'label': './labelsTr/BRATS_067.nii.gz'}, {'image': './imagesTr/BRATS_481.nii.gz', 'label': './labelsTr/BRATS_481.nii.gz'}, {'image': './imagesTr/BRATS_167.nii.gz', 'label': './labelsTr/BRATS_167.nii.gz'}, {'image': './imagesTr/BRATS_079.nii.gz', 'label': './labelsTr/BRATS_079.nii.gz'}, {'image': './imagesTr/BRATS_179.nii.gz', 'label': './labelsTr/BRATS_179.nii.gz'}, {'image': './imagesTr/BRATS_004.nii.gz', 'label': './labelsTr/BRATS_004.nii.gz'}, {'image': './imagesTr/BRATS_104.nii.gz', 'label': './labelsTr/BRATS_104.nii.gz'}, {'image': './imagesTr/BRATS_051.nii.gz', 'label': './labelsTr/BRATS_051.nii.gz'}, {'image': './imagesTr/BRATS_151.nii.gz', 'label': './labelsTr/BRATS_151.nii.gz'}, {'image': './imagesTr/BRATS_285.nii.gz', 'label': './labelsTr/BRATS_285.nii.gz'}, {'image': './imagesTr/BRATS_032.nii.gz', 'label': './labelsTr/BRATS_032.nii.gz'}, {'image': './imagesTr/BRATS_385.nii.gz', 'label': './labelsTr/BRATS_385.nii.gz'}, {'image': './imagesTr/BRATS_132.nii.gz', 'label': './labelsTr/BRATS_132.nii.gz'}, {'image': './imagesTr/BRATS_143.nii.gz', 'label': './labelsTr/BRATS_143.nii.gz'}, {'image': './imagesTr/BRATS_043.nii.gz', 'label': './labelsTr/BRATS_043.nii.gz'}, {'image': './imagesTr/BRATS_389.nii.gz', 'label': './labelsTr/BRATS_389.nii.gz'}, {'image': './imagesTr/BRATS_289.nii.gz', 'label': './labelsTr/BRATS_289.nii.gz'}, {'image': './imagesTr/BRATS_120.nii.gz', 'label': './labelsTr/BRATS_120.nii.gz'}, {'image': './imagesTr/BRATS_397.nii.gz', 'label': './labelsTr/BRATS_397.nii.gz'}, {'image': './imagesTr/BRATS_020.nii.gz', 'label': './labelsTr/BRATS_020.nii.gz'}, {'image': './imagesTr/BRATS_297.nii.gz', 'label': './labelsTr/BRATS_297.nii.gz'}, {'image': './imagesTr/BRATS_411.nii.gz', 'label': './labelsTr/BRATS_411.nii.gz'}, {'image': './imagesTr/BRATS_340.nii.gz', 'label': './labelsTr/BRATS_340.nii.gz'}, {'image': './imagesTr/BRATS_240.nii.gz', 'label': './labelsTr/BRATS_240.nii.gz'}, {'image': './imagesTr/BRATS_194.nii.gz', 'label': './labelsTr/BRATS_194.nii.gz'}, {'image': './imagesTr/BRATS_472.nii.gz', 'label': './labelsTr/BRATS_472.nii.gz'}, {'image': './imagesTr/BRATS_323.nii.gz', 'label': './labelsTr/BRATS_323.nii.gz'}, {'image': './imagesTr/BRATS_094.nii.gz', 'label': './labelsTr/BRATS_094.nii.gz'}, {'image': './imagesTr/BRATS_223.nii.gz', 'label': './labelsTr/BRATS_223.nii.gz'}, {'image': './imagesTr/BRATS_252.nii.gz', 'label': './labelsTr/BRATS_252.nii.gz'}, {'image': './imagesTr/BRATS_352.nii.gz', 'label': './labelsTr/BRATS_352.nii.gz'}, {'image': './imagesTr/BRATS_403.nii.gz', 'label': './labelsTr/BRATS_403.nii.gz'}, {'image': './imagesTr/BRATS_098.nii.gz', 'label': './labelsTr/BRATS_098.nii.gz'}, {'image': './imagesTr/BRATS_198.nii.gz', 'label': './labelsTr/BRATS_198.nii.gz'}, {'image': './imagesTr/BRATS_231.nii.gz', 'label': './labelsTr/BRATS_231.nii.gz'}, {'image': './imagesTr/BRATS_086.nii.gz', 'label': './labelsTr/BRATS_086.nii.gz'}, {'image': './imagesTr/BRATS_331.nii.gz', 'label': './labelsTr/BRATS_331.nii.gz'}, {'image': './imagesTr/BRATS_460.nii.gz', 'label': './labelsTr/BRATS_460.nii.gz'}, {'image': './imagesTr/BRATS_186.nii.gz', 'label': './labelsTr/BRATS_186.nii.gz'}, {'image': './imagesTr/BRATS_264.nii.gz', 'label': './labelsTr/BRATS_264.nii.gz'}, {'image': './imagesTr/BRATS_435.nii.gz', 'label': './labelsTr/BRATS_435.nii.gz'}, {'image': './imagesTr/BRATS_364.nii.gz', 'label': './labelsTr/BRATS_364.nii.gz'}, {'image': './imagesTr/BRATS_219.nii.gz', 'label': './labelsTr/BRATS_219.nii.gz'}, {'image': './imagesTr/BRATS_448.nii.gz', 'label': './labelsTr/BRATS_448.nii.gz'}, {'image': './imagesTr/BRATS_319.nii.gz', 'label': './labelsTr/BRATS_319.nii.gz'}, {'image': './imagesTr/BRATS_207.nii.gz', 'label': './labelsTr/BRATS_207.nii.gz'}, {'image': './imagesTr/BRATS_456.nii.gz', 'label': './labelsTr/BRATS_456.nii.gz'}, {'image': './imagesTr/BRATS_307.nii.gz', 'label': './labelsTr/BRATS_307.nii.gz'}, {'image': './imagesTr/BRATS_376.nii.gz', 'label': './labelsTr/BRATS_376.nii.gz'}, {'image': './imagesTr/BRATS_427.nii.gz', 'label': './labelsTr/BRATS_427.nii.gz'}, {'image': './imagesTr/BRATS_276.nii.gz', 'label': './labelsTr/BRATS_276.nii.gz'}, {'image': './imagesTr/BRATS_368.nii.gz', 'label': './labelsTr/BRATS_368.nii.gz'}, {'image': './imagesTr/BRATS_439.nii.gz', 'label': './labelsTr/BRATS_439.nii.gz'}, {'image': './imagesTr/BRATS_268.nii.gz', 'label': './labelsTr/BRATS_268.nii.gz'}, {'image': './imagesTr/BRATS_315.nii.gz', 'label': './labelsTr/BRATS_315.nii.gz'}, {'image': './imagesTr/BRATS_444.nii.gz', 'label': './labelsTr/BRATS_444.nii.gz'}, {'image': './imagesTr/BRATS_215.nii.gz', 'label': './labelsTr/BRATS_215.nii.gz'}, {'image': './imagesTr/BRATS_233.nii.gz', 'label': './labelsTr/BRATS_233.nii.gz'}, {'image': './imagesTr/BRATS_084.nii.gz', 'label': './labelsTr/BRATS_084.nii.gz'}, {'image': './imagesTr/BRATS_333.nii.gz', 'label': './labelsTr/BRATS_333.nii.gz'}, {'image': './imagesTr/BRATS_462.nii.gz', 'label': './labelsTr/BRATS_462.nii.gz'}, {'image': './imagesTr/BRATS_184.nii.gz', 'label': './labelsTr/BRATS_184.nii.gz'}, {'image': './imagesTr/BRATS_250.nii.gz', 'label': './labelsTr/BRATS_250.nii.gz'}, {'image': './imagesTr/BRATS_350.nii.gz', 'label': './labelsTr/BRATS_350.nii.gz'}, {'image': './imagesTr/BRATS_401.nii.gz', 'label': './labelsTr/BRATS_401.nii.gz'}, {'image': './imagesTr/BRATS_196.nii.gz', 'label': './labelsTr/BRATS_196.nii.gz'}, {'image': './imagesTr/BRATS_470.nii.gz', 'label': './labelsTr/BRATS_470.nii.gz'}, {'image': './imagesTr/BRATS_321.nii.gz', 'label': './labelsTr/BRATS_321.nii.gz'}, {'image': './imagesTr/BRATS_096.nii.gz', 'label': './labelsTr/BRATS_096.nii.gz'}, {'image': './imagesTr/BRATS_221.nii.gz', 'label': './labelsTr/BRATS_221.nii.gz'}, {'image': './imagesTr/BRATS_413.nii.gz', 'label': './labelsTr/BRATS_413.nii.gz'}, {'image': './imagesTr/BRATS_342.nii.gz', 'label': './labelsTr/BRATS_342.nii.gz'}, {'image': './imagesTr/BRATS_242.nii.gz', 'label': './labelsTr/BRATS_242.nii.gz'}, {'image': './imagesTr/BRATS_188.nii.gz', 'label': './labelsTr/BRATS_188.nii.gz'}, {'image': './imagesTr/BRATS_088.nii.gz', 'label': './labelsTr/BRATS_088.nii.gz'}, {'image': './imagesTr/BRATS_317.nii.gz', 'label': './labelsTr/BRATS_317.nii.gz'}, {'image': './imagesTr/BRATS_446.nii.gz', 'label': './labelsTr/BRATS_446.nii.gz'}, {'image': './imagesTr/BRATS_217.nii.gz', 'label': './labelsTr/BRATS_217.nii.gz'}, {'image': './imagesTr/BRATS_374.nii.gz', 'label': './labelsTr/BRATS_374.nii.gz'}, {'image': './imagesTr/BRATS_425.nii.gz', 'label': './labelsTr/BRATS_425.nii.gz'}, {'image': './imagesTr/BRATS_274.nii.gz', 'label': './labelsTr/BRATS_274.nii.gz'}, {'image': './imagesTr/BRATS_309.nii.gz', 'label': './labelsTr/BRATS_309.nii.gz'}, {'image': './imagesTr/BRATS_458.nii.gz', 'label': './labelsTr/BRATS_458.nii.gz'}, {'image': './imagesTr/BRATS_209.nii.gz', 'label': './labelsTr/BRATS_209.nii.gz'}, {'image': './imagesTr/BRATS_278.nii.gz', 'label': './labelsTr/BRATS_278.nii.gz'}, {'image': './imagesTr/BRATS_429.nii.gz', 'label': './labelsTr/BRATS_429.nii.gz'}, {'image': './imagesTr/BRATS_378.nii.gz', 'label': './labelsTr/BRATS_378.nii.gz'}, {'image': './imagesTr/BRATS_205.nii.gz', 'label': './labelsTr/BRATS_205.nii.gz'}, {'image': './imagesTr/BRATS_454.nii.gz', 'label': './labelsTr/BRATS_454.nii.gz'}, {'image': './imagesTr/BRATS_305.nii.gz', 'label': './labelsTr/BRATS_305.nii.gz'}, {'image': './imagesTr/BRATS_266.nii.gz', 'label': './labelsTr/BRATS_266.nii.gz'}, {'image': './imagesTr/BRATS_437.nii.gz', 'label': './labelsTr/BRATS_437.nii.gz'}, {'image': './imagesTr/BRATS_366.nii.gz', 'label': './labelsTr/BRATS_366.nii.gz'}, {'image': './imagesTr/BRATS_006.nii.gz', 'label': './labelsTr/BRATS_006.nii.gz'}, {'image': './imagesTr/BRATS_106.nii.gz', 'label': './labelsTr/BRATS_106.nii.gz'}, {'image': './imagesTr/BRATS_065.nii.gz', 'label': './labelsTr/BRATS_065.nii.gz'}, {'image': './imagesTr/BRATS_483.nii.gz', 'label': './labelsTr/BRATS_483.nii.gz'}, {'image': './imagesTr/BRATS_165.nii.gz', 'label': './labelsTr/BRATS_165.nii.gz'}, {'image': './imagesTr/BRATS_018.nii.gz', 'label': './labelsTr/BRATS_018.nii.gz'}, {'image': './imagesTr/BRATS_118.nii.gz', 'label': './labelsTr/BRATS_118.nii.gz'}, {'image': './imagesTr/BRATS_169.nii.gz', 'label': './labelsTr/BRATS_169.nii.gz'}, {'image': './imagesTr/BRATS_069.nii.gz', 'label': './labelsTr/BRATS_069.nii.gz'}, {'image': './imagesTr/BRATS_114.nii.gz', 'label': './labelsTr/BRATS_114.nii.gz'}, {'image': './imagesTr/BRATS_014.nii.gz', 'label': './labelsTr/BRATS_014.nii.gz'}, {'image': './imagesTr/BRATS_177.nii.gz', 'label': './labelsTr/BRATS_177.nii.gz'}, {'image': './imagesTr/BRATS_077.nii.gz', 'label': './labelsTr/BRATS_077.nii.gz'}, {'image': './imagesTr/BRATS_122.nii.gz', 'label': './labelsTr/BRATS_122.nii.gz'}, {'image': './imagesTr/BRATS_395.nii.gz', 'label': './labelsTr/BRATS_395.nii.gz'}, {'image': './imagesTr/BRATS_022.nii.gz', 'label': './labelsTr/BRATS_022.nii.gz'}, {'image': './imagesTr/BRATS_295.nii.gz', 'label': './labelsTr/BRATS_295.nii.gz'}, {'image': './imagesTr/BRATS_141.nii.gz', 'label': './labelsTr/BRATS_141.nii.gz'}, {'image': './imagesTr/BRATS_041.nii.gz', 'label': './labelsTr/BRATS_041.nii.gz'}, {'image': './imagesTr/BRATS_287.nii.gz', 'label': './labelsTr/BRATS_287.nii.gz'}, {'image': './imagesTr/BRATS_030.nii.gz', 'label': './labelsTr/BRATS_030.nii.gz'}, {'image': './imagesTr/BRATS_387.nii.gz', 'label': './labelsTr/BRATS_387.nii.gz'}, {'image': './imagesTr/BRATS_130.nii.gz', 'label': './labelsTr/BRATS_130.nii.gz'}, {'image': './imagesTr/BRATS_053.nii.gz', 'label': './labelsTr/BRATS_053.nii.gz'}, {'image': './imagesTr/BRATS_153.nii.gz', 'label': './labelsTr/BRATS_153.nii.gz'}, {'image': './imagesTr/BRATS_299.nii.gz', 'label': './labelsTr/BRATS_299.nii.gz'}, {'image': './imagesTr/BRATS_399.nii.gz', 'label': './labelsTr/BRATS_399.nii.gz'}, {'image': './imagesTr/BRATS_201.nii.gz', 'label': './labelsTr/BRATS_201.nii.gz'}, {'image': './imagesTr/BRATS_301.nii.gz', 'label': './labelsTr/BRATS_301.nii.gz'}, {'image': './imagesTr/BRATS_450.nii.gz', 'label': './labelsTr/BRATS_450.nii.gz'}, {'image': './imagesTr/BRATS_262.nii.gz', 'label': './labelsTr/BRATS_262.nii.gz'}, {'image': './imagesTr/BRATS_362.nii.gz', 'label': './labelsTr/BRATS_362.nii.gz'}, {'image': './imagesTr/BRATS_433.nii.gz', 'label': './labelsTr/BRATS_433.nii.gz'}, {'image': './imagesTr/BRATS_442.nii.gz', 'label': './labelsTr/BRATS_442.nii.gz'}, {'image': './imagesTr/BRATS_313.nii.gz', 'label': './labelsTr/BRATS_313.nii.gz'}, {'image': './imagesTr/BRATS_213.nii.gz', 'label': './labelsTr/BRATS_213.nii.gz'}, {'image': './imagesTr/BRATS_421.nii.gz', 'label': './labelsTr/BRATS_421.nii.gz'}, {'image': './imagesTr/BRATS_370.nii.gz', 'label': './labelsTr/BRATS_370.nii.gz'}, {'image': './imagesTr/BRATS_270.nii.gz', 'label': './labelsTr/BRATS_270.nii.gz'}, {'image': './imagesTr/BRATS_192.nii.gz', 'label': './labelsTr/BRATS_192.nii.gz'}, {'image': './imagesTr/BRATS_325.nii.gz', 'label': './labelsTr/BRATS_325.nii.gz'}, {'image': './imagesTr/BRATS_474.nii.gz', 'label': './labelsTr/BRATS_474.nii.gz'}, {'image': './imagesTr/BRATS_092.nii.gz', 'label': './labelsTr/BRATS_092.nii.gz'}, {'image': './imagesTr/BRATS_225.nii.gz', 'label': './labelsTr/BRATS_225.nii.gz'}, {'image': './imagesTr/BRATS_358.nii.gz', 'label': './labelsTr/BRATS_358.nii.gz'}, {'image': './imagesTr/BRATS_409.nii.gz', 'label': './labelsTr/BRATS_409.nii.gz'}, {'image': './imagesTr/BRATS_258.nii.gz', 'label': './labelsTr/BRATS_258.nii.gz'}, {'image': './imagesTr/BRATS_346.nii.gz', 'label': './labelsTr/BRATS_346.nii.gz'}, {'image': './imagesTr/BRATS_417.nii.gz', 'label': './labelsTr/BRATS_417.nii.gz'}, {'image': './imagesTr/BRATS_246.nii.gz', 'label': './labelsTr/BRATS_246.nii.gz'}, {'image': './imagesTr/BRATS_237.nii.gz', 'label': './labelsTr/BRATS_237.nii.gz'}, {'image': './imagesTr/BRATS_080.nii.gz', 'label': './labelsTr/BRATS_080.nii.gz'}, {'image': './imagesTr/BRATS_466.nii.gz', 'label': './labelsTr/BRATS_466.nii.gz'}, {'image': './imagesTr/BRATS_337.nii.gz', 'label': './labelsTr/BRATS_337.nii.gz'}, {'image': './imagesTr/BRATS_180.nii.gz', 'label': './labelsTr/BRATS_180.nii.gz'}, {'image': './imagesTr/BRATS_229.nii.gz', 'label': './labelsTr/BRATS_229.nii.gz'}, {'image': './imagesTr/BRATS_478.nii.gz', 'label': './labelsTr/BRATS_478.nii.gz'}, {'image': './imagesTr/BRATS_329.nii.gz', 'label': './labelsTr/BRATS_329.nii.gz'}, {'image': './imagesTr/BRATS_254.nii.gz', 'label': './labelsTr/BRATS_254.nii.gz'}, {'image': './imagesTr/BRATS_405.nii.gz', 'label': './labelsTr/BRATS_405.nii.gz'}, {'image': './imagesTr/BRATS_354.nii.gz', 'label': './labelsTr/BRATS_354.nii.gz'}, {'image': './imagesTr/BRATS_283.nii.gz', 'label': './labelsTr/BRATS_283.nii.gz'}, {'image': './imagesTr/BRATS_034.nii.gz', 'label': './labelsTr/BRATS_034.nii.gz'}, {'image': './imagesTr/BRATS_383.nii.gz', 'label': './labelsTr/BRATS_383.nii.gz'}, {'image': './imagesTr/BRATS_134.nii.gz', 'label': './labelsTr/BRATS_134.nii.gz'}, {'image': './imagesTr/BRATS_049.nii.gz', 'label': './labelsTr/BRATS_049.nii.gz'}, {'image': './imagesTr/BRATS_149.nii.gz', 'label': './labelsTr/BRATS_149.nii.gz'}, {'image': './imagesTr/BRATS_057.nii.gz', 'label': './labelsTr/BRATS_057.nii.gz'}, {'image': './imagesTr/BRATS_157.nii.gz', 'label': './labelsTr/BRATS_157.nii.gz'}, {'image': './imagesTr/BRATS_126.nii.gz', 'label': './labelsTr/BRATS_126.nii.gz'}, {'image': './imagesTr/BRATS_391.nii.gz', 'label': './labelsTr/BRATS_391.nii.gz'}, {'image': './imagesTr/BRATS_026.nii.gz', 'label': './labelsTr/BRATS_026.nii.gz'}, {'image': './imagesTr/BRATS_291.nii.gz', 'label': './labelsTr/BRATS_291.nii.gz'}, {'image': './imagesTr/BRATS_138.nii.gz', 'label': './labelsTr/BRATS_138.nii.gz'}, {'image': './imagesTr/BRATS_038.nii.gz', 'label': './labelsTr/BRATS_038.nii.gz'}, {'image': './imagesTr/BRATS_145.nii.gz', 'label': './labelsTr/BRATS_145.nii.gz'}, {'image': './imagesTr/BRATS_045.nii.gz', 'label': './labelsTr/BRATS_045.nii.gz'}, {'image': './imagesTr/BRATS_110.nii.gz', 'label': './labelsTr/BRATS_110.nii.gz'}, {'image': './imagesTr/BRATS_010.nii.gz', 'label': './labelsTr/BRATS_010.nii.gz'}, {'image': './imagesTr/BRATS_173.nii.gz', 'label': './labelsTr/BRATS_173.nii.gz'}, {'image': './imagesTr/BRATS_073.nii.gz', 'label': './labelsTr/BRATS_073.nii.gz'}, {'image': './imagesTr/BRATS_002.nii.gz', 'label': './labelsTr/BRATS_002.nii.gz'}, {'image': './imagesTr/BRATS_102.nii.gz', 'label': './labelsTr/BRATS_102.nii.gz'}, {'image': './imagesTr/BRATS_061.nii.gz', 'label': './labelsTr/BRATS_061.nii.gz'}, {'image': './imagesTr/BRATS_161.nii.gz', 'label': './labelsTr/BRATS_161.nii.gz'}, {'image': './imagesTr/BRATS_147.nii.gz', 'label': './labelsTr/BRATS_147.nii.gz'}, {'image': './imagesTr/BRATS_047.nii.gz', 'label': './labelsTr/BRATS_047.nii.gz'}, {'image': './imagesTr/BRATS_124.nii.gz', 'label': './labelsTr/BRATS_124.nii.gz'}, {'image': './imagesTr/BRATS_393.nii.gz', 'label': './labelsTr/BRATS_393.nii.gz'}, {'image': './imagesTr/BRATS_024.nii.gz', 'label': './labelsTr/BRATS_024.nii.gz'}, {'image': './imagesTr/BRATS_293.nii.gz', 'label': './labelsTr/BRATS_293.nii.gz'}, {'image': './imagesTr/BRATS_159.nii.gz', 'label': './labelsTr/BRATS_159.nii.gz'}, {'image': './imagesTr/BRATS_059.nii.gz', 'label': './labelsTr/BRATS_059.nii.gz'}, {'image': './imagesTr/BRATS_028.nii.gz', 'label': './labelsTr/BRATS_028.nii.gz'}, {'image': './imagesTr/BRATS_128.nii.gz', 'label': './labelsTr/BRATS_128.nii.gz'}, {'image': './imagesTr/BRATS_055.nii.gz', 'label': './labelsTr/BRATS_055.nii.gz'}, {'image': './imagesTr/BRATS_155.nii.gz', 'label': './labelsTr/BRATS_155.nii.gz'}, {'image': './imagesTr/BRATS_281.nii.gz', 'label': './labelsTr/BRATS_281.nii.gz'}, {'image': './imagesTr/BRATS_036.nii.gz', 'label': './labelsTr/BRATS_036.nii.gz'}, {'image': './imagesTr/BRATS_381.nii.gz', 'label': './labelsTr/BRATS_381.nii.gz'}, {'image': './imagesTr/BRATS_136.nii.gz', 'label': './labelsTr/BRATS_136.nii.gz'}, {'image': './imagesTr/BRATS_063.nii.gz', 'label': './labelsTr/BRATS_063.nii.gz'}, {'image': './imagesTr/BRATS_163.nii.gz', 'label': './labelsTr/BRATS_163.nii.gz'}, {'image': './imagesTr/BRATS_100.nii.gz', 'label': './labelsTr/BRATS_100.nii.gz'}, {'image': './imagesTr/BRATS_171.nii.gz', 'label': './labelsTr/BRATS_171.nii.gz'}, {'image': './imagesTr/BRATS_071.nii.gz', 'label': './labelsTr/BRATS_071.nii.gz'}, {'image': './imagesTr/BRATS_112.nii.gz', 'label': './labelsTr/BRATS_112.nii.gz'}, {'image': './imagesTr/BRATS_012.nii.gz', 'label': './labelsTr/BRATS_012.nii.gz'}, {'image': './imagesTr/BRATS_423.nii.gz', 'label': './labelsTr/BRATS_423.nii.gz'}, {'image': './imagesTr/BRATS_372.nii.gz', 'label': './labelsTr/BRATS_372.nii.gz'}, {'image': './imagesTr/BRATS_272.nii.gz', 'label': './labelsTr/BRATS_272.nii.gz'}, {'image': './imagesTr/BRATS_440.nii.gz', 'label': './labelsTr/BRATS_440.nii.gz'}, {'image': './imagesTr/BRATS_311.nii.gz', 'label': './labelsTr/BRATS_311.nii.gz'}, {'image': './imagesTr/BRATS_211.nii.gz', 'label': './labelsTr/BRATS_211.nii.gz'}, {'image': './imagesTr/BRATS_260.nii.gz', 'label': './labelsTr/BRATS_260.nii.gz'}, {'image': './imagesTr/BRATS_360.nii.gz', 'label': './labelsTr/BRATS_360.nii.gz'}, {'image': './imagesTr/BRATS_431.nii.gz', 'label': './labelsTr/BRATS_431.nii.gz'}, {'image': './imagesTr/BRATS_203.nii.gz', 'label': './labelsTr/BRATS_203.nii.gz'}, {'image': './imagesTr/BRATS_303.nii.gz', 'label': './labelsTr/BRATS_303.nii.gz'}, {'image': './imagesTr/BRATS_452.nii.gz', 'label': './labelsTr/BRATS_452.nii.gz'}, {'image': './imagesTr/BRATS_256.nii.gz', 'label': './labelsTr/BRATS_256.nii.gz'}, {'image': './imagesTr/BRATS_407.nii.gz', 'label': './labelsTr/BRATS_407.nii.gz'}, {'image': './imagesTr/BRATS_356.nii.gz', 'label': './labelsTr/BRATS_356.nii.gz'}, {'image': './imagesTr/BRATS_235.nii.gz', 'label': './labelsTr/BRATS_235.nii.gz'}, {'image': './imagesTr/BRATS_082.nii.gz', 'label': './labelsTr/BRATS_082.nii.gz'}, {'image': './imagesTr/BRATS_464.nii.gz', 'label': './labelsTr/BRATS_464.nii.gz'}, {'image': './imagesTr/BRATS_335.nii.gz', 'label': './labelsTr/BRATS_335.nii.gz'}, {'image': './imagesTr/BRATS_182.nii.gz', 'label': './labelsTr/BRATS_182.nii.gz'}, {'image': './imagesTr/BRATS_248.nii.gz', 'label': './labelsTr/BRATS_248.nii.gz'}, {'image': './imagesTr/BRATS_419.nii.gz', 'label': './labelsTr/BRATS_419.nii.gz'}, {'image': './imagesTr/BRATS_348.nii.gz', 'label': './labelsTr/BRATS_348.nii.gz'}, {'image': './imagesTr/BRATS_339.nii.gz', 'label': './labelsTr/BRATS_339.nii.gz'}, {'image': './imagesTr/BRATS_468.nii.gz', 'label': './labelsTr/BRATS_468.nii.gz'}, {'image': './imagesTr/BRATS_239.nii.gz', 'label': './labelsTr/BRATS_239.nii.gz'}, {'image': './imagesTr/BRATS_344.nii.gz', 'label': './labelsTr/BRATS_344.nii.gz'}, {'image': './imagesTr/BRATS_415.nii.gz', 'label': './labelsTr/BRATS_415.nii.gz'}, {'image': './imagesTr/BRATS_244.nii.gz', 'label': './labelsTr/BRATS_244.nii.gz'}, {'image': './imagesTr/BRATS_190.nii.gz', 'label': './labelsTr/BRATS_190.nii.gz'}, {'image': './imagesTr/BRATS_327.nii.gz', 'label': './labelsTr/BRATS_327.nii.gz'}, {'image': './imagesTr/BRATS_476.nii.gz', 'label': './labelsTr/BRATS_476.nii.gz'}, {'image': './imagesTr/BRATS_090.nii.gz', 'label': './labelsTr/BRATS_090.nii.gz'}, {'image': './imagesTr/BRATS_227.nii.gz', 'label': './labelsTr/BRATS_227.nii.gz'}]\n",
            "\n",
            "Key: test\n",
            "['./imagesTs/BRATS_557.nii.gz', './imagesTs/BRATS_549.nii.gz', './imagesTs/BRATS_683.nii.gz', './imagesTs/BRATS_534.nii.gz', './imagesTs/BRATS_545.nii.gz', './imagesTs/BRATS_538.nii.gz', './imagesTs/BRATS_526.nii.gz', './imagesTs/BRATS_691.nii.gz', './imagesTs/BRATS_573.nii.gz', './imagesTs/BRATS_510.nii.gz', './imagesTs/BRATS_561.nii.gz', './imagesTs/BRATS_502.nii.gz', './imagesTs/BRATS_662.nii.gz', './imagesTs/BRATS_601.nii.gz', './imagesTs/BRATS_701.nii.gz', './imagesTs/BRATS_670.nii.gz', './imagesTs/BRATS_713.nii.gz', './imagesTs/BRATS_613.nii.gz', './imagesTs/BRATS_746.nii.gz', './imagesTs/BRATS_646.nii.gz', './imagesTs/BRATS_658.nii.gz', './imagesTs/BRATS_725.nii.gz', './imagesTs/BRATS_592.nii.gz', './imagesTs/BRATS_625.nii.gz', './imagesTs/BRATS_492.nii.gz', './imagesTs/BRATS_654.nii.gz', './imagesTs/BRATS_629.nii.gz', './imagesTs/BRATS_729.nii.gz', './imagesTs/BRATS_637.nii.gz', './imagesTs/BRATS_580.nii.gz', './imagesTs/BRATS_737.nii.gz', './imagesTs/BRATS_711.nii.gz', './imagesTs/BRATS_611.nii.gz', './imagesTs/BRATS_672.nii.gz', './imagesTs/BRATS_603.nii.gz', './imagesTs/BRATS_703.nii.gz', './imagesTs/BRATS_660.nii.gz', './imagesTs/BRATS_648.nii.gz', './imagesTs/BRATS_748.nii.gz', './imagesTs/BRATS_635.nii.gz', './imagesTs/BRATS_582.nii.gz', './imagesTs/BRATS_735.nii.gz', './imagesTs/BRATS_656.nii.gz', './imagesTs/BRATS_727.nii.gz', './imagesTs/BRATS_590.nii.gz', './imagesTs/BRATS_627.nii.gz', './imagesTs/BRATS_490.nii.gz', './imagesTs/BRATS_744.nii.gz', './imagesTs/BRATS_644.nii.gz', './imagesTs/BRATS_739.nii.gz', './imagesTs/BRATS_639.nii.gz', './imagesTs/BRATS_559.nii.gz', './imagesTs/BRATS_524.nii.gz', './imagesTs/BRATS_693.nii.gz', './imagesTs/BRATS_547.nii.gz', './imagesTs/BRATS_681.nii.gz', './imagesTs/BRATS_536.nii.gz', './imagesTs/BRATS_555.nii.gz', './imagesTs/BRATS_528.nii.gz', './imagesTs/BRATS_500.nii.gz', './imagesTs/BRATS_563.nii.gz', './imagesTs/BRATS_512.nii.gz', './imagesTs/BRATS_571.nii.gz', './imagesTs/BRATS_723.nii.gz', './imagesTs/BRATS_594.nii.gz', './imagesTs/BRATS_623.nii.gz', './imagesTs/BRATS_494.nii.gz', './imagesTs/BRATS_740.nii.gz', './imagesTs/BRATS_640.nii.gz', './imagesTs/BRATS_486.nii.gz', './imagesTs/BRATS_631.nii.gz', './imagesTs/BRATS_586.nii.gz', './imagesTs/BRATS_731.nii.gz', './imagesTs/BRATS_498.nii.gz', './imagesTs/BRATS_598.nii.gz', './imagesTs/BRATS_652.nii.gz', './imagesTs/BRATS_607.nii.gz', './imagesTs/BRATS_707.nii.gz', './imagesTs/BRATS_619.nii.gz', './imagesTs/BRATS_719.nii.gz', './imagesTs/BRATS_664.nii.gz', './imagesTs/BRATS_715.nii.gz', './imagesTs/BRATS_615.nii.gz', './imagesTs/BRATS_668.nii.gz', './imagesTs/BRATS_676.nii.gz', './imagesTs/BRATS_516.nii.gz', './imagesTs/BRATS_508.nii.gz', './imagesTs/BRATS_575.nii.gz', './imagesTs/BRATS_504.nii.gz', './imagesTs/BRATS_579.nii.gz', './imagesTs/BRATS_567.nii.gz', './imagesTs/BRATS_685.nii.gz', './imagesTs/BRATS_532.nii.gz', './imagesTs/BRATS_551.nii.gz', './imagesTs/BRATS_520.nii.gz', './imagesTs/BRATS_697.nii.gz', './imagesTs/BRATS_689.nii.gz', './imagesTs/BRATS_543.nii.gz', './imagesTs/BRATS_518.nii.gz', './imagesTs/BRATS_565.nii.gz', './imagesTs/BRATS_506.nii.gz', './imagesTs/BRATS_577.nii.gz', './imagesTs/BRATS_514.nii.gz', './imagesTs/BRATS_569.nii.gz', './imagesTs/BRATS_541.nii.gz', './imagesTs/BRATS_522.nii.gz', './imagesTs/BRATS_695.nii.gz', './imagesTs/BRATS_699.nii.gz', './imagesTs/BRATS_553.nii.gz', './imagesTs/BRATS_687.nii.gz', './imagesTs/BRATS_530.nii.gz', './imagesTs/BRATS_650.nii.gz', './imagesTs/BRATS_750.nii.gz', './imagesTs/BRATS_633.nii.gz', './imagesTs/BRATS_584.nii.gz', './imagesTs/BRATS_733.nii.gz', './imagesTs/BRATS_588.nii.gz', './imagesTs/BRATS_488.nii.gz', './imagesTs/BRATS_742.nii.gz', './imagesTs/BRATS_642.nii.gz', './imagesTs/BRATS_721.nii.gz', './imagesTs/BRATS_596.nii.gz', './imagesTs/BRATS_621.nii.gz', './imagesTs/BRATS_496.nii.gz', './imagesTs/BRATS_709.nii.gz', './imagesTs/BRATS_609.nii.gz', './imagesTs/BRATS_674.nii.gz', './imagesTs/BRATS_717.nii.gz', './imagesTs/BRATS_617.nii.gz', './imagesTs/BRATS_666.nii.gz', './imagesTs/BRATS_605.nii.gz', './imagesTs/BRATS_705.nii.gz', './imagesTs/BRATS_678.nii.gz', './imagesTs/BRATS_624.nii.gz', './imagesTs/BRATS_493.nii.gz', './imagesTs/BRATS_724.nii.gz', './imagesTs/BRATS_593.nii.gz', './imagesTs/BRATS_659.nii.gz', './imagesTs/BRATS_647.nii.gz', './imagesTs/BRATS_747.nii.gz', './imagesTs/BRATS_581.nii.gz', './imagesTs/BRATS_736.nii.gz', './imagesTs/BRATS_636.nii.gz', './imagesTs/BRATS_728.nii.gz', './imagesTs/BRATS_628.nii.gz', './imagesTs/BRATS_655.nii.gz', './imagesTs/BRATS_700.nii.gz', './imagesTs/BRATS_600.nii.gz', './imagesTs/BRATS_663.nii.gz', './imagesTs/BRATS_612.nii.gz', './imagesTs/BRATS_712.nii.gz', './imagesTs/BRATS_671.nii.gz', './imagesTs/BRATS_511.nii.gz', './imagesTs/BRATS_572.nii.gz', './imagesTs/BRATS_503.nii.gz', './imagesTs/BRATS_560.nii.gz', './imagesTs/BRATS_535.nii.gz', './imagesTs/BRATS_682.nii.gz', './imagesTs/BRATS_548.nii.gz', './imagesTs/BRATS_556.nii.gz', './imagesTs/BRATS_690.nii.gz', './imagesTs/BRATS_527.nii.gz', './imagesTs/BRATS_539.nii.gz', './imagesTs/BRATS_544.nii.gz', './imagesTs/BRATS_562.nii.gz', './imagesTs/BRATS_501.nii.gz', './imagesTs/BRATS_570.nii.gz', './imagesTs/BRATS_513.nii.gz', './imagesTs/BRATS_546.nii.gz', './imagesTs/BRATS_692.nii.gz', './imagesTs/BRATS_525.nii.gz', './imagesTs/BRATS_558.nii.gz', './imagesTs/BRATS_529.nii.gz', './imagesTs/BRATS_554.nii.gz', './imagesTs/BRATS_537.nii.gz', './imagesTs/BRATS_680.nii.gz', './imagesTs/BRATS_657.nii.gz', './imagesTs/BRATS_583.nii.gz', './imagesTs/BRATS_734.nii.gz', './imagesTs/BRATS_634.nii.gz', './imagesTs/BRATS_749.nii.gz', './imagesTs/BRATS_649.nii.gz', './imagesTs/BRATS_638.nii.gz', './imagesTs/BRATS_738.nii.gz', './imagesTs/BRATS_645.nii.gz', './imagesTs/BRATS_745.nii.gz', './imagesTs/BRATS_626.nii.gz', './imagesTs/BRATS_491.nii.gz', './imagesTs/BRATS_726.nii.gz', './imagesTs/BRATS_591.nii.gz', './imagesTs/BRATS_673.nii.gz', './imagesTs/BRATS_610.nii.gz', './imagesTs/BRATS_710.nii.gz', './imagesTs/BRATS_661.nii.gz', './imagesTs/BRATS_702.nii.gz', './imagesTs/BRATS_602.nii.gz', './imagesTs/BRATS_550.nii.gz', './imagesTs/BRATS_533.nii.gz', './imagesTs/BRATS_684.nii.gz', './imagesTs/BRATS_542.nii.gz', './imagesTs/BRATS_688.nii.gz', './imagesTs/BRATS_696.nii.gz', './imagesTs/BRATS_521.nii.gz', './imagesTs/BRATS_574.nii.gz', './imagesTs/BRATS_509.nii.gz', './imagesTs/BRATS_517.nii.gz', './imagesTs/BRATS_566.nii.gz', './imagesTs/BRATS_578.nii.gz', './imagesTs/BRATS_505.nii.gz', './imagesTs/BRATS_665.nii.gz', './imagesTs/BRATS_718.nii.gz', './imagesTs/BRATS_618.nii.gz', './imagesTs/BRATS_706.nii.gz', './imagesTs/BRATS_606.nii.gz', './imagesTs/BRATS_677.nii.gz', './imagesTs/BRATS_669.nii.gz', './imagesTs/BRATS_614.nii.gz', './imagesTs/BRATS_714.nii.gz', './imagesTs/BRATS_641.nii.gz', './imagesTs/BRATS_741.nii.gz', './imagesTs/BRATS_622.nii.gz', './imagesTs/BRATS_495.nii.gz', './imagesTs/BRATS_722.nii.gz', './imagesTs/BRATS_595.nii.gz', './imagesTs/BRATS_653.nii.gz', './imagesTs/BRATS_599.nii.gz', './imagesTs/BRATS_499.nii.gz', './imagesTs/BRATS_587.nii.gz', './imagesTs/BRATS_730.nii.gz', './imagesTs/BRATS_487.nii.gz', './imagesTs/BRATS_630.nii.gz', './imagesTs/BRATS_616.nii.gz', './imagesTs/BRATS_716.nii.gz', './imagesTs/BRATS_675.nii.gz', './imagesTs/BRATS_608.nii.gz', './imagesTs/BRATS_708.nii.gz', './imagesTs/BRATS_679.nii.gz', './imagesTs/BRATS_704.nii.gz', './imagesTs/BRATS_604.nii.gz', './imagesTs/BRATS_667.nii.gz', './imagesTs/BRATS_585.nii.gz', './imagesTs/BRATS_732.nii.gz', './imagesTs/BRATS_485.nii.gz', './imagesTs/BRATS_632.nii.gz', './imagesTs/BRATS_651.nii.gz', './imagesTs/BRATS_620.nii.gz', './imagesTs/BRATS_497.nii.gz', './imagesTs/BRATS_720.nii.gz', './imagesTs/BRATS_597.nii.gz', './imagesTs/BRATS_643.nii.gz', './imagesTs/BRATS_743.nii.gz', './imagesTs/BRATS_489.nii.gz', './imagesTs/BRATS_589.nii.gz', './imagesTs/BRATS_694.nii.gz', './imagesTs/BRATS_523.nii.gz', './imagesTs/BRATS_540.nii.gz', './imagesTs/BRATS_531.nii.gz', './imagesTs/BRATS_686.nii.gz', './imagesTs/BRATS_552.nii.gz', './imagesTs/BRATS_698.nii.gz', './imagesTs/BRATS_507.nii.gz', './imagesTs/BRATS_564.nii.gz', './imagesTs/BRATS_519.nii.gz', './imagesTs/BRATS_568.nii.gz', './imagesTs/BRATS_515.nii.gz', './imagesTs/BRATS_576.nii.gz']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "base_dir = '/content/Task01_BrainTumour'\n",
        "\n",
        "\n",
        "# Define the path to dataset.json\n",
        "dataset_json_path = '/content/Task01_BrainTumour/dataset.json'\n",
        "\n",
        "# Load dataset.json\n",
        "with open(dataset_json_path, 'r') as f:\n",
        "    dataset_info = json.load(f)\n",
        "\n",
        "# Display the keys in dataset.json\n",
        "print(\"Keys in dataset.json:\", dataset_info.keys())\n",
        "\n",
        "# Explore the content under each key\n",
        "for key in dataset_info:\n",
        "    print(f\"\\nKey: {key}\")\n",
        "    print(dataset_info[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQIltKnf_2yZ"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EqTyU6h8_MVy"
      },
      "outputs": [],
      "source": [
        "from monai.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the base directory where the dataset is extracted\n",
        "base_dir = '/content/Task01_BrainTumour'  # Ensure this matches your directory name\n",
        "\n",
        "# Paths to subdirectories\n",
        "images_tr_dir = os.path.join(base_dir, 'imagesTr')\n",
        "labels_tr_dir = os.path.join(base_dir, 'labelsTr')\n",
        "images_ts_dir = os.path.join(base_dir, 'imagesTs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vsUWsy30YPaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5215b1bc-1aaf-43cf-9116-302a08fa5708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in dataset.json: dict_keys(['name', 'description', 'reference', 'licence', 'release', 'tensorImageSize', 'modality', 'labels', 'numTraining', 'numTest', 'training', 'test'])\n",
            "\n",
            "Sample Training Entries:\n",
            "{'image': './imagesTr/BRATS_457.nii.gz', 'label': './labelsTr/BRATS_457.nii.gz'}\n",
            "{'image': './imagesTr/BRATS_306.nii.gz', 'label': './labelsTr/BRATS_306.nii.gz'}\n",
            "{'image': './imagesTr/BRATS_206.nii.gz', 'label': './labelsTr/BRATS_206.nii.gz'}\n",
            "{'image': './imagesTr/BRATS_449.nii.gz', 'label': './labelsTr/BRATS_449.nii.gz'}\n",
            "{'image': './imagesTr/BRATS_318.nii.gz', 'label': './labelsTr/BRATS_318.nii.gz'}\n"
          ]
        }
      ],
      "source": [
        "# Path to dataset.json\n",
        "dataset_json_path = os.path.join(base_dir, 'dataset.json')\n",
        "\n",
        "# Load dataset.json\n",
        "with open(dataset_json_path, 'r') as f:\n",
        "    dataset_info = json.load(f)\n",
        "\n",
        "# Inspect keys and sample entries\n",
        "print(\"Keys in dataset.json:\", dataset_info.keys())\n",
        "print(\"\\nSample Training Entries:\")\n",
        "for entry in dataset_info['training'][:5]:\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk7KN4W9Ycx8"
      },
      "source": [
        "# Filtering out hidden files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RJ_0qvg2Yf5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1463ee-9243-4211-b804-8b513e072824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images (filtered): 484\n",
            "Total labels (filtered): 484\n"
          ]
        }
      ],
      "source": [
        "def filter_hidden_files(file_list):\n",
        "    return [file for file in file_list if not file.startswith('._')]\n",
        "\n",
        "# List and filter image and label files\n",
        "all_images = filter_hidden_files(os.listdir(images_tr_dir))\n",
        "all_labels = filter_hidden_files(os.listdir(labels_tr_dir))\n",
        "\n",
        "print(f\"Total images (filtered): {len(all_images)}\")\n",
        "print(f\"Total labels (filtered): {len(all_labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qOa7jrWBYjZa"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "def make_abs_paths(file_list, base_dir):\n",
        "    \"\"\"\n",
        "    Convert relative paths to absolute paths for image-label pairs.\n",
        "\n",
        "    Args:\n",
        "        file_list (list): List of dictionaries with 'image' and 'label' keys.\n",
        "        base_dir (str): Base directory path.\n",
        "\n",
        "    Returns:\n",
        "        list: List of dictionaries with absolute 'image' and 'label' paths.\n",
        "    \"\"\"\n",
        "    abs_files = []\n",
        "    missing_files = []\n",
        "    for item in file_list:\n",
        "        try:\n",
        "            rel_image = item['image'].replace('./', '').strip()\n",
        "            rel_label = item['label'].replace('./', '').strip()\n",
        "        except TypeError:\n",
        "            # If item is not a dict, log and skip\n",
        "            logging.error(f\"Invalid item format (expected dict): {item}\")\n",
        "            continue\n",
        "\n",
        "        # Construct absolute paths\n",
        "        abs_image = os.path.join(base_dir, rel_image)\n",
        "        abs_label = os.path.join(base_dir, rel_label)\n",
        "\n",
        "        # Handle labels without '_seg' suffix if necessary\n",
        "        if not os.path.exists(abs_label):\n",
        "            # Attempt to find label without '_seg'\n",
        "            alt_abs_label = abs_label.replace('_seg', '')\n",
        "            if os.path.exists(alt_abs_label):\n",
        "                abs_label = alt_abs_label\n",
        "                print(f\"Adjusted label path for {abs_image} to {abs_label}\")\n",
        "            else:\n",
        "                print(f\"Label file does not exist for {abs_image}: {abs_label}\")\n",
        "                missing_files.append(abs_image)\n",
        "                continue  # Skip this pair\n",
        "\n",
        "        # Check if image exists\n",
        "        if not os.path.exists(abs_image):\n",
        "            print(f\"Image file does not exist: {abs_image}\")\n",
        "            missing_files.append(abs_image)\n",
        "            continue  # Skip this pair\n",
        "\n",
        "        # Append to the list if both files exist\n",
        "        abs_files.append({'image': abs_image, 'label': abs_label})\n",
        "\n",
        "    if missing_files:\n",
        "        print(f\"\\nTotal missing files: {len(missing_files)}\")\n",
        "        for file in missing_files:\n",
        "            print(f\"Missing: {file}\")\n",
        "    else:\n",
        "        print(\"\\nAll image-label pairs are present.\")\n",
        "\n",
        "    return abs_files\n",
        "\n",
        "def make_image_paths(file_list, base_dir):\n",
        "    \"\"\"\n",
        "    Convert relative paths to absolute paths for images without labels.\n",
        "\n",
        "    Args:\n",
        "        file_list (list): List of image filenames or relative paths (strings).\n",
        "        base_dir (str): Base directory path.\n",
        "\n",
        "    Returns:\n",
        "        list: List of dictionaries with absolute 'image' paths.\n",
        "    \"\"\"\n",
        "    abs_files = []\n",
        "    missing_files = []\n",
        "    for filename in file_list:\n",
        "        if not isinstance(filename, str):\n",
        "            logging.error(f\"Invalid filename format (expected string): {filename}\")\n",
        "            continue\n",
        "\n",
        "        # Remove any leading './' from the filename\n",
        "        rel_image = filename.replace('./', '').strip()\n",
        "\n",
        "        # Construct the absolute path without adding 'imagesTs' again\n",
        "        abs_image = os.path.join(base_dir, rel_image)\n",
        "\n",
        "        # Check if the image file exists\n",
        "        if not os.path.exists(abs_image):\n",
        "            print(f\"Image file does not exist: {abs_image}\")\n",
        "            missing_files.append(abs_image)\n",
        "            continue  # Skip this file\n",
        "\n",
        "        # Append to the list if the file exists\n",
        "        abs_files.append({'image': abs_image})\n",
        "\n",
        "    if missing_files:\n",
        "        print(f\"\\nTotal missing test files: {len(missing_files)}\")\n",
        "        for file in missing_files:\n",
        "            print(f\"Missing: {file}\")\n",
        "    else:\n",
        "        print(\"\\nAll test image files are present.\")\n",
        "\n",
        "    return abs_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GgpHD33WZH8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ee50fd-7298-4d4f-816e-790c52011f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All image-label pairs are present.\n",
            "\n",
            "All test image files are present.\n",
            "\n",
            "Number of training samples after path conversion: 484\n",
            "Number of test samples after path conversion: 266\n"
          ]
        }
      ],
      "source": [
        "# Apply the function to training set\n",
        "train_files = make_abs_paths(dataset_info.get('training', []), base_dir)\n",
        "\n",
        "# Apply the function to test set\n",
        "test_files = make_image_paths(dataset_info.get('test', []), base_dir)\n",
        "\n",
        "print(f\"\\nNumber of training samples after path conversion: {len(train_files)}\")\n",
        "print(f\"Number of test samples after path conversion: {len(test_files)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlvdjnbVAE2L"
      },
      "source": [
        "# Splitting Training data into training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "J8rb1hnd__yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4b855c-0556-4cc0-9f07-381a50685a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples after split: 387\n",
            "Number of validation samples: 97\n"
          ]
        }
      ],
      "source": [
        "# Perform an 80-20 split for training and validation\n",
        "train_files, val_files = train_test_split(train_files, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Number of training samples after split: {len(train_files)}\")\n",
        "print(f\"Number of validation samples: {len(val_files)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE84as0uAVTn"
      },
      "source": [
        "# Training Transforms (With Augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_labels(x):\n",
        "    # Map label 4 to 3\n",
        "    # This assumes you are working with BraTS labels\n",
        "    x[x == 4] = 3\n",
        "    return x"
      ],
      "metadata": {
        "id": "nIN-uocFyLbq"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "    NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
        "    Lambdad(keys=[\"label\"], func=map_labels),\n",
        "\n",
        "    # Perform data augmentation that might change shape\n",
        "    RandFlipd(keys=[\"image\", \"label\"], spatial_axis=0, prob=0.5),\n",
        "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(0, 2)),\n",
        "\n",
        "    # Now perform cropping to ensure consistent size\n",
        "    RandCropByPosNegLabeld(\n",
        "        keys=[\"image\", \"label\"],\n",
        "        label_key=\"label\",\n",
        "        spatial_size=(128, 128, 64),\n",
        "        pos=1,\n",
        "        neg=1,\n",
        "        num_samples=2,\n",
        "        image_key=\"image\",\n",
        "        image_threshold=0,\n",
        "    ),\n",
        "\n",
        "    # Final step: ensure that no matter what, the result is (128,128,64).\n",
        "    ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=(128, 128, 64)),\n",
        "\n",
        "    EnsureTyped(keys=[\"image\", \"label\"], dtype=torch.float32),\n",
        "])\n",
        "\n",
        "val_transforms = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "    NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
        "    Lambdad(keys=[\"label\"], func=map_labels),\n",
        "\n",
        "    # Validation might not need augmentation, but ensure uniform shape\n",
        "    ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=(128, 128, 64)),\n",
        "\n",
        "    EnsureTyped(keys=[\"image\", \"label\"], dtype=torch.float32),\n",
        "])"
      ],
      "metadata": {
        "id": "BUEsVufbySxD"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5yCTrHAaANHO"
      },
      "outputs": [],
      "source": [
        "# train_transforms = Compose([\n",
        "#     LoadImaged(keys=[\"image\", \"label\"]),\n",
        "#     EnsureChannelFirstd(keys=[\"image\", \"label\"]),  # Adds channel dimension if missing\n",
        "#     Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "#     Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "#     ScaleIntensityRanged(\n",
        "#         keys=[\"image\"],\n",
        "#         a_min=-175,\n",
        "#         a_max=250,\n",
        "#         b_min=0.0,\n",
        "#         b_max=1.0,\n",
        "#         clip=True,\n",
        "#     ),\n",
        "#     CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "#     RandCropByPosNegLabeld(\n",
        "#         keys=[\"image\", \"label\"],\n",
        "#         label_key=\"label\",\n",
        "#         spatial_size=(64,64,64),\n",
        "#         pos=1,\n",
        "#         neg=1,\n",
        "#         num_samples=4,\n",
        "#         image_key=\"image\",\n",
        "#         image_threshold=0,\n",
        "#     ),\n",
        "#     RandFlipd(keys=[\"image\", \"label\"], spatial_axis=0, prob=0.5),\n",
        "#     RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(0, 2)),\n",
        "#     EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "# ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXobpiZ_AgLu"
      },
      "source": [
        "# Validation Transform (Without Augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dkRTqFmJAe5O"
      },
      "outputs": [],
      "source": [
        "# from monai.transforms import ResizeWithPadOrCropd\n",
        "\n",
        "# val_transforms = Compose([\n",
        "#     LoadImaged(keys=[\"image\", \"label\"]),\n",
        "#     EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "#     Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "#     Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "#     ScaleIntensityRanged(\n",
        "#         keys=[\"image\"],\n",
        "#         a_min=-175,\n",
        "#         a_max=250,\n",
        "#         b_min=0.0,\n",
        "#         b_max=1.0,\n",
        "#         clip=True,\n",
        "#     ),\n",
        "#     CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "#     ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=(64,64,64)),\n",
        "#     EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "# ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygbipoP7BIgi"
      },
      "source": [
        "# Creating MONAI Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "anCmyUWrA5rb"
      },
      "outputs": [],
      "source": [
        "from monai.data import Dataset as MonaiDataset\n",
        "\n",
        "train_ds = MonaiDataset(data=train_files, transform=train_transforms)\n",
        "val_ds = MonaiDataset(data=val_files, transform=val_transforms)\n",
        "\n",
        "# # Create Datasets and DataLoaders\n",
        "# train_ds = Dataset(data=train_files, transform=train_transforms)\n",
        "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
        "\n",
        "# Define DataLoader parameters optimized for Colab Pro's T4 GPU\n",
        "batch_size = 1                # Minimum possible to reduce memory usage\n",
        "num_workers = 2               # Reduced to minimize memory overhead\n",
        "pin_memory = True             # Enable pinned memory for faster GPU transfers\n",
        "persistent_workers = True     # Keeps workers alive between epochs to reduce overhead\n",
        "prefetch_factor = 2           # Lower to reduce memory usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "A-Yr9TAOEYM4"
      },
      "outputs": [],
      "source": [
        "from monai.data import list_data_collate\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        "    persistent_workers=persistent_workers,\n",
        "    prefetch_factor=prefetch_factor,\n",
        "    collate_fn=list_data_collate\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        "    persistent_workers=persistent_workers,\n",
        "    prefetch_factor=prefetch_factor,\n",
        "    collate_fn=list_data_collate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "VP3f5aQcEiGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a52f75-9430-40e3-9708-62fd9e057a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "k1QPEWSxEb-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9607de76-81b6-4263-a1f0-bb3963a4272e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch shape: torch.Size([2, 4, 128, 128, 64])\n",
            "Label batch shape: torch.Size([2, 1, 128, 128, 64])\n"
          ]
        }
      ],
      "source": [
        "# Fetch a batch from the training DataLoader\n",
        "try:\n",
        "    batch = next(iter(train_loader))\n",
        "    images = batch[\"image\"].to(device)\n",
        "    labels = batch[\"label\"].to(device)\n",
        "\n",
        "    print(f'Image batch shape: {images.shape}')  # Expected: [B, C, H, W, D]\n",
        "    print(f'Label batch shape: {labels.shape}')  # Expected: [B, C, H, W, D]\n",
        "except RuntimeError as e:\n",
        "    print(\"RuntimeError:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1T0jL5RUMFLt"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Fetch a batch from the training DataLoader\n",
        "# batch = next(iter(train_loader))\n",
        "# images = batch[\"image\"].to(device)\n",
        "# labels = batch[\"label\"].to(device)\n",
        "\n",
        "# # Select the first sample in the batch\n",
        "# img = images[0, 0, :, :, 64].cpu().numpy()  # First modality (e.g., T1) and middle slice\n",
        "# lbl = labels[0, 0, :, :, 64].cpu().numpy()\n",
        "\n",
        "# # Plot the image and label\n",
        "# fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# axs[0].imshow(img, cmap='gray')\n",
        "# axs[0].set_title('Image Slice (Modality 1)')\n",
        "# axs[0].axis('off')\n",
        "\n",
        "# axs[1].imshow(lbl, cmap='gray')\n",
        "# axs[1].set_title('Label Slice')\n",
        "# axs[1].axis('off')\n",
        "\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRMx12b1ub9w"
      },
      "source": [
        "# Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "oRS_C8_MaYjy"
      },
      "outputs": [],
      "source": [
        "from monai.networks.nets import SwinUNETR  # Example Transformer-based encoder\n",
        "from monai.networks.layers import Conv\n",
        "from monai.networks.blocks import Convolution, UpSample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9tPgGwdwXWb"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Input Image\n",
        "    |\n",
        "[Dual Encoders]\n",
        "    |          \\\n",
        "[CNN Encoder] [Transformer Encoder]\n",
        "    |                   |\n",
        "[Feature Maps]        [Global Features]\n",
        "    |                   |\n",
        "    |-------[Feature Fusion]-------\n",
        "    |                   |\n",
        "[Decoder with Skip Connections]\n",
        "    |\n",
        "Segmentation Output\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcXpWYN-ueqz"
      },
      "source": [
        "# CNN Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "ktnuczhfugno"
      },
      "outputs": [],
      "source": [
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self, in_channels=4, feature_channels=[16, 32, 64, 128]):\n",
        "        super(CNNEncoder, self).__init__()\n",
        "        layers = []\n",
        "        prev_channels = in_channels\n",
        "        for out_channels in feature_channels:\n",
        "            layers.append(nn.Conv3d(prev_channels, out_channels, kernel_size=3, padding=1))\n",
        "            layers.append(nn.BatchNorm3d(out_channels))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            layers.append(nn.MaxPool3d(kernel_size=2, stride=2))  # Downsampling\n",
        "            prev_channels = out_channels\n",
        "        self.encoder = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = []\n",
        "        for layer in self.encoder:\n",
        "            x = layer(x)\n",
        "            if isinstance(layer, nn.MaxPool3d):\n",
        "                features.append(x)\n",
        "        return features  # List of feature maps at different scales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QdZfNTSu0ba"
      },
      "source": [
        "# Vision Transformer Encoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O model_swinvit.pt https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/model_swinvit.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecmPtfp7vKIb",
        "outputId": "14b302e6-ddd4-43cb-9e9b-2551e5bf87aa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-10 01:20:24--  https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/model_swinvit.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/366729051/c7bc9f02-a8fb-4527-b311-e308fce79182?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241210T012024Z&X-Amz-Expires=300&X-Amz-Signature=79979af1125c93b92d6dbd75f7bda26fcdbc8984c40e7bb4f8b42283a516abd5&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmodel_swinvit.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-12-10 01:20:24--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/366729051/c7bc9f02-a8fb-4527-b311-e308fce79182?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241210T012024Z&X-Amz-Expires=300&X-Amz-Signature=79979af1125c93b92d6dbd75f7bda26fcdbc8984c40e7bb4f8b42283a516abd5&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmodel_swinvit.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 411162269 (392M) [application/octet-stream]\n",
            "Saving to: ‘model_swinvit.pt’\n",
            "\n",
            "model_swinvit.pt    100%[===================>] 392.11M  45.9MB/s    in 8.7s    \n",
            "\n",
            "2024-12-10 01:20:33 (44.9 MB/s) - ‘model_swinvit.pt’ saved [411162269/411162269]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "rO7ozuvRTpyw"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, in_channels=4, feature_size=24, img_size=(64, 64, 64)):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.transformer = SwinUNETR(\n",
        "            img_size=img_size,\n",
        "            in_channels=in_channels,\n",
        "            out_channels=feature_size,  # final segmentation channels\n",
        "            feature_size=feature_size,\n",
        "            use_checkpoint=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract intermediate features directly\n",
        "        features = self.transformer.swinViT(x)  # returns a tuple/list of features at multiple resolutions\n",
        "\n",
        "        # Print out all feature shapes to identify correct index\n",
        "        for i, f in enumerate(features):\n",
        "            print(f\"features[{i}] shape:\", f.shape)\n",
        "\n",
        "        # Choose the feature map that matches the CNN's deepest layer spatial dimension\n",
        "        # For example, if features[3] matches the CNN deepest scale, use that.\n",
        "        transformer_deep_feature = features[3]\n",
        "        return transformer_deep_feature"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, in_channels=4, feature_size=48, img_size=(64, 64, 64), pretrained_weights_path=None):\n",
        "        \"\"\"\n",
        "        Transformer Encoder using Swin UNETR with optional pre-trained weights.\n",
        "\n",
        "        Args:\n",
        "        - in_channels (int): Number of input channels.\n",
        "        - feature_size (int): Size of features extracted by the transformer.\n",
        "        - img_size (tuple): Size of the input image.\n",
        "        - pretrained_weights_path (str, optional): Path to the pre-trained weights for Swin UNETR.\n",
        "        \"\"\"\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.transformer = SwinUNETR(\n",
        "            img_size=img_size,\n",
        "            in_channels=in_channels,\n",
        "            out_channels=feature_size,  # final segmentation channels\n",
        "            feature_size=feature_size,\n",
        "            use_checkpoint=True\n",
        "        )\n",
        "\n",
        "        # Load pre-trained weights if provided\n",
        "        if pretrained_weights_path:\n",
        "            weight = torch.load(pretrained_weights_path)\n",
        "            self.transformer.load_from(weights=weight)\n",
        "            print(f\"Loaded pre-trained weights from {pretrained_weights_path}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the transformer encoder.\n",
        "\n",
        "        Args:\n",
        "        - x (torch.Tensor): Input tensor of shape [B, C, H, W, D].\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: Deep feature map extracted from the transformer.\n",
        "        \"\"\"\n",
        "        features = self.transformer.swinViT(x)  # Extract intermediate features directly\n",
        "\n",
        "        # Debug: Print feature shapes\n",
        "        for i, f in enumerate(features):\n",
        "            print(f\"features[{i}] shape:\", f.shape)\n",
        "\n",
        "        # Select the deepest feature map\n",
        "        transformer_deep_feature = features[3]  # Assuming features[3] is the deepest\n",
        "        return transformer_deep_feature"
      ],
      "metadata": {
        "id": "S5kPFSaQKYqk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to the pre-trained weights\n",
        "pretrained_weights_path = \"/content/model_swinvit.pt\"\n",
        "\n",
        "# Create the TransformerEncoder with pre-trained weights\n",
        "transformer_encoder = TransformerEncoder(\n",
        "    in_channels=4,\n",
        "    feature_size=48,\n",
        "    img_size=(64, 64, 64),\n",
        "    pretrained_weights_path=pretrained_weights_path\n",
        ").to(device)\n",
        "\n",
        "# Test with a sample input tensor\n",
        "example_input = torch.rand((1, 4, 64, 64, 64)).to(device)\n",
        "output_features = transformer_encoder(example_input)\n",
        "print(f\"Output feature shape: {output_features.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fULxkpr2KrEP",
        "outputId": "0fcae595-93ab-4aee-ce01-bf94e10e68d3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pre-trained weights from /content/model_swinvit.pt\n",
            "features[0] shape: torch.Size([1, 48, 32, 32, 32])\n",
            "features[1] shape: torch.Size([1, 96, 16, 16, 16])\n",
            "features[2] shape: torch.Size([1, 192, 8, 8, 8])\n",
            "features[3] shape: torch.Size([1, 384, 4, 4, 4])\n",
            "features[4] shape: torch.Size([1, 768, 2, 2, 2])\n",
            "Output feature shape: torch.Size([1, 384, 4, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgPNxst_vU5k"
      },
      "source": [
        "# Fusing Features from both Encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "P45OM_pzvQkb"
      },
      "outputs": [],
      "source": [
        "# class FeatureFusion(nn.Module):\n",
        "#     def __init__(self, cnn_channels, transformer_channels):\n",
        "#         super(FeatureFusion, self).__init__()\n",
        "#         self.conv = nn.Conv3d(cnn_channels + transformer_channels, transformer_channels, kernel_size=1)\n",
        "\n",
        "#     def forward(self, cnn_features, transformer_features):\n",
        "#         # Concatenate along the channel dimension\n",
        "#         fused = torch.cat((cnn_features, transformer_features), dim=1)\n",
        "#         fused = self.conv(fused)\n",
        "#         return fused"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "mLJi-2b1_H0f"
      },
      "outputs": [],
      "source": [
        "class FeatureFusion(nn.Module):\n",
        "    def __init__(self, cnn_channels=128, transformer_channels=192):\n",
        "        super(FeatureFusion, self).__init__()\n",
        "        # Now that we know total channels = 128 + 192 = 320\n",
        "        self.conv = nn.Conv3d(cnn_channels + transformer_channels, 128, kernel_size=1)\n",
        "\n",
        "    def forward(self, cnn_feature, transformer_feature):\n",
        "        if cnn_feature.shape[2:] != transformer_feature.shape[2:]:\n",
        "            transformer_feature = nn.functional.interpolate(\n",
        "                transformer_feature, size=cnn_feature.shape[2:], mode='trilinear', align_corners=True\n",
        "            )\n",
        "\n",
        "        fused = torch.cat((cnn_feature, transformer_feature), dim=1)  # [B, 320, D, H, W]\n",
        "        fused = self.conv(fused)  # [B, 128, D, H, W]\n",
        "        return fused"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP7IQdYwvq8N"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOoiCpEtw6LV"
      },
      "outputs": [],
      "source": [
        "# class Decoder(nn.Module):\n",
        "#     def __init__(self, feature_channels=[128, 64, 32, 16], out_channels=1):\n",
        "#         super(Decoder, self).__init__()\n",
        "#         layers = []\n",
        "#         prev_channels = feature_channels[0]\n",
        "#         for out_c in feature_channels[1:]:\n",
        "#             layers.append(\n",
        "#                 nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "#             )\n",
        "#             layers.append(nn.Conv3d(prev_channels, out_c, kernel_size=3, padding=1))\n",
        "#             layers.append(nn.BatchNorm3d(out_c))\n",
        "#             layers.append(nn.ReLU(inplace=True))\n",
        "#             prev_channels = out_c\n",
        "#         layers.append(nn.Conv3d(prev_channels, out_channels, kernel_size=1))  # Final segmentation map\n",
        "#         self.decoder = nn.Sequential(*layers)\n",
        "\n",
        "#     def forward(self, x, skip_connections):\n",
        "#         for idx in range(len(self.decoder)):\n",
        "#             layer = self.decoder[idx]\n",
        "#             if isinstance(layer, nn.Upsample):\n",
        "#                 x = layer(x)\n",
        "#                 # Retrieve the corresponding skip connection\n",
        "#                 skip = skip_connections[-(idx//4 + 1)]  # Modify if necessary\n",
        "#                 # Ensure spatial dimensions match\n",
        "#                 if x.shape != skip.shape:\n",
        "#                     skip = nn.functional.interpolate(skip, size=x.shape[2:], mode='trilinear', align_corners=True)\n",
        "#                 x = x + skip  # Simple addition; alternatively, concatenate\n",
        "#             else:\n",
        "#                 x = layer(x)\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "lWA83CaRDSnL"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, skip_channels=[128, 64, 32, 16], out_channels=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        # Now add four upsample+conv stages corresponding to each skip connection.\n",
        "\n",
        "        # Stage 1: from 4->8\n",
        "        self.up1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv3d(128 + 64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Stage 2: from 8->16\n",
        "        self.up2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv3d(64 + 32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Stage 3: from 16->32\n",
        "        self.up3 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv3d(32 + 16, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Stage 4: from 32->64 (If you have another skip at a shallower level)\n",
        "        # If you don't have another skip, just upsample and conv without skip:\n",
        "        self.up4 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv3d(16, 8, kernel_size=3, padding=1),  # or adjust based on your architecture\n",
        "            nn.BatchNorm3d(8),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.final_conv = nn.Conv3d(8, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x, skip_connections):\n",
        "        # This depends on how many skip connections you have\n",
        "        # Adjust accordingly.\n",
        "\n",
        "        # 1: from 4->8, use the deepest skip\n",
        "        x = self.up1(x)\n",
        "        skip = skip_connections[-1]\n",
        "        if x.shape[2:] != skip.shape[2:]:\n",
        "            skip = nn.functional.interpolate(skip, size=x.shape[2:], mode='trilinear', align_corners=True)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        # 2: from 8->16\n",
        "        x = self.up2(x)\n",
        "        skip = skip_connections[-2]\n",
        "        if x.shape[2:] != skip.shape[2:]:\n",
        "            skip = nn.functional.interpolate(skip, size=x.shape[2:], mode='trilinear', align_corners=True)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        # 3: from 16->32\n",
        "        x = self.up3(x)\n",
        "        skip = skip_connections[-3]\n",
        "        if x.shape[2:] != skip.shape[2:]:\n",
        "            skip = nn.functional.interpolate(skip, size=x.shape[2:], mode='trilinear', align_corners=True)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv3(x)\n",
        "\n",
        "        # 4: from 32->64\n",
        "        # If you have a fourth skip connection:\n",
        "        # skip = skip_connections[-4]\n",
        "        # interpolate if necessary, then concat\n",
        "        # x = torch.cat([x, skip], dim=1)\n",
        "        # Or if you don't have a fourth skip, just upsample:\n",
        "        x = self.up4(x)\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_0zsIQNvw3y"
      },
      "source": [
        "# Assembling the Dual Encoder U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "LN453LyTvuDB"
      },
      "outputs": [],
      "source": [
        "class RobustTransSeg(nn.Module):\n",
        "    def __init__(self, in_channels=4, out_channels=1, img_size=(64, 64, 64)):\n",
        "        super(RobustTransSeg, self).__init__()\n",
        "        self.cnn_encoder = CNNEncoder(in_channels=in_channels, feature_channels=[16, 32, 64, 128])\n",
        "        self.transformer_encoder = TransformerEncoder(in_channels=in_channels, feature_size=24, img_size=img_size)\n",
        "        # self.fusion = FeatureFusion(cnn_channels=128, transformer_channels=24)  # Adjusted channels\n",
        "        self.fusion = FeatureFusion(cnn_channels=128, transformer_channels=192)\n",
        "        # self.decoder = Decoder(feature_channels=[128, 64, 32, 16], out_channels=out_channels)\n",
        "        self.decoder = Decoder(skip_channels=[128, 64, 32, 16], out_channels=out_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN Encoder\n",
        "        cnn_features = self.cnn_encoder(x)  # List of feature maps at different scales\n",
        "\n",
        "        # Transformer Encoder\n",
        "        transformer_features = self.transformer_encoder(x)  # High-level global features\n",
        "\n",
        "        # Fuse features\n",
        "        fused = self.fusion(cnn_features[-1], transformer_features)  # Use the deepest CNN feature map\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        output = self.decoder(fused, cnn_features[:-1])  # Exclude the last feature map used for fusion\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twYku5KIwADb"
      },
      "source": [
        "# Initialization of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "m4OLOIsfv5MO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ba6799-8532-435d-ff3d-60d62bad72ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "RobustTransSeg(\n",
            "  (cnn_encoder): CNNEncoder(\n",
            "    (encoder): Sequential(\n",
            "      (0): Conv3d(4, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "      (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (4): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "      (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (8): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "      (9): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (10): ReLU(inplace=True)\n",
            "      (11): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (12): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "      (13): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (14): ReLU(inplace=True)\n",
            "      (15): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (transformer): SwinUNETR(\n",
            "      (swinViT): SwinTransformer(\n",
            "        (patch_embed): PatchEmbed(\n",
            "          (proj): Conv3d(4, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "        )\n",
            "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "        (layers1): ModuleList(\n",
            "          (0): BasicLayer(\n",
            "            (blocks): ModuleList(\n",
            "              (0-1): 2 x SwinTransformerBlock(\n",
            "                (norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
            "                (attn): WindowAttention(\n",
            "                  (qkv): Linear(in_features=24, out_features=72, bias=True)\n",
            "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                  (proj): Linear(in_features=24, out_features=24, bias=True)\n",
            "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                  (softmax): Softmax(dim=-1)\n",
            "                )\n",
            "                (drop_path): Identity()\n",
            "                (norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
            "                (mlp): MLPBlock(\n",
            "                  (linear1): Linear(in_features=24, out_features=96, bias=True)\n",
            "                  (linear2): Linear(in_features=96, out_features=24, bias=True)\n",
            "                  (fn): GELU(approximate='none')\n",
            "                  (drop1): Dropout(p=0.0, inplace=False)\n",
            "                  (drop2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (downsample): PatchMerging(\n",
            "              (reduction): Linear(in_features=192, out_features=48, bias=False)\n",
            "              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (layers2): ModuleList(\n",
            "          (0): BasicLayer(\n",
            "            (blocks): ModuleList(\n",
            "              (0-1): 2 x SwinTransformerBlock(\n",
            "                (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
            "                (attn): WindowAttention(\n",
            "                  (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
            "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                  (proj): Linear(in_features=48, out_features=48, bias=True)\n",
            "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                  (softmax): Softmax(dim=-1)\n",
            "                )\n",
            "                (drop_path): Identity()\n",
            "                (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
            "                (mlp): MLPBlock(\n",
            "                  (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
            "                  (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
            "                  (fn): GELU(approximate='none')\n",
            "                  (drop1): Dropout(p=0.0, inplace=False)\n",
            "                  (drop2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (downsample): PatchMerging(\n",
            "              (reduction): Linear(in_features=384, out_features=96, bias=False)\n",
            "              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (layers3): ModuleList(\n",
            "          (0): BasicLayer(\n",
            "            (blocks): ModuleList(\n",
            "              (0-1): 2 x SwinTransformerBlock(\n",
            "                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "                (attn): WindowAttention(\n",
            "                  (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                  (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                  (softmax): Softmax(dim=-1)\n",
            "                )\n",
            "                (drop_path): Identity()\n",
            "                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "                (mlp): MLPBlock(\n",
            "                  (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
            "                  (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
            "                  (fn): GELU(approximate='none')\n",
            "                  (drop1): Dropout(p=0.0, inplace=False)\n",
            "                  (drop2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (downsample): PatchMerging(\n",
            "              (reduction): Linear(in_features=768, out_features=192, bias=False)\n",
            "              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (layers4): ModuleList(\n",
            "          (0): BasicLayer(\n",
            "            (blocks): ModuleList(\n",
            "              (0-1): 2 x SwinTransformerBlock(\n",
            "                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "                (attn): WindowAttention(\n",
            "                  (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                  (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                  (softmax): Softmax(dim=-1)\n",
            "                )\n",
            "                (drop_path): Identity()\n",
            "                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "                (mlp): MLPBlock(\n",
            "                  (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
            "                  (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
            "                  (fn): GELU(approximate='none')\n",
            "                  (drop1): Dropout(p=0.0, inplace=False)\n",
            "                  (drop2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (downsample): PatchMerging(\n",
            "              (reduction): Linear(in_features=1536, out_features=384, bias=False)\n",
            "              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (encoder1): UnetrBasicBlock(\n",
            "        (layer): UnetResBlock(\n",
            "          (conv1): Convolution(\n",
            "            (conv): Conv3d(4, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (conv2): Convolution(\n",
            "            (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "          (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (conv3): Convolution(\n",
            "            (conv): Conv3d(4, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (norm3): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder2): UnetrBasicBlock(\n",
            "        (layer): UnetResBlock(\n",
            "          (conv1): Convolution(\n",
            "            (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (conv2): Convolution(\n",
            "            (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "          (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder3): UnetrBasicBlock(\n",
            "        (layer): UnetResBlock(\n",
            "          (conv1): Convolution(\n",
            "            (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (conv2): Convolution(\n",
            "            (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "          (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder4): UnetrBasicBlock(\n",
            "        (layer): UnetResBlock(\n",
            "          (conv1): Convolution(\n",
            "            (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (conv2): Convolution(\n",
            "            (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "          (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder10): UnetrBasicBlock(\n",
            "        (layer): UnetResBlock(\n",
            "          (conv1): Convolution(\n",
            "            (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (conv2): Convolution(\n",
            "            (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "          (norm1): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (norm2): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (decoder5): UnetrUpBlock(\n",
            "        (transp_conv): Convolution(\n",
            "          (conv): ConvTranspose3d(384, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
            "        )\n",
            "        (conv_block): UnetResBlock(\n",
            "          (conv1): Convolution(\n",
            "            (conv): Conv3d(384, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (conv2): Convolution(\n",
            "            (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "          (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (conv3): Convolution(\n",
            "            (conv): Conv3d(384, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (norm3): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (decoder4): UnetrUpBlock(\n",
            "        (transp_conv): Convolution(\n",
            "          (conv): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
            "        )\n",
            "        (conv_block): UnetResBlock(\n",
            "          (conv1): Convolution(\n",
            "            (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (conv2): Convolution(\n",
            "            (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "          (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (conv3): Convolution(\n",
            "            (conv): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (norm3): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (decoder3): UnetrUpBlock(\n",
            "        (transp_conv): Convolution(\n",
            "          (conv): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
            "        )\n",
            "        (conv_block): UnetResBlock(\n",
            "          (conv1): Convolution(\n",
            "            (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (conv2): Convolution(\n",
            "            (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "          (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (conv3): Convolution(\n",
            "            (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (decoder2): UnetrUpBlock(\n",
            "        (transp_conv): Convolution(\n",
            "          (conv): ConvTranspose3d(48, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
            "        )\n",
            "        (conv_block): UnetResBlock(\n",
            "          (conv1): Convolution(\n",
            "            (conv): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (conv2): Convolution(\n",
            "            (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "          (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (conv3): Convolution(\n",
            "            (conv): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (norm3): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (decoder1): UnetrUpBlock(\n",
            "        (transp_conv): Convolution(\n",
            "          (conv): ConvTranspose3d(24, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
            "        )\n",
            "        (conv_block): UnetResBlock(\n",
            "          (conv1): Convolution(\n",
            "            (conv): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (conv2): Convolution(\n",
            "            (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "          (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (conv3): Convolution(\n",
            "            (conv): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          )\n",
            "          (norm3): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (out): UnetOutBlock(\n",
            "        (conv): Convolution(\n",
            "          (conv): Conv3d(24, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fusion): FeatureFusion(\n",
            "    (conv): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (up1): Upsample(scale_factor=2.0, mode='trilinear')\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (up2): Upsample(scale_factor=2.0, mode='trilinear')\n",
            "    (conv2): Sequential(\n",
            "      (0): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (up3): Upsample(scale_factor=2.0, mode='trilinear')\n",
            "    (conv3): Sequential(\n",
            "      (0): Conv3d(48, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "      (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (up4): Upsample(scale_factor=2.0, mode='trilinear')\n",
            "    (conv4): Sequential(\n",
            "      (0): Conv3d(16, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "      (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (final_conv): Conv3d(8, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "# print(torch.cuda.get_device_name(0))\n",
        "\n",
        "\n",
        "# Initialize the model with reduced image size\n",
        "# model = RobustTransSeg(in_channels=4, out_channels=1, img_size=(64, 64, 64)).to(device)\n",
        "model = RobustTransSeg(in_channels=4, out_channels=1, img_size=(64, 64, 64))\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "8uSvvjoBwGho"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceCELoss\n",
        "from monai.data import decollate_batch\n",
        "from monai.transforms import EnsureTyped\n",
        "from tqdm import tqdm  # For progress bars\n",
        "import logging\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# # Define the loss function\n",
        "# criterion = DiceCELoss(to_onehot_y=False, softmax=False, include_background=True)\n",
        "# # Define the optimizer\n",
        "# optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "# # Define the learning rate scheduler\n",
        "# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "cdcOICPHVHY_"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "# Configure logging before training\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,              # Set the minimum logging level to INFO\n",
        "    format='%(asctime)s %(levelname)s: %(message)s',  # Format of the log messages\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'     # Optional: specify a date/time format\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# architecture is defined as RobustTransSeg with out_channels=4\n",
        "model = RobustTransSeg(in_channels=4, out_channels=4, img_size=(128, 128, 64)).to(device)\n",
        "\n",
        "# For multi-class, use DiceCELoss with softmax=True, to_onehot_y=True\n",
        "criterion = DiceCELoss(\n",
        "    to_onehot_y=True,\n",
        "    softmax=True,\n",
        "    include_background=True,\n",
        "    lambda_dice=0.5,\n",
        "    lambda_ce=0.5\n",
        ")\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "# Optionally use a scheduler after you confirm stable training\n",
        "scheduler = StepLR(optimizer, step_size=50, gamma=0.5)  # less aggressive scheduling\n",
        "\n",
        "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "id": "myFIDAd51xAm"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "best_val_loss = float('inf')\n",
        "accumulation_steps = 4\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "\n",
        "    for step, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\")):\n",
        "        images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels) / accumulation_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (step + 1) % accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        epoch_loss += (loss.item() * accumulation_steps)\n",
        "\n",
        "    epoch_loss /= (step + 1)\n",
        "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_steps = 0\n",
        "    dice_metric.reset()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
        "            images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_steps += 1\n",
        "\n",
        "            # For multi-class dice, we can directly feed softmaxed outputs into DiceMetric\n",
        "            # The criterion already does softmax internally, but we can apply here again for clarity:\n",
        "            softmax_preds = torch.softmax(outputs, dim=1)\n",
        "            dice_metric(y_pred=softmax_preds, y=labels)\n",
        "\n",
        "    val_loss /= val_steps\n",
        "    dice_score = dice_metric.aggregate().item()\n",
        "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Dice Score: {dice_score:.4f}\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/RobustTransSeg_best_model.pth')\n",
        "        logger.info(\"Best model saved.\")\n",
        "\n",
        "    # Optional: save checkpoint at intervals\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        checkpoint_path = f\"RobustTransSeg_epoch{epoch+1}.pth\"\n",
        "        torch.save({\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"dice_score\": dice_score\n",
        "        }, checkpoint_path)\n",
        "        logger.info(f\"Checkpoint saved at epoch {epoch+1} with dice score {dice_score:.4f}\")\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEhOaRCZ13_j",
        "outputId": "24990c9c-72c8-4102-d865-7cad425a571f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   0%|          | 0/387 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   0%|          | 1/387 [00:05<32:17,  5.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   1%|          | 2/387 [00:05<16:27,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   1%|          | 3/387 [00:08<17:18,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   1%|          | 4/387 [00:09<12:40,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   1%|▏         | 5/387 [00:14<19:33,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   2%|▏         | 6/387 [00:15<14:52,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   2%|▏         | 7/387 [00:20<20:19,  3.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   2%|▏         | 8/387 [00:21<15:28,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   2%|▏         | 9/387 [00:24<16:42,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   3%|▎         | 10/387 [00:25<13:03,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   3%|▎         | 11/387 [00:27<12:50,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   3%|▎         | 12/387 [00:28<10:29,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   3%|▎         | 13/387 [00:32<16:14,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   4%|▎         | 14/387 [00:33<12:59,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   4%|▍         | 15/387 [00:39<19:03,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   4%|▍         | 16/387 [00:39<14:45,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   4%|▍         | 17/387 [00:42<14:52,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   5%|▍         | 18/387 [00:43<11:50,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   5%|▍         | 19/387 [00:45<12:30,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   5%|▌         | 20/387 [00:46<10:16,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   5%|▌         | 21/387 [00:49<13:12,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   6%|▌         | 22/387 [00:50<10:56,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   6%|▌         | 23/387 [00:57<19:33,  3.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   6%|▌         | 24/387 [00:57<15:06,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   6%|▋         | 25/387 [01:00<15:34,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   7%|▋         | 26/387 [01:01<12:18,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   7%|▋         | 27/387 [01:04<13:46,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   7%|▋         | 28/387 [01:05<11:04,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   7%|▋         | 29/387 [01:07<12:35,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   8%|▊         | 30/387 [01:08<10:15,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   8%|▊         | 31/387 [01:14<18:08,  3.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   8%|▊         | 32/387 [01:15<14:14,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   9%|▊         | 33/387 [01:19<16:17,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   9%|▉         | 34/387 [01:20<12:50,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   9%|▉         | 35/387 [01:22<14:00,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:   9%|▉         | 36/387 [01:23<11:11,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  10%|▉         | 37/387 [01:27<13:57,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  10%|▉         | 38/387 [01:28<11:10,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  10%|█         | 39/387 [01:33<17:13,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  10%|█         | 40/387 [01:34<13:35,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  11%|█         | 41/387 [01:38<16:20,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  11%|█         | 42/387 [01:39<12:48,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  11%|█         | 43/387 [01:42<14:23,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  11%|█▏        | 44/387 [01:43<11:26,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  12%|█▏        | 45/387 [01:46<14:17,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  12%|█▏        | 46/387 [01:48<12:34,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  12%|█▏        | 47/387 [01:54<19:36,  3.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  12%|█▏        | 48/387 [01:55<15:06,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  13%|█▎        | 49/387 [01:58<14:39,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  13%|█▎        | 50/387 [01:58<11:36,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  13%|█▎        | 51/387 [02:02<13:20,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  13%|█▎        | 52/387 [02:02<10:43,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  14%|█▎        | 53/387 [02:05<12:25,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  14%|█▍        | 54/387 [02:06<10:02,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  14%|█▍        | 55/387 [02:11<15:51,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  14%|█▍        | 56/387 [02:12<12:30,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  15%|█▍        | 57/387 [02:16<15:19,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  15%|█▍        | 58/387 [02:17<12:03,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  15%|█▌        | 59/387 [02:20<13:07,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  16%|█▌        | 60/387 [02:21<10:34,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  16%|█▌        | 61/387 [02:24<11:40,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  16%|█▌        | 62/387 [02:24<09:29,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  16%|█▋        | 63/387 [02:28<12:59,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  17%|█▋        | 64/387 [02:29<10:32,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  17%|█▋        | 65/387 [02:34<15:11,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  17%|█▋        | 66/387 [02:35<11:58,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  17%|█▋        | 67/387 [02:38<13:10,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  18%|█▊        | 68/387 [02:39<10:33,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  18%|█▊        | 69/387 [02:42<12:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  18%|█▊        | 70/387 [02:43<09:46,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  18%|█▊        | 71/387 [02:48<14:34,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  19%|█▊        | 72/387 [02:48<11:30,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  19%|█▉        | 73/387 [02:53<15:57,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  19%|█▉        | 74/387 [02:54<12:22,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  19%|█▉        | 75/387 [02:57<13:23,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  20%|█▉        | 76/387 [02:58<10:36,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  20%|█▉        | 77/387 [03:01<12:12,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  20%|██        | 78/387 [03:02<09:55,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  20%|██        | 79/387 [03:07<14:39,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  21%|██        | 80/387 [03:08<11:37,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  21%|██        | 81/387 [03:13<15:01,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  21%|██        | 82/387 [03:13<11:43,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  21%|██▏       | 83/387 [03:16<12:30,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  22%|██▏       | 84/387 [03:17<09:56,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  22%|██▏       | 85/387 [03:20<11:40,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  22%|██▏       | 86/387 [03:21<09:22,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  22%|██▏       | 87/387 [03:27<14:59,  3.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  23%|██▎       | 88/387 [03:27<11:46,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  23%|██▎       | 89/387 [03:32<14:23,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  23%|██▎       | 90/387 [03:32<11:13,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  24%|██▎       | 91/387 [03:36<12:25,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  24%|██▍       | 92/387 [03:36<09:52,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  24%|██▍       | 93/387 [03:39<10:47,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  24%|██▍       | 94/387 [03:40<08:53,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  25%|██▍       | 95/387 [03:45<12:54,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  25%|██▍       | 96/387 [03:45<10:19,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  25%|██▌       | 97/387 [03:49<12:55,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  25%|██▌       | 98/387 [03:50<10:15,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  26%|██▌       | 99/387 [03:53<11:19,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  26%|██▌       | 100/387 [03:54<09:05,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  26%|██▌       | 101/387 [03:56<09:55,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  26%|██▋       | 102/387 [03:57<08:07,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  27%|██▋       | 103/387 [04:02<12:35,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  27%|██▋       | 104/387 [04:03<10:05,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  27%|██▋       | 105/387 [04:09<15:40,  3.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  27%|██▋       | 106/387 [04:10<12:12,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  28%|██▊       | 107/387 [04:13<12:31,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  28%|██▊       | 108/387 [04:14<09:54,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  28%|██▊       | 109/387 [04:17<11:33,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  28%|██▊       | 110/387 [04:18<09:20,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  29%|██▊       | 111/387 [04:23<12:58,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  29%|██▉       | 112/387 [04:24<10:20,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  29%|██▉       | 113/387 [04:28<12:26,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  29%|██▉       | 114/387 [04:28<09:49,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  30%|██▉       | 115/387 [04:31<10:18,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  30%|██▉       | 116/387 [04:32<08:20,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  30%|███       | 117/387 [04:34<09:24,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  30%|███       | 118/387 [04:36<08:05,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  31%|███       | 119/387 [04:40<12:00,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  31%|███       | 120/387 [04:41<09:48,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  31%|███▏      | 121/387 [04:47<13:49,  3.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  32%|███▏      | 122/387 [04:48<10:45,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  32%|███▏      | 123/387 [04:51<11:41,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  32%|███▏      | 124/387 [04:52<09:16,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  32%|███▏      | 125/387 [04:55<10:46,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  33%|███▎      | 126/387 [04:56<08:43,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  33%|███▎      | 127/387 [05:01<12:27,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  33%|███▎      | 128/387 [05:02<09:54,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  33%|███▎      | 129/387 [05:06<12:39,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  34%|███▎      | 130/387 [05:07<09:54,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  34%|███▍      | 131/387 [05:10<10:51,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  34%|███▍      | 132/387 [05:11<08:39,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  34%|███▍      | 133/387 [05:14<09:54,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  35%|███▍      | 134/387 [05:15<07:57,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  35%|███▍      | 135/387 [05:18<10:04,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  35%|███▌      | 136/387 [05:19<08:06,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  35%|███▌      | 137/387 [05:25<12:23,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  36%|███▌      | 138/387 [05:25<09:42,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  36%|███▌      | 139/387 [05:28<10:15,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  36%|███▌      | 140/387 [05:29<08:11,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  36%|███▋      | 141/387 [05:32<09:44,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  37%|███▋      | 142/387 [05:33<07:48,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  37%|███▋      | 143/387 [05:38<11:00,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  37%|███▋      | 144/387 [05:39<08:43,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  37%|███▋      | 145/387 [05:44<12:40,  3.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  38%|███▊      | 146/387 [05:45<09:49,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  38%|███▊      | 147/387 [05:48<10:25,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  38%|███▊      | 148/387 [05:49<08:17,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  39%|███▊      | 149/387 [05:51<08:46,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  39%|███▉      | 150/387 [05:52<07:07,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  39%|███▉      | 151/387 [05:55<08:44,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  39%|███▉      | 152/387 [05:56<07:11,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  40%|███▉      | 153/387 [06:02<11:40,  2.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  40%|███▉      | 154/387 [06:03<09:11,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  40%|████      | 155/387 [06:06<10:04,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  40%|████      | 156/387 [06:07<07:58,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  41%|████      | 157/387 [06:09<08:36,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  41%|████      | 158/387 [06:10<06:55,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  41%|████      | 159/387 [06:13<08:10,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  41%|████▏     | 160/387 [06:14<06:39,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  42%|████▏     | 161/387 [06:19<09:55,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  42%|████▏     | 162/387 [06:20<07:56,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  42%|████▏     | 163/387 [06:24<10:30,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  42%|████▏     | 164/387 [06:25<08:14,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  43%|████▎     | 165/387 [06:28<09:21,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  43%|████▎     | 166/387 [06:29<07:29,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  43%|████▎     | 167/387 [06:32<08:10,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  43%|████▎     | 168/387 [06:33<06:35,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  44%|████▎     | 169/387 [06:37<09:39,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  44%|████▍     | 170/387 [06:38<07:43,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  44%|████▍     | 171/387 [06:43<10:31,  2.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  44%|████▍     | 172/387 [06:44<08:15,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  45%|████▍     | 173/387 [06:47<08:44,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  45%|████▍     | 174/387 [06:47<06:59,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  45%|████▌     | 175/387 [06:51<08:12,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  45%|████▌     | 176/387 [06:51<06:35,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  46%|████▌     | 177/387 [06:56<09:24,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  46%|████▌     | 178/387 [06:57<07:31,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  46%|████▋     | 179/387 [07:02<10:06,  2.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  47%|████▋     | 180/387 [07:02<07:54,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  47%|████▋     | 181/387 [07:06<08:48,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  47%|████▋     | 182/387 [07:06<06:57,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  47%|████▋     | 183/387 [07:09<07:56,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  48%|████▊     | 184/387 [07:10<06:22,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  48%|████▊     | 185/387 [07:15<08:54,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  48%|████▊     | 186/387 [07:16<07:06,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  48%|████▊     | 187/387 [07:20<09:49,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  49%|████▊     | 188/387 [07:21<07:43,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  49%|████▉     | 189/387 [07:25<08:56,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  49%|████▉     | 190/387 [07:26<07:01,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  49%|████▉     | 191/387 [07:29<07:36,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  50%|████▉     | 192/387 [07:29<06:08,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  50%|████▉     | 193/387 [07:33<07:37,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  50%|█████     | 194/387 [07:34<06:06,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  50%|█████     | 195/387 [07:39<09:27,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  51%|█████     | 196/387 [07:40<07:21,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  51%|█████     | 197/387 [07:43<08:00,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  51%|█████     | 198/387 [07:44<06:21,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  51%|█████▏    | 199/387 [07:47<07:26,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  52%|█████▏    | 200/387 [07:48<05:57,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  52%|█████▏    | 201/387 [07:51<07:06,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  52%|█████▏    | 202/387 [07:52<05:44,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  52%|█████▏    | 203/387 [07:57<08:49,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  53%|█████▎    | 204/387 [07:58<07:00,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  53%|█████▎    | 205/387 [08:02<08:16,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  53%|█████▎    | 206/387 [08:03<06:30,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  53%|█████▎    | 207/387 [08:06<07:14,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  54%|█████▎    | 208/387 [08:06<05:48,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  54%|█████▍    | 209/387 [08:09<06:43,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  54%|█████▍    | 210/387 [08:10<05:26,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  55%|█████▍    | 211/387 [08:15<07:48,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  55%|█████▍    | 212/387 [08:16<06:14,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  55%|█████▌    | 213/387 [08:20<08:07,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  55%|█████▌    | 214/387 [08:21<06:23,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  56%|█████▌    | 215/387 [08:24<06:53,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  56%|█████▌    | 216/387 [08:25<05:30,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  56%|█████▌    | 217/387 [08:27<05:54,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  56%|█████▋    | 218/387 [08:28<04:50,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  57%|█████▋    | 219/387 [08:32<06:59,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  57%|█████▋    | 220/387 [08:33<05:37,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  57%|█████▋    | 221/387 [08:38<08:13,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  57%|█████▋    | 222/387 [08:39<06:25,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  58%|█████▊    | 223/387 [08:42<06:45,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  58%|█████▊    | 224/387 [08:43<05:23,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  58%|█████▊    | 225/387 [08:45<05:40,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  58%|█████▊    | 226/387 [08:46<04:37,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  59%|█████▊    | 227/387 [08:49<05:51,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  59%|█████▉    | 228/387 [08:50<04:46,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  59%|█████▉    | 229/387 [08:56<07:28,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  59%|█████▉    | 230/387 [08:56<05:51,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  60%|█████▉    | 231/387 [08:59<06:06,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  60%|█████▉    | 232/387 [09:00<04:55,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  60%|██████    | 233/387 [09:02<05:24,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  60%|██████    | 234/387 [09:03<04:24,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  61%|██████    | 235/387 [09:06<05:29,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  61%|██████    | 236/387 [09:07<04:31,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  61%|██████    | 237/387 [09:12<06:45,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  61%|██████▏   | 238/387 [09:14<06:08,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  62%|██████▏   | 239/387 [09:17<06:16,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  62%|██████▏   | 240/387 [09:18<05:31,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  62%|██████▏   | 241/387 [09:20<05:18,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  63%|██████▎   | 242/387 [09:22<04:52,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  63%|██████▎   | 243/387 [09:24<04:40,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  63%|██████▎   | 244/387 [09:26<04:33,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  63%|██████▎   | 245/387 [09:30<05:52,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  64%|██████▎   | 246/387 [09:32<05:43,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  64%|██████▍   | 247/387 [09:35<06:02,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  64%|██████▍   | 248/387 [09:37<05:30,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  64%|██████▍   | 249/387 [09:39<05:15,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  65%|██████▍   | 250/387 [09:40<04:47,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  65%|██████▍   | 251/387 [09:42<04:33,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  65%|██████▌   | 252/387 [09:44<04:20,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  65%|██████▌   | 253/387 [09:47<05:06,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  66%|██████▌   | 254/387 [09:50<05:33,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  66%|██████▌   | 255/387 [09:53<05:51,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  66%|██████▌   | 256/387 [09:55<05:15,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  66%|██████▋   | 257/387 [09:57<04:40,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  67%|██████▋   | 258/387 [09:59<04:41,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  67%|██████▋   | 259/387 [10:00<04:02,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  67%|██████▋   | 260/387 [10:03<04:29,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  67%|██████▋   | 261/387 [10:04<04:10,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  68%|██████▊   | 262/387 [10:09<05:32,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  68%|██████▊   | 263/387 [10:10<05:03,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  68%|██████▊   | 264/387 [10:13<05:20,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  68%|██████▊   | 265/387 [10:15<04:43,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  69%|██████▊   | 266/387 [10:17<04:34,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  69%|██████▉   | 267/387 [10:19<04:09,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  69%|██████▉   | 268/387 [10:21<04:06,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  70%|██████▉   | 269/387 [10:23<04:03,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  70%|██████▉   | 270/387 [10:26<04:46,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  70%|███████   | 271/387 [10:28<04:30,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  70%|███████   | 272/387 [10:32<05:04,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  71%|███████   | 273/387 [10:33<03:59,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  71%|███████   | 274/387 [10:36<04:52,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  71%|███████   | 275/387 [10:37<03:51,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  71%|███████▏  | 276/387 [10:39<03:39,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  72%|███████▏  | 277/387 [10:41<03:31,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  72%|███████▏  | 278/387 [10:44<04:07,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  72%|███████▏  | 279/387 [10:47<04:47,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  72%|███████▏  | 280/387 [10:50<04:27,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  73%|███████▎  | 281/387 [10:51<03:58,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  73%|███████▎  | 282/387 [10:53<03:55,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  73%|███████▎  | 283/387 [10:55<03:22,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  73%|███████▎  | 284/387 [10:57<03:29,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  74%|███████▎  | 285/387 [11:00<03:50,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  74%|███████▍  | 286/387 [11:02<03:44,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  74%|███████▍  | 287/387 [11:06<04:40,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  74%|███████▍  | 288/387 [11:09<04:35,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  75%|███████▍  | 289/387 [11:11<04:09,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  75%|███████▍  | 290/387 [11:13<03:50,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  75%|███████▌  | 291/387 [11:14<03:29,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  75%|███████▌  | 292/387 [11:16<03:22,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  76%|███████▌  | 293/387 [11:18<03:09,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  76%|███████▌  | 294/387 [11:21<03:24,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  76%|███████▌  | 295/387 [11:24<03:58,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  76%|███████▋  | 296/387 [11:27<04:01,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  77%|███████▋  | 297/387 [11:29<03:36,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  77%|███████▋  | 298/387 [11:31<03:12,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  77%|███████▋  | 299/387 [11:32<02:59,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  78%|███████▊  | 300/387 [11:35<03:09,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  78%|███████▊  | 301/387 [11:36<02:36,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  78%|███████▊  | 302/387 [11:40<03:34,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  78%|███████▊  | 303/387 [11:43<03:56,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  79%|███████▊  | 304/387 [11:46<03:37,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  79%|███████▉  | 305/387 [11:48<03:20,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  79%|███████▉  | 306/387 [11:49<03:00,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  79%|███████▉  | 307/387 [11:52<03:00,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  80%|███████▉  | 308/387 [11:54<02:48,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  80%|███████▉  | 309/387 [11:56<02:51,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  80%|████████  | 310/387 [12:00<03:30,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  80%|████████  | 311/387 [12:03<03:26,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  81%|████████  | 312/387 [12:05<03:22,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  81%|████████  | 313/387 [12:07<03:07,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  81%|████████  | 314/387 [12:09<02:44,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  81%|████████▏ | 315/387 [12:11<02:30,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  82%|████████▏ | 316/387 [12:13<02:29,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  82%|████████▏ | 317/387 [12:15<02:21,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  82%|████████▏ | 318/387 [12:18<02:41,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  82%|████████▏ | 319/387 [12:21<03:06,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  83%|████████▎ | 320/387 [12:24<02:52,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  83%|████████▎ | 321/387 [12:26<02:39,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  83%|████████▎ | 322/387 [12:27<02:25,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  83%|████████▎ | 323/387 [12:29<02:11,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  84%|████████▎ | 324/387 [12:32<02:20,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  84%|████████▍ | 325/387 [12:33<02:07,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  84%|████████▍ | 326/387 [12:36<02:18,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  84%|████████▍ | 327/387 [12:40<02:49,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  85%|████████▍ | 328/387 [12:42<02:26,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  85%|████████▌ | 329/387 [12:44<02:17,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  85%|████████▌ | 330/387 [12:46<02:10,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  86%|████████▌ | 331/387 [12:48<01:53,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  86%|████████▌ | 332/387 [12:49<01:49,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  86%|████████▌ | 333/387 [12:52<01:48,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  86%|████████▋ | 334/387 [12:54<01:51,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  87%|████████▋ | 335/387 [12:58<02:23,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  87%|████████▋ | 336/387 [13:00<02:04,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  87%|████████▋ | 337/387 [13:03<02:15,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  87%|████████▋ | 338/387 [13:04<01:48,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  88%|████████▊ | 339/387 [13:08<02:02,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  88%|████████▊ | 340/387 [13:09<01:41,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  88%|████████▊ | 341/387 [13:12<01:50,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  88%|████████▊ | 342/387 [13:15<02:04,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  89%|████████▊ | 343/387 [13:18<01:57,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  89%|████████▉ | 344/387 [13:20<01:50,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  89%|████████▉ | 345/387 [13:22<01:33,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  89%|████████▉ | 346/387 [13:24<01:38,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  90%|████████▉ | 347/387 [13:26<01:24,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  90%|████████▉ | 348/387 [13:28<01:21,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  90%|█████████ | 349/387 [13:30<01:17,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  90%|█████████ | 350/387 [13:33<01:28,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  91%|█████████ | 351/387 [13:35<01:26,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  91%|█████████ | 352/387 [13:38<01:30,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  91%|█████████ | 353/387 [13:40<01:17,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  91%|█████████▏| 354/387 [13:42<01:13,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  92%|█████████▏| 355/387 [13:44<01:11,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  92%|█████████▏| 356/387 [13:46<00:59,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  92%|█████████▏| 357/387 [13:50<01:17,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  93%|█████████▎| 358/387 [13:51<01:06,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  93%|█████████▎| 359/387 [13:56<01:21,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  93%|█████████▎| 360/387 [13:58<01:10,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  93%|█████████▎| 361/387 [13:59<01:01,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  94%|█████████▎| 362/387 [14:01<00:55,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  94%|█████████▍| 363/387 [14:03<00:50,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  94%|█████████▍| 364/387 [14:05<00:45,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  94%|█████████▍| 365/387 [14:06<00:41,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  95%|█████████▍| 366/387 [14:10<00:49,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  95%|█████████▍| 367/387 [14:12<00:47,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  95%|█████████▌| 368/387 [14:16<00:51,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  95%|█████████▌| 369/387 [14:18<00:44,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  96%|█████████▌| 370/387 [14:20<00:39,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  96%|█████████▌| 371/387 [14:21<00:33,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  96%|█████████▌| 372/387 [14:24<00:32,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  96%|█████████▋| 373/387 [14:25<00:26,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  97%|█████████▋| 374/387 [14:28<00:29,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  97%|█████████▋| 375/387 [14:30<00:27,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  97%|█████████▋| 376/387 [14:34<00:30,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  97%|█████████▋| 377/387 [14:36<00:24,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  98%|█████████▊| 378/387 [14:38<00:21,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  98%|█████████▊| 379/387 [14:40<00:17,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  98%|█████████▊| 380/387 [14:42<00:15,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  98%|█████████▊| 381/387 [14:44<00:12,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  99%|█████████▊| 382/387 [14:46<00:10,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  99%|█████████▉| 383/387 [14:48<00:07,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  99%|█████████▉| 384/387 [14:53<00:08,  2.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training:  99%|█████████▉| 385/387 [14:55<00:05,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Training: 100%|█████████▉| 386/387 [14:57<00:02,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Training: 100%|██████████| 387/387 [14:58<00:00,  2.32s/it]\n",
            "Epoch 1/10 - Validation:   1%|          | 1/97 [00:03<05:49,  3.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:   2%|▏         | 2/97 [00:03<02:39,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:   3%|▎         | 3/97 [00:06<03:30,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:   4%|▍         | 4/97 [00:07<02:18,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:   5%|▌         | 5/97 [00:12<04:19,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:   6%|▌         | 6/97 [00:12<02:58,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:   7%|▋         | 7/97 [00:16<04:02,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:   8%|▊         | 8/97 [00:17<02:54,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:   9%|▉         | 9/97 [00:19<03:10,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  10%|█         | 10/97 [00:20<02:16,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  11%|█▏        | 11/97 [00:22<02:48,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  12%|█▏        | 12/97 [00:23<02:01,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  13%|█▎        | 13/97 [00:26<02:39,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  14%|█▍        | 14/97 [00:26<01:59,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  15%|█▌        | 15/97 [00:29<02:40,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  16%|█▋        | 16/97 [00:29<01:56,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  18%|█▊        | 17/97 [00:34<03:16,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  19%|█▊        | 18/97 [00:35<02:24,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  20%|█▉        | 19/97 [00:39<03:27,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  21%|██        | 20/97 [00:39<02:28,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  22%|██▏       | 21/97 [00:42<02:43,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  23%|██▎       | 22/97 [00:42<01:57,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  24%|██▎       | 23/97 [00:45<02:12,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation:  26%|██▌       | 25/97 [00:47<02:02,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  27%|██▋       | 26/97 [00:48<01:30,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  28%|██▊       | 27/97 [00:51<02:12,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  29%|██▉       | 28/97 [00:51<01:36,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  30%|██▉       | 29/97 [00:57<02:56,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  31%|███       | 30/97 [00:57<02:08,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  32%|███▏      | 31/97 [01:01<02:46,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  33%|███▎      | 32/97 [01:01<01:58,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  34%|███▍      | 33/97 [01:04<02:14,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  35%|███▌      | 34/97 [01:04<01:36,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  36%|███▌      | 35/97 [01:07<01:55,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  37%|███▋      | 36/97 [01:07<01:23,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  38%|███▊      | 37/97 [01:09<01:40,  1.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  39%|███▉      | 38/97 [01:10<01:13,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  40%|████      | 39/97 [01:14<02:04,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  41%|████      | 40/97 [01:14<01:30,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  42%|████▏     | 41/97 [01:19<02:26,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  43%|████▎     | 42/97 [01:19<01:46,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  44%|████▍     | 43/97 [01:23<02:02,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  45%|████▌     | 44/97 [01:23<01:27,  1.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  46%|████▋     | 45/97 [01:25<01:39,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  47%|████▋     | 46/97 [01:26<01:12,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  48%|████▊     | 47/97 [01:28<01:29,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  49%|████▉     | 48/97 [01:28<01:04,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  51%|█████     | 49/97 [01:31<01:23,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  52%|█████▏    | 50/97 [01:31<01:01,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  53%|█████▎    | 51/97 [01:36<01:41,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  54%|█████▎    | 52/97 [01:36<01:13,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  55%|█████▍    | 53/97 [01:41<01:56,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  56%|█████▌    | 54/97 [01:41<01:24,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  57%|█████▋    | 55/97 [01:45<01:44,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  58%|█████▊    | 56/97 [01:45<01:13,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  59%|█████▉    | 57/97 [01:48<01:20,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation:  61%|██████    | 59/97 [01:50<01:06,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation:  63%|██████▎   | 61/97 [01:53<00:59,  1.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  64%|██████▍   | 62/97 [01:53<00:43,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  65%|██████▍   | 63/97 [01:57<01:08,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  66%|██████▌   | 64/97 [01:58<00:49,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  67%|██████▋   | 65/97 [02:03<01:26,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  68%|██████▊   | 66/97 [02:03<01:01,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  69%|██████▉   | 67/97 [02:07<01:18,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation:  71%|███████   | 69/97 [02:10<00:57,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  72%|███████▏  | 70/97 [02:10<00:40,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  73%|███████▎  | 71/97 [02:13<00:47,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation:  75%|███████▌  | 73/97 [02:16<00:41,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation:  77%|███████▋  | 75/97 [02:20<00:43,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  78%|███████▊  | 76/97 [02:20<00:30,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  79%|███████▉  | 77/97 [02:25<00:53,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  80%|████████  | 78/97 [02:26<00:37,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  81%|████████▏ | 79/97 [02:30<00:47,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation:  84%|████████▎ | 81/97 [02:33<00:34,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation:  86%|████████▌ | 83/97 [02:35<00:25,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation:  88%|████████▊ | 85/97 [02:38<00:19,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation:  90%|████████▉ | 87/97 [02:42<00:19,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  91%|█████████ | 88/97 [02:42<00:13,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  92%|█████████▏| 89/97 [02:46<00:17,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  93%|█████████▎| 90/97 [02:46<00:11,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  94%|█████████▍| 91/97 [02:51<00:15,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  95%|█████████▍| 92/97 [02:51<00:09,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  96%|█████████▌| 93/97 [02:54<00:08,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  97%|█████████▋| 94/97 [02:54<00:04,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 - Validation:  98%|█████████▊| 95/97 [02:56<00:03,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation: 100%|██████████| 97/97 [02:58<00:00,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2/10 - Training:   0%|          | 0/387 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   0%|          | 1/387 [00:04<30:18,  4.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   1%|          | 2/387 [00:05<15:30,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   1%|          | 3/387 [00:11<26:22,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   1%|          | 4/387 [00:12<18:18,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   1%|▏         | 5/387 [00:18<24:20,  3.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   2%|▏         | 6/387 [00:18<17:44,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   2%|▏         | 7/387 [00:22<18:32,  2.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   2%|▏         | 8/387 [00:22<14:13,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   2%|▏         | 9/387 [00:26<16:14,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   3%|▎         | 10/387 [00:27<12:53,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   3%|▎         | 11/387 [00:32<18:54,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   3%|▎         | 12/387 [00:33<14:52,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   3%|▎         | 13/387 [00:38<19:50,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   4%|▎         | 14/387 [00:39<15:19,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   4%|▍         | 15/387 [00:42<17:05,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   4%|▍         | 16/387 [00:43<13:25,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   4%|▍         | 17/387 [00:46<14:44,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   5%|▍         | 18/387 [00:46<11:43,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   5%|▍         | 19/387 [00:51<16:20,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   5%|▌         | 20/387 [00:52<13:04,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   5%|▌         | 21/387 [00:57<17:54,  2.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   6%|▌         | 22/387 [00:58<14:08,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   6%|▌         | 23/387 [01:01<16:23,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   6%|▌         | 24/387 [01:02<12:54,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   6%|▋         | 25/387 [01:05<13:49,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   7%|▋         | 26/387 [01:05<11:06,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   7%|▋         | 27/387 [01:09<14:31,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   7%|▋         | 28/387 [01:10<11:43,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   7%|▋         | 29/387 [01:16<18:30,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   8%|▊         | 30/387 [01:17<14:33,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   8%|▊         | 31/387 [01:22<20:12,  3.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   8%|▊         | 32/387 [01:23<15:36,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   9%|▊         | 33/387 [01:26<16:21,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   9%|▉         | 34/387 [01:27<12:48,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   9%|▉         | 35/387 [01:31<14:58,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:   9%|▉         | 36/387 [01:31<11:56,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  10%|▉         | 37/387 [01:36<15:59,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  10%|▉         | 38/387 [01:37<12:41,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  10%|█         | 39/387 [01:43<19:58,  3.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  10%|█         | 40/387 [01:44<15:22,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  11%|█         | 41/387 [01:47<17:02,  2.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  11%|█         | 42/387 [01:48<13:18,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  11%|█         | 43/387 [01:51<13:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  11%|█▏        | 44/387 [01:51<10:33,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  12%|█▏        | 45/387 [01:55<13:24,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  12%|█▏        | 46/387 [01:56<10:56,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  12%|█▏        | 47/387 [02:01<16:12,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  12%|█▏        | 48/387 [02:02<12:48,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  13%|█▎        | 49/387 [02:08<19:00,  3.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  13%|█▎        | 50/387 [02:09<14:42,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  13%|█▎        | 51/387 [02:11<14:35,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  13%|█▎        | 52/387 [02:12<11:33,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  14%|█▎        | 53/387 [02:15<13:26,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  14%|█▍        | 54/387 [02:16<10:41,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  14%|█▍        | 55/387 [02:21<15:08,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  14%|█▍        | 56/387 [02:21<11:58,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  15%|█▍        | 57/387 [02:27<17:51,  3.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  15%|█▍        | 58/387 [02:28<13:56,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  15%|█▌        | 59/387 [02:32<16:15,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  16%|█▌        | 60/387 [02:33<12:39,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  16%|█▌        | 61/387 [02:36<14:09,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  16%|█▌        | 62/387 [02:37<11:59,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  16%|█▋        | 63/387 [02:40<12:34,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  17%|█▋        | 64/387 [02:41<10:06,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  17%|█▋        | 65/387 [02:46<15:29,  2.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  17%|█▋        | 66/387 [02:47<12:06,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  17%|█▋        | 67/387 [02:52<16:56,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  18%|█▊        | 68/387 [02:53<13:07,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  18%|█▊        | 69/387 [02:56<13:44,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  18%|█▊        | 70/387 [02:57<10:51,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  18%|█▊        | 71/387 [03:00<12:00,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  19%|█▊        | 72/387 [03:00<09:40,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  19%|█▉        | 73/387 [03:03<11:27,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  19%|█▉        | 74/387 [03:04<09:18,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  19%|█▉        | 75/387 [03:11<16:35,  3.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  20%|█▉        | 76/387 [03:12<13:12,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  20%|█▉        | 77/387 [03:16<15:55,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  20%|██        | 78/387 [03:17<12:24,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  20%|██        | 79/387 [03:19<12:34,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  21%|██        | 80/387 [03:20<10:01,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  21%|██        | 81/387 [03:23<11:52,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  21%|██        | 82/387 [03:24<09:30,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  21%|██▏       | 83/387 [03:29<14:29,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  22%|██▏       | 84/387 [03:30<11:31,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  22%|██▏       | 85/387 [03:36<16:20,  3.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  22%|██▏       | 86/387 [03:37<12:43,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  22%|██▏       | 87/387 [03:40<13:52,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  23%|██▎       | 88/387 [03:41<10:53,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  23%|██▎       | 89/387 [03:44<12:52,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  23%|██▎       | 90/387 [03:45<10:09,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  24%|██▎       | 91/387 [03:49<12:10,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  24%|██▍       | 92/387 [03:49<09:47,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  24%|██▍       | 93/387 [03:55<14:53,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  24%|██▍       | 94/387 [03:56<11:39,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  25%|██▍       | 95/387 [04:01<15:42,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  25%|██▍       | 96/387 [04:02<12:07,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  25%|██▌       | 97/387 [04:05<13:18,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  25%|██▌       | 98/387 [04:06<10:25,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  26%|██▌       | 99/387 [04:09<11:12,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  26%|██▌       | 100/387 [04:10<08:58,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  26%|██▌       | 101/387 [04:13<11:36,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  26%|██▋       | 102/387 [04:14<09:17,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  27%|██▋       | 103/387 [04:20<14:17,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  27%|██▋       | 104/387 [04:21<11:17,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  27%|██▋       | 105/387 [04:26<14:57,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  27%|██▋       | 106/387 [04:26<11:34,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  28%|██▊       | 107/387 [04:29<12:11,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  28%|██▊       | 108/387 [04:30<09:37,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  28%|██▊       | 109/387 [04:33<11:06,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  28%|██▊       | 110/387 [04:34<08:51,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  29%|██▊       | 111/387 [04:39<12:44,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  29%|██▉       | 112/387 [04:40<10:05,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  29%|██▉       | 113/387 [04:45<14:46,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  29%|██▉       | 114/387 [04:46<11:25,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  30%|██▉       | 115/387 [04:49<12:20,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  30%|██▉       | 116/387 [04:50<09:42,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  30%|███       | 117/387 [04:53<10:54,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  30%|███       | 118/387 [04:54<08:41,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  31%|███       | 119/387 [04:58<11:59,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  31%|███       | 120/387 [04:59<09:36,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  31%|███▏      | 121/387 [05:06<15:14,  3.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  32%|███▏      | 122/387 [05:07<11:49,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  32%|███▏      | 123/387 [05:11<13:19,  3.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  32%|███▏      | 124/387 [05:11<10:20,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  32%|███▏      | 125/387 [05:14<11:05,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  33%|███▎      | 126/387 [05:15<08:48,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  33%|███▎      | 127/387 [05:18<09:39,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  33%|███▎      | 128/387 [05:19<07:49,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  33%|███▎      | 129/387 [05:23<10:20,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  34%|███▎      | 130/387 [05:23<08:16,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  34%|███▍      | 131/387 [05:29<13:14,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  34%|███▍      | 132/387 [05:30<10:22,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  34%|███▍      | 133/387 [05:33<11:24,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  35%|███▍      | 134/387 [05:34<08:59,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  35%|███▍      | 135/387 [05:37<10:20,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  35%|███▌      | 136/387 [05:38<08:14,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  35%|███▌      | 137/387 [05:40<08:27,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  36%|███▌      | 138/387 [05:41<06:54,  1.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  36%|███▌      | 139/387 [05:46<10:45,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  36%|███▌      | 140/387 [05:47<08:35,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  36%|███▋      | 141/387 [05:53<13:44,  3.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  37%|███▋      | 142/387 [05:54<10:32,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  37%|███▋      | 143/387 [05:57<10:43,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  37%|███▋      | 144/387 [05:58<08:31,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  37%|███▋      | 145/387 [06:01<09:53,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  38%|███▊      | 146/387 [06:02<07:50,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  38%|███▊      | 147/387 [06:07<11:38,  2.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  38%|███▊      | 148/387 [06:08<09:14,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  39%|███▊      | 149/387 [06:13<12:49,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  39%|███▉      | 150/387 [06:14<10:00,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  39%|███▉      | 151/387 [06:18<11:23,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  39%|███▉      | 152/387 [06:19<08:52,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  40%|███▉      | 153/387 [06:21<09:17,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  40%|███▉      | 154/387 [06:22<07:24,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  40%|████      | 155/387 [06:25<08:36,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  40%|████      | 156/387 [06:26<07:01,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  41%|████      | 157/387 [06:31<10:53,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  41%|████      | 158/387 [06:32<08:49,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  41%|████      | 159/387 [06:39<13:23,  3.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  41%|████▏     | 160/387 [06:39<10:15,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  42%|████▏     | 161/387 [06:42<10:23,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  42%|████▏     | 162/387 [06:43<08:07,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  42%|████▏     | 163/387 [06:46<09:25,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  42%|████▏     | 164/387 [06:47<07:29,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  43%|████▎     | 165/387 [06:51<09:04,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  43%|████▎     | 166/387 [06:51<07:14,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  43%|████▎     | 167/387 [06:56<10:18,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  43%|████▎     | 168/387 [06:57<08:10,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  44%|████▎     | 169/387 [07:03<11:38,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  44%|████▍     | 170/387 [07:03<08:58,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  44%|████▍     | 171/387 [07:07<10:15,  2.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  44%|████▍     | 172/387 [07:08<08:04,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  45%|████▍     | 173/387 [07:11<08:52,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  45%|████▍     | 174/387 [07:12<07:04,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  45%|████▌     | 175/387 [07:17<10:43,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  45%|████▌     | 176/387 [07:18<08:25,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  46%|████▌     | 177/387 [07:25<12:48,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  46%|████▌     | 178/387 [07:26<09:48,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  46%|████▋     | 179/387 [07:28<09:28,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  47%|████▋     | 180/387 [07:29<07:25,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  47%|████▋     | 181/387 [07:32<08:17,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  47%|████▋     | 182/387 [07:33<06:35,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  47%|████▋     | 183/387 [07:36<07:57,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  48%|████▊     | 184/387 [07:37<06:25,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  48%|████▊     | 185/387 [07:43<10:43,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  48%|████▊     | 186/387 [07:44<08:20,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  48%|████▊     | 187/387 [07:49<10:48,  3.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  49%|████▊     | 188/387 [07:50<08:20,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  49%|████▉     | 189/387 [07:52<08:09,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  49%|████▉     | 190/387 [07:53<06:27,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  49%|████▉     | 191/387 [07:57<08:02,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  50%|████▉     | 192/387 [07:57<06:23,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  50%|████▉     | 193/387 [08:02<09:00,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  50%|█████     | 194/387 [08:03<07:07,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  50%|█████     | 195/387 [08:09<10:36,  3.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  51%|█████     | 196/387 [08:10<08:09,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  51%|█████     | 197/387 [08:13<08:37,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  51%|█████     | 198/387 [08:14<06:47,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  51%|█████▏    | 199/387 [08:16<07:06,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  52%|█████▏    | 200/387 [08:17<05:42,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  52%|█████▏    | 201/387 [08:21<07:18,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  52%|█████▏    | 202/387 [08:21<05:52,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  52%|█████▏    | 203/387 [08:26<08:20,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  53%|█████▎    | 204/387 [08:27<06:38,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  53%|█████▎    | 205/387 [08:32<09:06,  3.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  53%|█████▎    | 206/387 [08:33<07:04,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  53%|█████▎    | 207/387 [08:36<07:49,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  54%|█████▎    | 208/387 [08:37<06:11,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  54%|█████▍    | 209/387 [08:40<06:51,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  54%|█████▍    | 210/387 [08:40<05:29,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  55%|█████▍    | 211/387 [08:45<07:27,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  55%|█████▍    | 212/387 [08:48<07:47,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  55%|█████▌    | 213/387 [08:51<08:41,  3.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  55%|█████▌    | 214/387 [08:52<06:46,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  56%|█████▌    | 215/387 [08:55<07:25,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  56%|█████▌    | 216/387 [08:56<05:51,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  56%|█████▌    | 217/387 [09:00<07:09,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  56%|█████▋    | 218/387 [09:01<05:41,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  57%|█████▋    | 219/387 [09:04<07:06,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  57%|█████▋    | 220/387 [09:05<05:41,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  57%|█████▋    | 221/387 [09:11<08:35,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  57%|█████▋    | 222/387 [09:12<06:42,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  58%|█████▊    | 223/387 [09:15<07:28,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  58%|█████▊    | 224/387 [09:16<05:51,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  58%|█████▊    | 225/387 [09:18<06:04,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  58%|█████▊    | 226/387 [09:19<04:53,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  59%|█████▊    | 227/387 [09:22<06:01,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  59%|█████▉    | 228/387 [09:23<04:52,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  59%|█████▉    | 229/387 [09:27<05:59,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  59%|█████▉    | 230/387 [09:28<04:52,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  60%|█████▉    | 231/387 [09:34<08:04,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  60%|█████▉    | 232/387 [09:34<06:18,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  60%|██████    | 233/387 [09:38<07:13,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  60%|██████    | 234/387 [09:39<05:39,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  61%|██████    | 235/387 [09:42<05:56,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  61%|██████    | 236/387 [09:42<04:46,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  61%|██████    | 237/387 [09:45<05:18,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  61%|██████▏   | 238/387 [09:46<04:20,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  62%|██████▏   | 239/387 [09:52<07:34,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  62%|██████▏   | 240/387 [09:53<05:56,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  62%|██████▏   | 241/387 [09:58<07:29,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  63%|██████▎   | 242/387 [09:58<05:49,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  63%|██████▎   | 243/387 [10:02<06:15,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  63%|██████▎   | 244/387 [10:02<04:58,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  63%|██████▎   | 245/387 [10:06<05:53,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  64%|██████▎   | 246/387 [10:07<04:44,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  64%|██████▍   | 247/387 [10:12<06:42,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  64%|██████▍   | 248/387 [10:13<05:18,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  64%|██████▍   | 249/387 [10:18<07:18,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  65%|██████▍   | 250/387 [10:19<05:39,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  65%|██████▍   | 251/387 [10:22<06:05,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  65%|██████▌   | 252/387 [10:23<04:47,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  65%|██████▌   | 253/387 [10:26<05:14,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  66%|██████▌   | 254/387 [10:27<04:19,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  66%|██████▌   | 255/387 [10:31<05:42,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  66%|██████▌   | 256/387 [10:32<04:34,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  66%|██████▋   | 257/387 [10:39<07:48,  3.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  67%|██████▋   | 258/387 [10:40<06:00,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  67%|██████▋   | 259/387 [10:42<06:00,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  67%|██████▋   | 260/387 [10:43<04:43,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  67%|██████▋   | 261/387 [10:47<05:20,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  68%|██████▊   | 262/387 [10:47<04:14,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  68%|██████▊   | 263/387 [10:51<04:55,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  68%|██████▊   | 264/387 [10:52<03:57,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  68%|██████▊   | 265/387 [10:57<06:02,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  69%|██████▊   | 266/387 [10:58<04:44,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  69%|██████▉   | 267/387 [11:03<06:27,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  69%|██████▉   | 268/387 [11:04<04:59,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  70%|██████▉   | 269/387 [11:07<05:06,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  70%|██████▉   | 270/387 [11:08<04:02,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  70%|███████   | 271/387 [11:10<04:04,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  70%|███████   | 272/387 [11:11<03:19,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  71%|███████   | 273/387 [11:15<04:41,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  71%|███████   | 274/387 [11:16<03:51,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  71%|███████   | 275/387 [11:22<06:06,  3.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  71%|███████▏  | 276/387 [11:23<04:45,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  72%|███████▏  | 277/387 [11:27<05:26,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  72%|███████▏  | 278/387 [11:28<04:14,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  72%|███████▏  | 279/387 [11:31<04:39,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  72%|███████▏  | 280/387 [11:32<03:41,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  73%|███████▎  | 281/387 [11:35<04:08,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  73%|███████▎  | 282/387 [11:36<03:19,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  73%|███████▎  | 283/387 [11:40<04:24,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  73%|███████▎  | 284/387 [11:41<03:31,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  74%|███████▎  | 285/387 [11:47<05:34,  3.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  74%|███████▍  | 286/387 [11:48<04:17,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  74%|███████▍  | 287/387 [11:51<04:42,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  74%|███████▍  | 288/387 [11:52<03:40,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  75%|███████▍  | 289/387 [11:55<03:55,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  75%|███████▍  | 290/387 [11:55<03:07,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  75%|███████▌  | 291/387 [11:59<03:58,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  75%|███████▌  | 292/387 [12:00<03:09,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  76%|███████▌  | 293/387 [12:05<04:23,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  76%|███████▌  | 294/387 [12:06<03:27,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  76%|███████▌  | 295/387 [12:11<04:51,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  76%|███████▋  | 296/387 [12:12<03:45,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  77%|███████▋  | 297/387 [12:15<04:04,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  77%|███████▋  | 298/387 [12:16<03:11,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  77%|███████▋  | 299/387 [12:19<03:35,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  78%|███████▊  | 300/387 [12:20<02:51,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  78%|███████▊  | 301/387 [12:24<03:47,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  78%|███████▊  | 302/387 [12:25<03:00,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  78%|███████▊  | 303/387 [12:31<04:31,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  79%|███████▊  | 304/387 [12:32<03:30,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  79%|███████▉  | 305/387 [12:36<04:09,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  79%|███████▉  | 306/387 [12:37<03:13,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  79%|███████▉  | 307/387 [12:40<03:25,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  80%|███████▉  | 308/387 [12:41<02:43,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  80%|███████▉  | 309/387 [12:43<02:50,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  80%|████████  | 310/387 [12:44<02:18,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  80%|████████  | 311/387 [12:50<03:40,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  81%|████████  | 312/387 [12:51<02:52,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  81%|████████  | 313/387 [12:56<04:04,  3.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  81%|████████  | 314/387 [12:57<03:07,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  81%|████████▏ | 315/387 [13:00<03:11,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  82%|████████▏ | 316/387 [13:01<02:33,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  82%|████████▏ | 317/387 [13:03<02:39,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  82%|████████▏ | 318/387 [13:04<02:07,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  82%|████████▏ | 319/387 [13:10<03:26,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  83%|████████▎ | 320/387 [13:11<02:40,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  83%|████████▎ | 321/387 [13:16<03:32,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  83%|████████▎ | 322/387 [13:17<02:42,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  83%|████████▎ | 323/387 [13:20<02:43,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  84%|████████▎ | 324/387 [13:21<02:08,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  84%|████████▍ | 325/387 [13:23<02:15,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  84%|████████▍ | 326/387 [13:24<01:48,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  84%|████████▍ | 327/387 [13:27<02:17,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  85%|████████▍ | 328/387 [13:29<01:54,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  85%|████████▌ | 329/387 [13:35<03:12,  3.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  85%|████████▌ | 330/387 [13:36<02:27,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  86%|████████▌ | 331/387 [13:40<02:49,  3.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  86%|████████▌ | 332/387 [13:41<02:11,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  86%|████████▌ | 333/387 [13:45<02:29,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  86%|████████▋ | 334/387 [13:45<01:56,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  87%|████████▋ | 335/387 [13:48<02:06,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  87%|████████▋ | 336/387 [13:49<01:40,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  87%|████████▋ | 337/387 [13:55<02:34,  3.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  87%|████████▋ | 338/387 [13:56<01:59,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  88%|████████▊ | 339/387 [14:01<02:32,  3.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  88%|████████▊ | 340/387 [14:02<01:57,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  88%|████████▊ | 341/387 [14:05<02:05,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  88%|████████▊ | 342/387 [14:06<01:37,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  89%|████████▊ | 343/387 [14:09<01:49,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  89%|████████▉ | 344/387 [14:10<01:26,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  89%|████████▉ | 345/387 [14:13<01:43,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  89%|████████▉ | 346/387 [14:14<01:20,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  90%|████████▉ | 347/387 [14:20<01:59,  2.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  90%|████████▉ | 348/387 [14:21<01:31,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  90%|█████████ | 349/387 [14:25<01:52,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  90%|█████████ | 350/387 [14:26<01:26,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  91%|█████████ | 351/387 [14:29<01:31,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  91%|█████████ | 352/387 [14:30<01:11,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  91%|█████████ | 353/387 [14:32<01:13,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  91%|█████████▏| 354/387 [14:33<00:58,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  92%|█████████▏| 355/387 [14:38<01:29,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  92%|█████████▏| 356/387 [14:39<01:09,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  92%|█████████▏| 357/387 [14:44<01:33,  3.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  93%|█████████▎| 358/387 [14:45<01:10,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  93%|█████████▎| 359/387 [14:48<01:12,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  93%|█████████▎| 360/387 [14:49<00:56,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  93%|█████████▎| 361/387 [14:52<00:59,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  94%|█████████▎| 362/387 [14:53<00:46,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  94%|█████████▍| 363/387 [14:55<00:48,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  94%|█████████▍| 364/387 [14:56<00:38,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  94%|█████████▍| 365/387 [15:01<00:58,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  95%|█████████▍| 366/387 [15:02<00:44,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  95%|█████████▍| 367/387 [15:07<01:02,  3.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  95%|█████████▌| 368/387 [15:08<00:46,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  95%|█████████▌| 369/387 [15:12<00:53,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  96%|█████████▌| 370/387 [15:13<00:39,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  96%|█████████▌| 371/387 [15:16<00:39,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  96%|█████████▌| 372/387 [15:17<00:30,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  96%|█████████▋| 373/387 [15:19<00:29,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  97%|█████████▋| 374/387 [15:20<00:22,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  97%|█████████▋| 375/387 [15:26<00:37,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  97%|█████████▋| 376/387 [15:27<00:26,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  97%|█████████▋| 377/387 [15:32<00:30,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  98%|█████████▊| 378/387 [15:33<00:21,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  98%|█████████▊| 379/387 [15:35<00:20,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  98%|█████████▊| 380/387 [15:36<00:14,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  98%|█████████▊| 381/387 [15:39<00:14,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  99%|█████████▊| 382/387 [15:40<00:09,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  99%|█████████▉| 383/387 [15:45<00:11,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  99%|█████████▉| 384/387 [15:46<00:06,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training:  99%|█████████▉| 385/387 [15:50<00:05,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Training: 100%|█████████▉| 386/387 [15:51<00:02,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 - Training: 100%|██████████| 387/387 [15:54<00:00,  2.47s/it]\n",
            "Epoch 2/10 - Validation:   1%|          | 1/97 [00:04<06:33,  4.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:   2%|▏         | 2/97 [00:04<02:52,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:   3%|▎         | 3/97 [00:07<03:38,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:   4%|▍         | 4/97 [00:07<02:18,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:   5%|▌         | 5/97 [00:10<03:02,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:   6%|▌         | 6/97 [00:10<02:08,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:   7%|▋         | 7/97 [00:14<03:22,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:   8%|▊         | 8/97 [00:14<02:26,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:   9%|▉         | 9/97 [00:19<03:33,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  10%|█         | 10/97 [00:19<02:35,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  11%|█▏        | 11/97 [00:23<03:28,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  12%|█▏        | 12/97 [00:23<02:28,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  13%|█▎        | 13/97 [00:26<02:57,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  14%|█▍        | 14/97 [00:26<02:08,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  15%|█▌        | 15/97 [00:29<02:27,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  16%|█▋        | 16/97 [00:29<01:47,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  18%|█▊        | 17/97 [00:32<02:20,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  19%|█▊        | 18/97 [00:32<01:43,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  20%|█▉        | 19/97 [00:37<03:06,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  21%|██        | 20/97 [00:37<02:17,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  22%|██▏       | 21/97 [00:42<03:20,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  23%|██▎       | 22/97 [00:42<02:25,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  24%|██▎       | 23/97 [00:45<02:35,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 - Validation:  26%|██▌       | 25/97 [00:47<02:07,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  27%|██▋       | 26/97 [00:47<01:33,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  28%|██▊       | 27/97 [00:50<01:51,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  29%|██▉       | 28/97 [00:50<01:22,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  30%|██▉       | 29/97 [00:53<02:01,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  31%|███       | 30/97 [00:53<01:29,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  32%|███▏      | 31/97 [00:58<02:29,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  33%|███▎      | 32/97 [00:58<01:53,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  34%|███▍      | 33/97 [01:04<02:59,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  35%|███▌      | 34/97 [01:04<02:09,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  36%|███▌      | 35/97 [01:07<02:24,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  37%|███▋      | 36/97 [01:07<01:43,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  38%|███▊      | 37/97 [01:09<01:55,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  39%|███▉      | 38/97 [01:10<01:22,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  40%|████      | 39/97 [01:12<01:42,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  41%|████      | 40/97 [01:13<01:14,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  42%|████▏     | 41/97 [01:15<01:40,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  43%|████▎     | 42/97 [01:16<01:13,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  44%|████▍     | 43/97 [01:20<01:56,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  45%|████▌     | 44/97 [01:20<01:25,  1.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  46%|████▋     | 45/97 [01:25<02:19,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  47%|████▋     | 46/97 [01:26<01:40,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  48%|████▊     | 47/97 [01:29<02:04,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 - Validation:  51%|█████     | 49/97 [01:33<01:44,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  52%|█████▏    | 50/97 [01:33<01:15,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  53%|█████▎    | 51/97 [01:36<01:32,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  54%|█████▎    | 52/97 [01:36<01:06,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  55%|█████▍    | 53/97 [01:40<01:32,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  56%|█████▌    | 54/97 [01:40<01:06,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  57%|█████▋    | 55/97 [01:44<01:42,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  58%|█████▊    | 56/97 [01:45<01:13,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  59%|█████▉    | 57/97 [01:49<01:43,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  60%|█████▉    | 58/97 [01:49<01:14,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  61%|██████    | 59/97 [01:52<01:22,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  62%|██████▏   | 60/97 [01:52<00:58,  1.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  63%|██████▎   | 61/97 [01:55<01:08,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 - Validation:  65%|██████▍   | 63/97 [01:58<00:57,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  66%|██████▌   | 64/97 [01:58<00:40,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  67%|██████▋   | 65/97 [02:01<00:56,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  68%|██████▊   | 66/97 [02:01<00:40,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  69%|██████▉   | 67/97 [02:05<01:05,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  70%|███████   | 68/97 [02:06<00:47,  1.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  71%|███████   | 69/97 [02:10<01:10,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  72%|███████▏  | 70/97 [02:11<00:50,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  73%|███████▎  | 71/97 [02:14<00:58,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  74%|███████▍  | 72/97 [02:14<00:41,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  75%|███████▌  | 73/97 [02:17<00:46,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  76%|███████▋  | 74/97 [02:17<00:33,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  77%|███████▋  | 75/97 [02:19<00:37,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 - Validation:  79%|███████▉  | 77/97 [02:22<00:33,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  80%|████████  | 78/97 [02:22<00:24,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  81%|████████▏ | 79/97 [02:26<00:37,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  82%|████████▏ | 80/97 [02:27<00:26,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  84%|████████▎ | 81/97 [02:31<00:39,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  85%|████████▍ | 82/97 [02:32<00:27,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  86%|████████▌ | 83/97 [02:35<00:31,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  87%|████████▋ | 84/97 [02:35<00:21,  1.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  88%|████████▊ | 85/97 [02:38<00:23,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 - Validation:  90%|████████▉ | 87/97 [02:41<00:18,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  91%|█████████ | 88/97 [02:41<00:12,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  92%|█████████▏| 89/97 [02:43<00:13,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  93%|█████████▎| 90/97 [02:44<00:09,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  94%|█████████▍| 91/97 [02:48<00:12,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  95%|█████████▍| 92/97 [02:48<00:07,  1.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  96%|█████████▌| 93/97 [02:53<00:09,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  97%|█████████▋| 94/97 [02:53<00:05,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/10 - Validation:  98%|█████████▊| 95/97 [02:56<00:04,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 - Validation: 100%|██████████| 97/97 [02:57<00:00,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3/10 - Training:   0%|          | 0/387 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   0%|          | 1/387 [00:04<29:57,  4.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   1%|          | 2/387 [00:05<15:31,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   1%|          | 3/387 [00:09<18:53,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   1%|          | 4/387 [00:10<13:54,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   1%|▏         | 5/387 [00:15<22:17,  3.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   2%|▏         | 6/387 [00:16<16:54,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   2%|▏         | 7/387 [00:21<20:40,  3.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   2%|▏         | 8/387 [00:22<17:02,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   2%|▏         | 9/387 [00:25<15:52,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   3%|▎         | 10/387 [00:26<13:48,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   3%|▎         | 11/387 [00:29<14:48,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   3%|▎         | 12/387 [00:31<13:39,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   3%|▎         | 13/387 [00:34<15:17,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   4%|▎         | 14/387 [00:37<16:36,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   4%|▍         | 15/387 [00:40<16:54,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   4%|▍         | 16/387 [00:42<15:11,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   4%|▍         | 17/387 [00:44<14:30,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   5%|▍         | 18/387 [00:46<13:43,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   5%|▍         | 19/387 [00:47<12:52,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   5%|▌         | 20/387 [00:49<12:35,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   5%|▌         | 21/387 [00:51<11:35,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   6%|▌         | 22/387 [00:56<16:37,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   6%|▌         | 23/387 [00:58<16:23,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   6%|▌         | 24/387 [01:03<19:29,  3.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   6%|▋         | 25/387 [01:04<16:08,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   7%|▋         | 26/387 [01:07<15:55,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   7%|▋         | 27/387 [01:08<14:00,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   7%|▋         | 28/387 [01:10<13:17,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   7%|▋         | 29/387 [01:12<12:36,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   8%|▊         | 30/387 [01:15<13:21,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   8%|▊         | 31/387 [01:18<14:44,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   8%|▊         | 32/387 [01:21<16:53,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   9%|▊         | 33/387 [01:24<16:53,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   9%|▉         | 34/387 [01:27<16:03,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   9%|▉         | 35/387 [01:28<14:29,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:   9%|▉         | 36/387 [01:30<12:47,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  10%|▉         | 37/387 [01:32<12:46,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  10%|▉         | 38/387 [01:34<11:58,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  10%|█         | 39/387 [01:36<11:21,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  10%|█         | 40/387 [01:40<15:16,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  11%|█         | 41/387 [01:42<14:28,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  11%|█         | 42/387 [01:45<15:37,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  11%|█         | 43/387 [01:47<14:12,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  11%|█▏        | 44/387 [01:49<13:17,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  12%|█▏        | 45/387 [01:51<12:20,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  12%|█▏        | 46/387 [01:53<11:49,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  12%|█▏        | 47/387 [01:55<11:13,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  12%|█▏        | 48/387 [01:57<11:33,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  13%|█▎        | 49/387 [02:00<12:51,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  13%|█▎        | 50/387 [02:02<12:52,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  13%|█▎        | 51/387 [02:06<15:28,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  13%|█▎        | 52/387 [02:07<13:17,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  14%|█▎        | 53/387 [02:10<13:16,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  14%|█▍        | 54/387 [02:11<12:03,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  14%|█▍        | 55/387 [02:14<11:56,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  14%|█▍        | 56/387 [02:16<11:45,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  15%|█▍        | 57/387 [02:18<11:44,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  15%|█▍        | 58/387 [02:21<13:59,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  15%|█▌        | 59/387 [02:24<14:48,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  16%|█▌        | 60/387 [02:27<14:58,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  16%|█▌        | 61/387 [02:30<15:24,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  16%|█▌        | 62/387 [02:32<13:40,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  16%|█▋        | 63/387 [02:34<13:19,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  17%|█▋        | 64/387 [02:36<11:51,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  17%|█▋        | 65/387 [02:38<11:35,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  17%|█▋        | 66/387 [02:40<11:42,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  17%|█▋        | 67/387 [02:43<12:59,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  18%|█▊        | 68/387 [02:46<13:16,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  18%|█▊        | 69/387 [02:50<15:48,  2.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  18%|█▊        | 70/387 [02:52<13:41,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  18%|█▊        | 71/387 [02:54<12:53,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  19%|█▊        | 72/387 [02:56<12:14,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  19%|█▉        | 73/387 [02:57<11:01,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  19%|█▉        | 74/387 [03:00<11:05,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  19%|█▉        | 75/387 [03:01<10:06,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  20%|█▉        | 76/387 [03:05<13:27,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  20%|█▉        | 77/387 [03:08<13:31,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  20%|██        | 78/387 [03:12<14:58,  2.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  20%|██        | 79/387 [03:14<14:13,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  21%|██        | 80/387 [03:17<13:50,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  21%|██        | 81/387 [03:18<11:52,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  21%|██        | 82/387 [03:20<11:49,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  21%|██▏       | 83/387 [03:22<11:19,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  22%|██▏       | 84/387 [03:24<11:03,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  22%|██▏       | 85/387 [03:27<11:20,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  22%|██▏       | 86/387 [03:30<13:13,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  22%|██▏       | 87/387 [03:33<12:55,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  23%|██▎       | 88/387 [03:36<13:57,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  23%|██▎       | 89/387 [03:37<11:25,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  23%|██▎       | 90/387 [03:40<11:39,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  24%|██▎       | 91/387 [03:42<11:23,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  24%|██▍       | 92/387 [03:44<11:45,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  24%|██▍       | 93/387 [03:47<12:35,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  24%|██▍       | 94/387 [03:49<11:34,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  25%|██▍       | 95/387 [03:54<14:41,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  25%|██▍       | 96/387 [03:56<13:12,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  25%|██▌       | 97/387 [03:59<14:16,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  25%|██▌       | 98/387 [04:01<12:05,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  26%|██▌       | 99/387 [04:03<11:34,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  26%|██▌       | 100/387 [04:05<10:36,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  26%|██▌       | 101/387 [04:07<10:47,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  26%|██▋       | 102/387 [04:09<09:33,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  27%|██▋       | 103/387 [04:13<13:07,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  27%|██▋       | 104/387 [04:16<12:40,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  27%|██▋       | 105/387 [04:20<14:22,  3.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  27%|██▋       | 106/387 [04:22<12:41,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  28%|██▊       | 107/387 [04:23<11:26,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  28%|██▊       | 108/387 [04:25<10:37,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  28%|██▊       | 109/387 [04:27<09:45,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  28%|██▊       | 110/387 [04:29<09:34,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  29%|██▊       | 111/387 [04:31<09:00,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  29%|██▉       | 112/387 [04:34<11:12,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  29%|██▉       | 113/387 [04:36<10:34,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  29%|██▉       | 114/387 [04:41<13:17,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  30%|██▉       | 115/387 [04:44<13:21,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  30%|██▉       | 116/387 [04:45<11:54,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  30%|███       | 117/387 [04:47<10:13,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  30%|███       | 118/387 [04:49<10:21,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  31%|███       | 119/387 [04:51<08:49,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  31%|███       | 120/387 [04:53<09:55,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  31%|███▏      | 121/387 [04:55<09:10,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  32%|███▏      | 122/387 [04:59<11:52,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  32%|███▏      | 123/387 [05:03<13:34,  3.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  32%|███▏      | 124/387 [05:05<11:43,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  32%|███▏      | 125/387 [05:07<11:14,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  33%|███▎      | 126/387 [05:09<09:35,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  33%|███▎      | 127/387 [05:11<09:18,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  33%|███▎      | 128/387 [05:13<09:20,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  33%|███▎      | 129/387 [05:14<08:05,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  34%|███▎      | 130/387 [05:18<11:16,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  34%|███▍      | 131/387 [05:19<09:01,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  34%|███▍      | 132/387 [05:25<13:23,  3.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  34%|███▍      | 133/387 [05:27<11:30,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  35%|███▍      | 134/387 [05:29<11:03,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  35%|███▍      | 135/387 [05:31<10:00,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  35%|███▌      | 136/387 [05:32<09:03,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  35%|███▌      | 137/387 [05:35<09:24,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  36%|███▌      | 138/387 [05:36<08:05,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  36%|███▌      | 139/387 [05:40<10:17,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  36%|███▌      | 140/387 [05:42<09:50,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  36%|███▋      | 141/387 [05:47<12:46,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  37%|███▋      | 142/387 [05:49<11:55,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  37%|███▋      | 143/387 [05:51<10:32,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  37%|███▋      | 144/387 [05:54<10:36,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  37%|███▋      | 145/387 [05:56<09:25,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  38%|███▊      | 146/387 [05:57<08:37,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  38%|███▊      | 147/387 [05:59<08:03,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  38%|███▊      | 148/387 [06:03<09:56,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  39%|███▊      | 149/387 [06:04<09:13,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  39%|███▉      | 150/387 [06:09<11:41,  2.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  39%|███▉      | 151/387 [06:11<11:04,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  39%|███▉      | 152/387 [06:13<10:04,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  40%|███▉      | 153/387 [06:15<08:48,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  40%|███▉      | 154/387 [06:17<08:41,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  40%|████      | 155/387 [06:19<08:37,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  40%|████      | 156/387 [06:21<07:38,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  41%|████      | 157/387 [06:24<09:05,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  41%|████      | 158/387 [06:27<09:45,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  41%|████      | 159/387 [06:29<09:14,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  41%|████▏     | 160/387 [06:33<10:48,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  42%|████▏     | 161/387 [06:35<09:55,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  42%|████▏     | 162/387 [06:38<09:37,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  42%|████▏     | 163/387 [06:39<08:28,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  42%|████▏     | 164/387 [06:41<08:04,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  43%|████▎     | 165/387 [06:43<07:21,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  43%|████▎     | 166/387 [06:46<08:31,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  43%|████▎     | 167/387 [06:49<09:45,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  43%|████▎     | 168/387 [06:51<08:45,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  44%|████▎     | 169/387 [06:55<10:36,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  44%|████▍     | 170/387 [06:56<08:27,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  44%|████▍     | 171/387 [06:59<08:40,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  44%|████▍     | 172/387 [07:00<07:28,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  45%|████▍     | 173/387 [07:03<08:08,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  45%|████▍     | 174/387 [07:04<07:31,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  45%|████▌     | 175/387 [07:07<08:26,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  45%|████▌     | 176/387 [07:11<09:41,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  46%|████▌     | 177/387 [07:15<10:27,  2.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  46%|████▌     | 178/387 [07:17<10:05,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  46%|████▋     | 179/387 [07:20<09:33,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  47%|████▋     | 180/387 [07:21<08:19,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  47%|████▋     | 181/387 [07:23<07:49,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  47%|████▋     | 182/387 [07:25<07:37,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  47%|████▋     | 183/387 [07:27<06:59,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  48%|████▊     | 184/387 [07:30<07:52,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  48%|████▊     | 185/387 [07:32<07:35,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  48%|████▊     | 186/387 [07:36<09:26,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  48%|████▊     | 187/387 [07:39<09:32,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  49%|████▊     | 188/387 [07:41<08:32,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  49%|████▉     | 189/387 [07:42<07:09,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  49%|████▉     | 190/387 [07:45<07:35,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  49%|████▉     | 191/387 [07:46<06:34,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  50%|████▉     | 192/387 [07:49<06:51,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  50%|████▉     | 193/387 [07:51<07:15,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  50%|█████     | 194/387 [07:54<08:12,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  50%|█████     | 195/387 [07:57<08:11,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  51%|█████     | 196/387 [08:00<08:35,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  51%|█████     | 197/387 [08:02<08:00,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  51%|█████     | 198/387 [08:04<07:06,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  51%|█████▏    | 199/387 [08:06<06:37,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  52%|█████▏    | 200/387 [08:08<06:32,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  52%|█████▏    | 201/387 [08:09<05:52,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  52%|█████▏    | 202/387 [08:12<06:30,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  52%|█████▏    | 203/387 [08:14<06:26,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  53%|█████▎    | 204/387 [08:18<08:20,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  53%|█████▎    | 205/387 [08:22<09:00,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  53%|█████▎    | 206/387 [08:24<08:18,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  53%|█████▎    | 207/387 [08:26<07:50,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  54%|█████▎    | 208/387 [08:27<06:25,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  54%|█████▍    | 209/387 [08:30<06:37,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  54%|█████▍    | 210/387 [08:31<06:13,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  55%|█████▍    | 211/387 [08:33<05:53,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  55%|█████▍    | 212/387 [08:36<06:51,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  55%|█████▌    | 213/387 [08:38<06:38,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  55%|█████▌    | 214/387 [08:43<08:32,  2.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  56%|█████▌    | 215/387 [08:44<07:13,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  56%|█████▌    | 216/387 [08:47<07:18,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  56%|█████▌    | 217/387 [08:48<05:47,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  56%|█████▋    | 218/387 [08:51<06:23,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  57%|█████▋    | 219/387 [08:52<05:50,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  57%|█████▋    | 220/387 [08:56<06:39,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  57%|█████▋    | 221/387 [08:58<06:45,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  57%|█████▋    | 222/387 [09:01<06:57,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  58%|█████▊    | 223/387 [09:04<07:44,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  58%|█████▊    | 224/387 [09:06<06:45,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  58%|█████▊    | 225/387 [09:08<06:18,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  58%|█████▊    | 226/387 [09:10<06:02,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  59%|█████▊    | 227/387 [09:12<05:36,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  59%|█████▉    | 228/387 [09:14<05:30,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  59%|█████▉    | 229/387 [09:15<04:50,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  59%|█████▉    | 230/387 [09:19<06:22,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  60%|█████▉    | 231/387 [09:21<06:09,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  60%|█████▉    | 232/387 [09:25<07:28,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  60%|██████    | 233/387 [09:27<06:51,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  60%|██████    | 234/387 [09:29<06:17,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  61%|██████    | 235/387 [09:31<05:49,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  61%|██████    | 236/387 [09:33<05:23,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  61%|██████    | 237/387 [09:35<05:17,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  61%|██████▏   | 238/387 [09:36<04:29,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  62%|██████▏   | 239/387 [09:40<06:01,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  62%|██████▏   | 240/387 [09:42<05:47,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  62%|██████▏   | 241/387 [09:46<06:23,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  63%|██████▎   | 242/387 [09:50<07:24,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  63%|██████▎   | 243/387 [09:51<05:54,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  63%|██████▎   | 244/387 [09:54<06:06,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  63%|██████▎   | 245/387 [09:55<05:16,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  64%|██████▎   | 246/387 [09:57<05:04,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  64%|██████▍   | 247/387 [09:59<04:35,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  64%|██████▍   | 248/387 [10:01<04:53,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  64%|██████▍   | 249/387 [10:04<05:10,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  65%|██████▍   | 250/387 [10:06<05:25,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  65%|██████▍   | 251/387 [10:10<06:17,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  65%|██████▌   | 252/387 [10:14<07:02,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  65%|██████▌   | 253/387 [10:15<05:44,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  66%|██████▌   | 254/387 [10:18<05:34,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  66%|██████▌   | 255/387 [10:20<05:13,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  66%|██████▌   | 256/387 [10:21<04:51,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  66%|██████▋   | 257/387 [10:23<04:29,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  67%|██████▋   | 258/387 [10:26<05:00,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  67%|██████▋   | 259/387 [10:29<05:29,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  67%|██████▋   | 260/387 [10:31<05:09,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  67%|██████▋   | 261/387 [10:35<06:10,  2.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  68%|██████▊   | 262/387 [10:37<05:09,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  68%|██████▊   | 263/387 [10:39<05:08,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  68%|██████▊   | 264/387 [10:41<04:44,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  68%|██████▊   | 265/387 [10:43<04:22,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  69%|██████▊   | 266/387 [10:45<04:09,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  69%|██████▉   | 267/387 [10:47<04:04,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  69%|██████▉   | 268/387 [10:50<04:35,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  70%|██████▉   | 269/387 [10:54<05:23,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  70%|██████▉   | 270/387 [10:57<05:48,  2.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  70%|███████   | 271/387 [10:59<05:12,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  70%|███████   | 272/387 [11:01<04:50,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  71%|███████   | 273/387 [11:03<04:10,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  71%|███████   | 274/387 [11:04<03:47,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  71%|███████   | 275/387 [11:06<03:38,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  71%|███████▏  | 276/387 [11:08<03:45,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  72%|███████▏  | 277/387 [11:10<03:33,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  72%|███████▏  | 278/387 [11:14<04:20,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  72%|███████▏  | 279/387 [11:17<04:48,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  72%|███████▏  | 280/387 [11:19<04:28,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  73%|███████▎  | 281/387 [11:22<04:26,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  73%|███████▎  | 282/387 [11:23<03:54,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  73%|███████▎  | 283/387 [11:25<03:51,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  73%|███████▎  | 284/387 [11:27<03:40,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  74%|███████▎  | 285/387 [11:29<03:36,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  74%|███████▍  | 286/387 [11:32<03:47,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  74%|███████▍  | 287/387 [11:35<04:18,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  74%|███████▍  | 288/387 [11:40<05:15,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  75%|███████▍  | 289/387 [11:42<04:30,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  75%|███████▍  | 290/387 [11:44<04:18,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  75%|███████▌  | 291/387 [11:46<04:06,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  75%|███████▌  | 292/387 [11:48<03:35,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  76%|███████▌  | 293/387 [11:50<03:27,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  76%|███████▌  | 294/387 [11:52<03:16,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  76%|███████▌  | 295/387 [11:55<03:53,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  76%|███████▋  | 296/387 [11:58<03:45,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  77%|███████▋  | 297/387 [12:02<04:33,  3.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  77%|███████▋  | 298/387 [12:05<04:22,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  77%|███████▋  | 299/387 [12:07<03:45,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  78%|███████▊  | 300/387 [12:09<03:41,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  78%|███████▊  | 301/387 [12:10<02:57,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  78%|███████▊  | 302/387 [12:13<03:23,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  78%|███████▊  | 303/387 [12:15<03:06,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  79%|███████▊  | 304/387 [12:19<03:52,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  79%|███████▉  | 305/387 [12:21<03:36,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  79%|███████▉  | 306/387 [12:26<04:16,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  79%|███████▉  | 307/387 [12:27<03:32,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  80%|███████▉  | 308/387 [12:29<03:20,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  80%|███████▉  | 309/387 [12:31<03:04,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  80%|████████  | 310/387 [12:33<02:50,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  80%|████████  | 311/387 [12:35<02:39,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  81%|████████  | 312/387 [12:38<02:48,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  81%|████████  | 313/387 [12:39<02:27,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  81%|████████  | 314/387 [12:45<03:39,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  81%|████████▏ | 315/387 [12:46<03:13,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  82%|████████▏ | 316/387 [12:50<03:30,  2.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  82%|████████▏ | 317/387 [12:52<03:00,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  82%|████████▏ | 318/387 [12:55<03:08,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  82%|████████▏ | 319/387 [12:56<02:27,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  83%|████████▎ | 320/387 [12:58<02:38,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  83%|████████▎ | 321/387 [13:01<02:37,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  83%|████████▎ | 322/387 [13:04<02:41,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  83%|████████▎ | 323/387 [13:08<03:06,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  84%|████████▎ | 324/387 [13:11<03:06,  2.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  84%|████████▍ | 325/387 [13:13<02:54,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  84%|████████▍ | 326/387 [13:14<02:21,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  84%|████████▍ | 327/387 [13:17<02:32,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  85%|████████▍ | 328/387 [13:19<02:09,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  85%|████████▌ | 329/387 [13:21<02:10,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  85%|████████▌ | 330/387 [13:24<02:18,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  86%|████████▌ | 331/387 [13:27<02:26,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  86%|████████▌ | 332/387 [13:32<03:06,  3.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  86%|████████▌ | 333/387 [13:33<02:26,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  86%|████████▋ | 334/387 [13:37<02:32,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  87%|████████▋ | 335/387 [13:38<02:06,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  87%|████████▋ | 336/387 [13:41<02:07,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  87%|████████▋ | 337/387 [13:42<01:42,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  87%|████████▋ | 338/387 [13:45<01:54,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  88%|████████▊ | 339/387 [13:48<02:02,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  88%|████████▊ | 340/387 [13:50<02:01,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  88%|████████▊ | 341/387 [13:53<02:01,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  88%|████████▊ | 342/387 [13:56<02:02,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  89%|████████▊ | 343/387 [13:57<01:39,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  89%|████████▉ | 344/387 [13:59<01:35,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  89%|████████▉ | 345/387 [14:01<01:21,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  89%|████████▉ | 346/387 [14:03<01:26,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  90%|████████▉ | 347/387 [14:06<01:30,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  90%|████████▉ | 348/387 [14:08<01:29,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  90%|█████████ | 349/387 [14:12<01:42,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  90%|█████████ | 350/387 [14:16<01:52,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  91%|█████████ | 351/387 [14:18<01:40,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  91%|█████████ | 352/387 [14:19<01:25,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  91%|█████████ | 353/387 [14:22<01:19,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  91%|█████████▏| 354/387 [14:24<01:19,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  92%|█████████▏| 355/387 [14:26<01:07,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  92%|█████████▏| 356/387 [14:28<01:10,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  92%|█████████▏| 357/387 [14:32<01:22,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  93%|█████████▎| 358/387 [14:35<01:21,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  93%|█████████▎| 359/387 [14:39<01:26,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  93%|█████████▎| 360/387 [14:41<01:12,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  93%|█████████▎| 361/387 [14:43<01:06,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  94%|█████████▎| 362/387 [14:45<01:00,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  94%|█████████▍| 363/387 [14:46<00:51,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  94%|█████████▍| 364/387 [14:49<00:51,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  94%|█████████▍| 365/387 [14:50<00:44,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  95%|█████████▍| 366/387 [14:55<00:58,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  95%|█████████▍| 367/387 [14:58<00:55,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  95%|█████████▌| 368/387 [15:01<00:56,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  95%|█████████▌| 369/387 [15:04<00:51,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  96%|█████████▌| 370/387 [15:05<00:40,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  96%|█████████▌| 371/387 [15:07<00:37,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  96%|█████████▌| 372/387 [15:09<00:33,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  96%|█████████▋| 373/387 [15:11<00:29,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  97%|█████████▋| 374/387 [15:14<00:30,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  97%|█████████▋| 375/387 [15:16<00:27,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  97%|█████████▋| 376/387 [15:20<00:31,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  97%|█████████▋| 377/387 [15:22<00:25,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  98%|█████████▊| 378/387 [15:25<00:24,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  98%|█████████▊| 379/387 [15:27<00:20,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  98%|█████████▊| 380/387 [15:29<00:15,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  98%|█████████▊| 381/387 [15:31<00:12,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  99%|█████████▊| 382/387 [15:33<00:10,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  99%|█████████▉| 383/387 [15:35<00:08,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  99%|█████████▉| 384/387 [15:38<00:06,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training:  99%|█████████▉| 385/387 [15:42<00:05,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Training: 100%|█████████▉| 386/387 [15:45<00:02,  2.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([2, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([2, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([2, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([2, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([2, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 - Training: 100%|██████████| 387/387 [15:46<00:00,  2.45s/it]\n",
            "Epoch 3/10 - Validation:   1%|          | 1/97 [00:03<05:02,  3.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:   2%|▏         | 2/97 [00:03<02:13,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:   3%|▎         | 3/97 [00:06<03:29,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:   4%|▍         | 4/97 [00:06<02:12,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:   5%|▌         | 5/97 [00:11<03:49,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:   6%|▌         | 6/97 [00:11<02:38,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:   7%|▋         | 7/97 [00:15<03:48,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:   8%|▊         | 8/97 [00:15<02:41,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:   9%|▉         | 9/97 [00:19<03:42,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  10%|█         | 10/97 [00:20<02:41,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  11%|█▏        | 11/97 [00:23<03:19,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  12%|█▏        | 12/97 [00:23<02:23,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  13%|█▎        | 13/97 [00:26<02:46,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  14%|█▍        | 14/97 [00:26<01:59,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  15%|█▌        | 15/97 [00:29<02:21,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  16%|█▋        | 16/97 [00:29<01:44,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  18%|█▊        | 17/97 [00:32<02:28,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  19%|█▊        | 18/97 [00:32<01:48,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  20%|█▉        | 19/97 [00:37<03:04,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  21%|██        | 20/97 [00:37<02:14,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  22%|██▏       | 21/97 [00:42<03:17,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  23%|██▎       | 22/97 [00:42<02:22,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  24%|██▎       | 23/97 [00:45<02:38,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  25%|██▍       | 24/97 [00:45<01:53,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  26%|██▌       | 25/97 [00:47<02:10,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 - Validation:  28%|██▊       | 27/97 [00:50<01:54,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n",
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 - Validation:  30%|██▉       | 29/97 [00:53<01:56,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  31%|███       | 30/97 [00:53<01:26,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  32%|███▏      | 31/97 [00:58<02:28,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  33%|███▎      | 32/97 [00:58<01:48,  1.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  34%|███▍      | 33/97 [01:03<02:55,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  35%|███▌      | 34/97 [01:04<02:09,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  36%|███▌      | 35/97 [01:07<02:34,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  37%|███▋      | 36/97 [01:08<01:50,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  38%|███▊      | 37/97 [01:10<02:00,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  39%|███▉      | 38/97 [01:10<01:26,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  40%|████      | 39/97 [01:13<01:45,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  41%|████      | 40/97 [01:13<01:16,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  42%|████▏     | 41/97 [01:16<01:35,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  43%|████▎     | 42/97 [01:16<01:10,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  44%|████▍     | 43/97 [01:20<01:57,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  45%|████▌     | 44/97 [01:21<01:25,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  46%|████▋     | 45/97 [01:25<02:10,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  47%|████▋     | 46/97 [01:26<01:34,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  48%|████▊     | 47/97 [01:28<01:48,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  49%|████▉     | 48/97 [01:29<01:18,  1.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  51%|█████     | 49/97 [01:31<01:32,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  52%|█████▏    | 50/97 [01:32<01:06,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  53%|█████▎    | 51/97 [01:34<01:21,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  54%|█████▎    | 52/97 [01:34<00:58,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  55%|█████▍    | 53/97 [01:38<01:31,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  56%|█████▌    | 54/97 [01:39<01:10,  1.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  57%|█████▋    | 55/97 [01:44<01:45,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/10 - Validation:  58%|█████▊    | 56/97 [01:44<01:16,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features[0] shape: torch.Size([1, 24, 64, 64, 32])\n",
            "features[1] shape: torch.Size([1, 48, 32, 32, 16])\n",
            "features[2] shape: torch.Size([1, 96, 16, 16, 8])\n",
            "features[3] shape: torch.Size([1, 192, 8, 8, 4])\n",
            "features[4] shape: torch.Size([1, 384, 4, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "CP_Q8_dBPVlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec1858e-bf1a-4397-91a0-b6ecc26df6d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5\n",
            "Validation Loss: 1.6323459621557255\n",
            "Dice Score: 0.06389562040567398\n"
          ]
        }
      ],
      "source": [
        "checkpoint = torch.load(\"RobustTransSeg_epoch5.pth\")\n",
        "print(\"Epoch:\", checkpoint[\"epoch\"])\n",
        "print(\"Validation Loss:\", checkpoint[\"val_loss\"])\n",
        "print(\"Dice Score:\", checkpoint[\"dice_score\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81ImIzh3PVkA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDK0ed80PVfd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28SUncG1bDZs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}